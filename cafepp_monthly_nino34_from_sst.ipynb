{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# CAFEPP (utilising cafepp.py)\n",
    "\n",
    "***\n",
    "\n",
    "## This example will produce a set of monthly SST files across the V1 assimilation run (interpolated onto a 1x1 latxlon grid), and upon success, generate an average over the nino3.4 region and plot the time-series.\n",
    "\n",
    "***\n",
    "\n",
    "# Various settings required:\n",
    "\n",
    "## BATCH determines whether it will be sent to the queue via qsub command or run interactively.\n",
    "\n",
    "## CLEAN determines whether the run directory will be emptied prior to processing.\n",
    "\n",
    "Choose to run either 1. assimilation 2. forecast, then continue with plotting options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 12,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "sys.version= 2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \n",
      "[GCC 7.2.0]\n",
      "hostname= oa-32-cdc\n",
      "Removing run directory and reestablish it.\n",
      "Running in directory /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir\n",
      "Using script cafepp_monthly_forecast.py\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "from __future__ import print_function #this is to allow print(,file=xxx) feature\n",
    "\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "import inspect\n",
    "\n",
    "__file__='jupyter_notebook' #this can be deleted when written to a python script and loaded as module.\n",
    "\n",
    "print('sys.version=',sys.version)\n",
    "hostname=socket.gethostname()\n",
    "print('hostname=',hostname)\n",
    "\n",
    "#dvar='tos' #variable to generate as well as further proces and plot.\n",
    "#dvar='pr'\n",
    "#dvar='psl'\n",
    "#dvar='siconc'\n",
    "#dvar='msftyz' #was called msftyyz\n",
    "#dvar='ts'\n",
    "#dvar='thetao'\n",
    "#dvar='tos'\n",
    "#dvar='siconc'\n",
    "\n",
    "BATCH=True #submit to queue\n",
    "BATCH=False #run interactively but in a batch temporary area.\n",
    "\n",
    "CLEAN=False #don't remove rundir, just use it.\n",
    "CLEAN=True #remove rundir and recreate it.\n",
    "\n",
    "if(BATCH):\n",
    "  print('Submitting to queue.')\n",
    "\n",
    "if(CLEAN):\n",
    "  print('Removing run directory and reestablish it.')\n",
    "\n",
    "if(re.match('raijin',hostname)):\n",
    "  cmipdir='/short/v14/mac599' #this might be different to predir for other users.\n",
    "  predir='/short/v14/mac599' #this is directory area for temporary cafepp files.\n",
    "elif(re.match('oa-32-cdc',hostname) or re.match('oa-33-cdc',hostname)):\n",
    "  cmipdir='/OSM/CBR/OA_DCFP/data/CAFEPP/CMIP6' #this might be different to predir for other users.\n",
    "  predir='/OSM/CBR/OA_DCFP/data/col414' #this is directory area for temporary cafepp files.\n",
    "elif(re.match('tube-hba',hostname)):\n",
    "  cmipdir='/OSM/HBA/OA_DECADAL_CLIMATE/work/col414' #this might be different to predir for other users.\n",
    "  predir='/OSM/HBA/OA_DECADAL_CLIMATE/work/col414' #this is directory area for temporary cafepp files.\n",
    "else:\n",
    "  raise SystemExit('hostname not known:'+__file__+' line number: '+str(inspect.stack()[0][2])) \n",
    "\n",
    "topdir=predir+'/'+'cafepp'\n",
    "#script='cafepp_monthly_assimilation.py'\n",
    "script='cafepp_monthly_forecast.py'\n",
    "#script='cafepp_monthly_forecast_v2.py'\n",
    "#script='cafepp_monthly_control.py'\n",
    "\n",
    "rundir=topdir+'/'+'rundir20171124143249'\n",
    "rundir=topdir+'/'+'rundir20171128165302'\n",
    "rundir=topdir+'/'+'rundir'+datetime.datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "rundir=topdir+'/'+'rundir' #temporary running directory\n",
    "\n",
    "rundir=topdir+'/'+'rundir' #temporary running directory\n",
    "print('Running in directory '+rundir)\n",
    "print('Using script '+script)\n",
    "\n",
    "if(re.match('raijin',hostname)):\n",
    "  srcdir='/home/599/mac599/decadal' #location of main cafepp code\n",
    "  prodir=srcdir+'/paper_analysis' #project directory\n",
    "elif(re.match('oa-32-cdc',hostname) or re.match('oa-33-cdc',hostname)):\n",
    "  srcdir='/OSM/CBR/OA_DCFP/work/col414/cafepp' #'/home/599/mac599/decadal' #location of main cafepp code\n",
    "  prodir='/OSM/CBR/OA_DCFP/work/col414/cafepp' #srcdir+'/paper_analysis' #project directory\n",
    "elif(re.match('tube-hba',hostname)):\n",
    "  srcdir='/OSM/HBA/OA_DECADAL_CLIMATE/work/col414/cafepp' #'/home/599/mac599/decadal' #location of main cafepp code\n",
    "  prodir='/OSM/HBA/OA_DECADAL_CLIMATE/work/col414/cafepp' #srcdir+'/paper_analysis' #project directory  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 12,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Here we make directories, copy across necessary JSON and python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 15,
        "hidden": false,
        "row": 12,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "print('copying json files, generating symlinks, cmor tables, queue script, if necessary.')\n",
    "if(os.path.exists(rundir) and CLEAN):\n",
    "  shutil.rmtree(rundir)\n",
    "  os.mkdir(rundir)\n",
    "  os.mkdir(rundir+'/'+'JsonTemplates') # exist_ok=True only python3\n",
    "elif(not os.path.exists(rundir)):\n",
    "  os.mkdir(rundir)\n",
    "  os.mkdir(rundir+'/'+'JsonTemplates') # exist_ok=True only python3\n",
    "\n",
    "if(os.path.isdir(cmipdir+'/'+'CMIP6')):\n",
    "  print('hello')\n",
    "  os.symlink(cmipdir+'/'+'CMIP6',rundir+'/'+'CMIP6')\n",
    "else:\n",
    "  print('there')\n",
    "  os.mkdir(cmipdir)\n",
    "os.symlink(prodir+'/'+'TablesTemplates',rundir+'/'+'TablesTemplates')\n",
    "os.symlink(prodir+'/'+'cmip6-cmor-tables',rundir+'/'+'cmip6-cmor-tables')\n",
    "\n",
    "if(BATCH):\n",
    "  print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "  ifh=open(prodir+'/'+'qjob.csh')\n",
    "  ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "  for i,line in enumerate(ifh):\n",
    "    line=line.replace('CAFEPP_SCRIPT','./'+script+' RUNDIR')\n",
    "    line=line.replace('RUNDIR',rundir)\n",
    "    line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "    line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "    print(line,file=ofh,end='')\n",
    "  ifh.close()\n",
    "  ofh.close()\n",
    "\n",
    "vector_string=['decadal_diag.py','cafepp.py','app_funcs.py','ProcTime.py']\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+srcdir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(srcdir+'/'+file_now,rundir+'/'+file_now)\n",
    "\n",
    "vector_string=[script]\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+prodir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(prodir+'/'+file_now,rundir+'/'+file_now)\n",
    "  os.chmod(rundir+'/'+script,500) #make executable incase want to run it interacively from terminal.\n",
    "  \n",
    "vector_string=[]\n",
    "#vector_string.append(script) #may need to do edits?\n",
    "#vector_string.append('cafepp_monthly_assimilation.json')\n",
    "vector_string.append('JsonTemplates'+'/'+'cafepp_experiments.json')\n",
    "vector_string.append('JsonTemplates'+'/'+'cafepp_csiro-gfdl.json')\n",
    "vector_string.append('JsonTemplates'+'/'+'cafepp_vars.json')\n",
    "#vector_string.append('cafepp_monthly_forecast.py')\n",
    "\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+prodir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(prodir+'/'+file_now,rundir+'/'+file_now)\n",
    "  \n",
    "print('Copying '+prodir+'/'+'cafepp_monthly_assimilation.json',rundir+'/'+'JsonTemplates/cafepp_monthly_assimilation.json')\n",
    "shutil.copyfile(prodir+'/'+'cafepp_monthly_assimilation.json',rundir+'/'+'JsonTemplates/cafepp_monthly_assimilation.json')\n",
    "  \n",
    "if(not os.path.exists(rundir+'/'+'CMIP5')):\n",
    "  if(re.match('raijin',hostname)):\n",
    "    print('No need to set CMIP5 symbolic link on raijin.')\n",
    "  elif(re.match('oa-32-cdc',hostname) or re.match('oa-33-cdc',hostname)):\n",
    "    os.symlink('/OSM/CBR/OA_DCFP/data/CAFEPP/g/data/p66/mac599/CMIP5',rundir+'/'+'CMIP5')\n",
    "  elif(re.match('tube-hba',hostname)):\n",
    "    os.symlink('/OSM/HBA/OA_DECADAL_CLIMATE/work/col414/CMIP5',rundir+'/'+'CMIP5')\n",
    "  else:\n",
    "    raise SystemExit('Dont know how to set CMIP5 symbolic link on this machine.'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "#   srcdir='/home/599/mac599/decadal' #location of main cafepp code\n",
    "#   prodir=srcdir+'/paper_analysis' #project directory\n",
    " \n",
    "print('prodir=',prodir)\n",
    "print('rundir=',rundir)\n",
    "\n",
    "#break\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 27,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# We establish where to execute the job.\n",
    "\n",
    "## We import a function that is relatively simple to loop over all necessary years, months, ensembles as required.\n",
    "## Different applications will require a different module to be written (often small and relatively simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 16,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "os.chdir(rundir)\n",
    "print('Current Working Directory=',os.getcwd())\n",
    "\n",
    "os.environ['APP_OUTPATH'] = '.'\n",
    "print(os.getenv('APP_OUTPATH'))\n",
    "\n",
    "import getpass\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "from time import strftime\n",
    "import netCDF4\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import seawater\n",
    "#import sys\n",
    "import getopt\n",
    "import string\n",
    "from decadal_diag import MustHaveAllLevs,diag_acc_drake,diag_acc_africa,diag_mozmbq,diag_aabw,diag_nadw,\\\n",
    "diag_pp,diag_nflux,diag_ep,diag_ssh,diag_moc,diag_moc_atlantic,diag_moc_pacific,diag_moc_indian,\\\n",
    "diag_shice_cover,diag_nhice_cover,diag_nino34,xtra_nino34,init_data,sum_data,avg_data,filemonth_index,\\\n",
    "data_wavg,time_avg,diag_nhblocking_index,diag_rws5,finish,diag_msftyz,make_mask3D,diag_mfo,transPort,\\\n",
    "diag_rws500,create_odirs,create_ofils,diag_iod,diag_iod,xtra_iod,atmos_vertical_interpolate,diag_isothetaoNc,\\\n",
    "calc_iso_surface,calc_isoN,grab_var_meta,diag_psl,diag_hfls,diag_heat_content,diag_salt_content,\\\n",
    "diag_north_heat_trans,diag_north_salt_trans,ocean_vertical_interpolate,diag_thetao0to80m,diag_varNl,\\\n",
    "uncomment_json,process_json,modify_json,get_daily_indices_for_monthlyave,diag_maxdTbydz,diag_depmaxdTbydz,\\\n",
    "diag_dTbydz,shade_2d_simple,shade_2d_latlon,diag_zmld_boyer,zmld_boyer,sigmatheta,diag_zmld_so,\\\n",
    "zmld_so,diag_spice,spice,diag_bigthetao,diag_soabs,diag_spiciness,diag_potrho,fractional_year_from_num2date,\\\n",
    "new_monthly_array_shape,restrict_input_files,get_timestamp_number\n",
    "from decadal_diag import data_wavg_ProcTime,cmor_file_parts,cmor_directory_parts,cmor_ripf_parts,file_spec_summary,generate_daily_month_indices\n",
    "from decadal_diag import plot_map_box,plot_xy_climatology,plot_xy_ensemble,calculate_monthly_climatology_anomaly_from_monthly\n",
    "\n",
    "import cmor\n",
    "import cdtime\n",
    "from app_funcs import *\n",
    "import json\n",
    "import pprint\n",
    "from datetime import date\n",
    "import filecmp\n",
    "from shutil import copyfile\n",
    "import cdms2\n",
    "import inspect\n",
    "import socket\n",
    "import glob\n",
    "from matplotlib.mlab import griddata\n",
    "import scipy.sparse as sps\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['mathtext.default'] = 'regular'\n",
    "import matplotlib.pyplot as plt\n",
    "from gridfill import fill as poisson_fill\n",
    "\n",
    "#from ProcTime import ProcTime\n",
    "\n",
    "#del(cafepp_monthly_forecast)\n",
    "#if('cafepp_monthly_forecast' not in sys.modules):\n",
    "#  print('no')\n",
    "#else:\n",
    "#  print('yes')\n",
    "\n",
    "if(script=='cafepp_monthly_assimilation'):\n",
    "  import cafepp_monthly_assimilation #this script/function needs to be edited to limit variable.\n",
    "elif(script=='cafepp_monthly_forecast.py'):\n",
    "  import cafepp_monthly_forecast #this script/function needs to be edited to limit year,month,ensemble range,variable if desired. Will need to restart kernel for it to take effect.\n",
    "elif(script=='cafepp_monthly_control.py'):\n",
    "  import cafepp_monthly_control\n",
    "\n",
    "#print(sys.modules)\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 16,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## information common to processing all runs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 20,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN.\n",
      "indices_nino= ['nino34', 'nino3', 'nino4', 'nino1+2']\n",
      "indices_i_gr2= [[190, 239], [210, 269], [150, 209], [270, 280]]\n",
      "END.\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "import math\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "#del(get_timestamp_number)\n",
    "#from decadal_diag import get_timestamp_number\n",
    "\n",
    "nmy=12\n",
    "\n",
    "rad = 4.0*math.atan(1.0)/180.0\n",
    "#print('rad=',rad)\n",
    "\n",
    "lons_nino = [[190, 240, 240, 190, 190], [210, 270, 270, 210, 210], [160, 210, 210, 160, 160], [270, 280, 280, 270, 270]] # indices_nino=['nino34','nino3','nino4','nino1+2']\n",
    "lats_nino = [[-5, -5, 5, 5, -5], [-5.1, -5.1, 5.1, 5.1, -5.1], [-5, -5, 5, 5, -5], [-10, -10, 0, 0, -10]] # 170W-120W:190-240, 150W-90W:210-270, 160E-150W:160-210, 90W-80W:270-280 (10S-0 latitude, others all 5S to 5N)\n",
    "indices_nino=['nino34','nino3','nino4','nino1+2'] # 170W-120W:190-240, 150W-90W:210-270, 160E-150W:160-210, 90W-80W:270-280 (10S-0 latitude, others all 5S to 5N)\n",
    "indices_label=['Ni$\\~{n}$o3.4','Ni$\\~{n}$o3','Ni$\\~{n}$o4','Ni$\\~{n}$o1+2']\n",
    "  \n",
    "#if(cafe_grid=='gr2'):\n",
    "#elif(cafe_grid=='gn'):\n",
    "\n",
    "indices_i_gr2,indices_j_gr2=[[190,239],[210,269],[150,209],[270,280]],[[85,94],[85,94],[85,94],[80,89]] #check this, whether I need +1 also...what about fractional cells?\n",
    "indices_i_gn,indices_j_gn=[[110,159],[130,189],[80,129],[190,199]],[[122,151],[122,151],[122,151],[107,136]] #check this, whether I need +1 also...what about fractional cells?\n",
    "indices_i_ncep2,indices_j_ncep2=[[102,128],[112,144],[86,112],[144,149]], [[45,50],[45,50],[45,50],[42,46]]\n",
    "\n",
    "#indices_select=array('i',[0,1,2,3])\n",
    "#indices_select=[np.int(0)]\n",
    "#indices_select=range(3)\n",
    "#print(type(indices_select))\n",
    "#print('indices_select=',indices_select)\n",
    "\n",
    "#used for speeding things up, either can choose a single indice or all - don't know why can't use : in eval for e.g.\n",
    "sss='-1' #last\n",
    "sss='0' #first\n",
    "sss='ALL'\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "if(sss!='ALL'):\n",
    "  indices_nino=[indices_nino[eval(sss)]]\n",
    "  indices_label=[indices_label[eval(sss)]]\n",
    "  indices_i_gr2=[indices_i_gr2[eval(sss)]]\n",
    "  indices_j_gr2=[indices_j_gr2[eval(sss)]]\n",
    "  indices_i_gn=[indices_i_gn[eval(sss)]]\n",
    "  indices_j_gn=[indices_j_gn[eval(sss)]]\n",
    "  indices_i_ncep2=[indices_i_ncep2[eval(sss)]]\n",
    "  indices_j_ncep2=[indices_j_ncep2[eval(sss)]]\n",
    "print('indices_nino=',indices_nino)\n",
    "\n",
    "print('indices_i_gr2=',indices_i_gr2)\n",
    "\n",
    "nindices_nino=len(indices_nino)\n",
    "\n",
    "#else:\n",
    "#  raise Exception('STOP!')\n",
    "#raise Exception('STOP!')\n",
    "#del(get_timestamp_number)\n",
    "#from decadal_diag import get_timestamp_number\n",
    "\n",
    "rad = 4.0*math.atan(1.0)/180.0\n",
    "#print('rad=',rad)\n",
    "\n",
    "print('END.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 33,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 1. Here we are procesing an assimilation, set script='cafepp_monthly_assimilation.py' above.\n",
    "\n",
    "## Either submit it to the queue or run interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 20,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "  print('prodir=',prodir)\n",
    "\n",
    "  if(script=='cafepp_monthly_assimilation'):\n",
    "    if(BATCH):\n",
    "      os.chmod(script,500)\n",
    "      os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "    else:\n",
    "      print('Current Working Directory=',os.getcwd())\n",
    "      os.chdir(rundir)\n",
    "      cafepp_monthly_assimilation.main(rundir)\n",
    "  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 37,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "\n",
    "# 2. Here we are processing multi-ensemble forecast, set script='cafepp_monthly_forecast.py' above.\n",
    "## Either submit it to the queue or run interactively.\n",
    "\n",
    "queued version needs more work...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 42,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "Current Working Directory= /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir\n",
      "cafe_experiment,dvar,ybeg,yend,mbeg,mend,ybeg_first,yend_last,mbeg_first,mend_last,ebeg,eend= v1_forecast msftyz 2003 2003 1 12 2002 2016 2 5 1 1\n",
      "Processing cafepp_monthly_assimilation.json\n",
      "top_directory_no2= /g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\n",
      "Processing cafepp_experiments.json\n",
      "MAIN\n",
      "hostname= oa-32-cdc\n",
      "Running cafepp from JSON instructions: cafepp.json\n",
      "fh_printfile= <ipykernel.iostream.OutStream object at 0x7f0fa3ee4a90>\n",
      "cafepp_experiments_fh= {\n",
      "\"v0\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment_id\":\"piControl\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"parent_experiment_id\":\"piControl-spinup\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"Original version of the coupled model using the ACCESS ocean grid with the GFDL namelist options from the CM2p1 set-up of their coupled model.  The simulation ran for 700 years with the ocean BGC simulated for the last 300 years.  The model run was stable but it was later discovered the land topography was not properly activated.\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin\",\n",
      "\"top_directory_no1\":\"/g/data1/v14/coupled_model/v0/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"tube-hba\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"oa-32-cdc\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"yes\",\n",
      "\"storage_machine_no4\":\"Snapper-as\",\n",
      "\"top_directory_no4\":\"/Volumes/LaCieNo1/data/CAFEPP/g/data1/v14/coupled_model/v0/OUTPUT\",\n",
      "\"active_disk_no4\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599,lxs599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":295,\n",
      "\"yend_max\":625,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":1,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"v1\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment_id\":\"piControl\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"parent_experiment_id\":\"piControl-spinup\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"500-year run with properly activated land topography (oct16e) but bit too much mass (~ 18 hPa) in the atmosphere. Namelist modified: vertical coordinate is switched to zstar, cm2_bugs are removed from the ice model.\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin\",\n",
      "\"top_directory_no1\":\"/g/data1/v14/coupled_model/v1/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"tube-hba\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"oa-32-cdc\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"yes\",\n",
      "\"storage_machine_no4\":\"Snapper-as\",\n",
      "\"top_directory_no4\":\"/Volumes/LaCieNo1/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT\",\n",
      "\"active_disk_no4\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":500,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":9,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\",\n",
      "\"calendar\":\"noleap\",\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\"\n",
      "},\n",
      "\"v2\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment_id\":\"piControl\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"parent_experiment_id\":\"piControl-spinup\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"500-year simulation with restoration of ocean fields below ~2000m.\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin\",\n",
      "\"top_directory_no1\":\"/g/data1/v14/coupled_model/v2/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"tube-hba\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"oa-32-cdc\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"yes\",\n",
      "\"storage_machine_no4\":\"Snapper-as\",\n",
      "\"top_directory_no4\":\"/Volumes/LaCieNo1/data/CAFEPP/g/data1/v14/coupled_model/v2/OUTPUT\",\n",
      "\"active_disk_no4\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":500,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":5,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"v3\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"experiment_id\":\"piControl\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"parent_experiment_id\":\"piControl-spinup\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"500-year simulation with restoration of ocean fields below ~2000m.\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin\",\n",
      "\"top_directory_no1\":\"/g/data1/v14/coupled_model/v3/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"tube-hba\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"oa-32-cdc\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"yes\",\n",
      "\"storage_machine_no4\":\"Snapper-as\",\n",
      "\"top_directory_no4\":\"/Volumes/LaCieNo1/data/CAFEPP/g/data1/v14/coupled_model/v3/OUTPUT\",\n",
      "\"active_disk_no4\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":499,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":6,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"aug17p\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"parent_experiment_id\":\"piControl-spinup\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"500-year simulation with restoration of ocean fields below ~2000m.\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no1\":\"/short/v19/mtc599/ao_am2/aug17p//OUTPUT/\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"no\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":99,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":7,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"v0_forecast_old\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing simulation of the recent past\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"2yr or 5yr forecasts of months from Feb 2002 to May 2016 using Terry's and Didier's bred_vectors as IC\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba.nexus.csiro.au\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/DA/breed_da\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":500,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":1,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"coupled_da/OUTPUT-2step-nobreeding-carbon\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing simulation of the recent past\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"None\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba.nexus.csiro.au\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/DA/coupled_da/OUTPUT-2step-nobreeding-carbon\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":2002,\n",
      "\"yend_max\":2016,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":6,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":1,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"True\"\n",
      "},\n",
      "\"breed_da_twostep_carbon/MEMBERS/m.1/OUTPUT\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing simulation of the recent past\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"None\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba.nexus.csiro.au\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/DA/breed_da/twostep_carbon/MEMBERS/m.1/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":2002,\n",
      "\"yend_max\":2003,\n",
      "\"mbeg_min\":2,\n",
      "\"mend_max\":3,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":1,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"daily_data_layout\":\"leap_1fileperday\",\n",
      "\"monthly_data_layout\":\"leap_1filepermonth\",\n",
      "\"Forecast\":\"True\"\n",
      "},\n",
      "\"test_case\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"present-day control\",\n",
      "\"experiment_id\":\"pdControl\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"None\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba\",\n",
      "\"top_directory_no1\":\"/tube1/col414/coupled_model/feb17a/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"yes\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":390,\n",
      "\"yend_max\":400,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":1,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"v0_multiyear_forecast\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"present-day control\",\n",
      "\"experiment_id\":\"pdControl\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"None\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/forecasts/v0/yr2006/mn1/OUTPUT.1\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":2006,\n",
      "\"yend_max\":2011,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"leap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"leap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":2,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"coupled_da/OUTPUT-2step-nobreeding-carbon2\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing data assimilation of the recent past\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"See https://confluence.csiro.au/pages/\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/DA/coupled_da/OUTPUT-2step-nobreeding-carbon2\",\n",
      "\"active_disk_no1\":\"no\",\n",
      "\"storage_machine_no2\":\"raijin\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":2002,\n",
      "\"yend_max\":2016,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":6,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"julian_1fileperday\", \n",
      "\"monthly_data_layout\":\"julian_1fileperyear\",  \n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":2,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"True\",\n",
      "\"calendar\":\"julian\"\n",
      "},\n",
      "\"v0_forecast\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing forecast of the recent past/future\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"2yr or 5yr forecasts of months from Feb 2002 to May 2016 using Terry's and Didier's bred_vectors as IC\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/DA/breed_da\",\n",
      "\"active_disk_no1\":\"no\",\n",
      "\"storage_machine_no2\":\"raijin\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":1,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":1,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"leap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"leap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":4,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"v1_forecast\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing forecast of the recent past/future\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"2yr or 5yr forecasts of months from Feb 2002 to May 2016 using Terry's and Didier's bred_vectors as IC\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin\",\n",
      "\"top_directory_no1\":\"/g/data1/v14/forecast/v1/yr2002/mn2/OUTPUT.1\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"tube-hba\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"no\",\n",
      "\"storage_machine_no3\":\"oa-32-cdc\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"yes\",\n",
      "\"storage_machine_no4\":\"Snapper-as\",\n",
      "\"top_directory_no4\":\"/Volumes/LaCieNo1/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT\",\n",
      "\"active_disk_no4\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":2002,\n",
      "\"yend_max\":2016,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"julian_1fileperyear\",\n",
      "\"monthly_data_layout\":\"julian_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":1,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"True\"\n",
      "},\n",
      "\"v2_forecast\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing forecast of the recent past/future\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"2yr or 5yr forecasts of months from Feb 2002 to May 2016 using Terry's and Didier's bred_vectors as IC\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba\",\n",
      "\"top_directory_no1\":\"/OSM/HBA/OA_DECADAL_CLIMATE/work/DA/breed_da\",\n",
      "\"active_disk_no1\":\"no\",\n",
      "\"storage_machine_no2\":\"raijin\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":1,\n",
      "\"yend_max\":1,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":1,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\", \n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\", \n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":3,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"jan17a\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"pre-industrial control\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"parent_experiment_id\":\"piControl-spinup\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"500-year simulation with restoration of ocean fields below ~2000m.\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no1\":\"/short/v14/lxs599/coupled_model/jan17a/OUTPUT\",\n",
      "\"active_disk_no1\":\"yes\",\n",
      "\"storage_machine_no2\":\"raijin.nci.org.au\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"no\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":395,\n",
      "\"yend_max\":502,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"noleap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"noleap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":8,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "},\n",
      "\"enkf-13\":{\n",
      "\"source_id\":                    \"CAFE-1-0\",\n",
      "\"source\":                       \"CAFE-1-0\",\n",
      "\"experiment\":\"all-forcing forecast of the recent past/future using EnKF\",\n",
      "\"experiment_id\":\"historical\",\n",
      "\"parent_experiment_id\":\"piControl\",\n",
      "\"history\":\"Coupled (ocean-atmosphere-land-ice-seaice) CAFE experiment using GFDL coupled model source code\",\n",
      "\"confluence_notes\":\"2yr or 5yr forecasts of months from Feb 2002 to May 2016 using Terry's and Didier's bred_vectors as IC\",\n",
      "\"reference\":\"None\",\n",
      "\"integration_machine\":\"raijin.nci.org.au\",\n",
      "\"integration_machine_info\":\"Linux raijin4 3.10.0-514.26.1.el6.x86_64 NO1 SMP Fri Jun 30 00:26:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\",\n",
      "\"storage_machine_no1\":\"tube-hba\",\n",
      "\"top_directory_no1\":\"dummy\",\n",
      "\"active_disk_no1\":\"no\",\n",
      "\"storage_machine_no2\":\"raijin\",\n",
      "\"top_directory_no2\":\"/g/data1/v14/forecast/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no2\":\"yes\",\n",
      "\"storage_machine_no3\":\"Snapper-as\",\n",
      "\"top_directory_no3\":\"/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\",\n",
      "\"active_disk_no3\":\"no\",\n",
      "\"main_science_contact\":\"tok599\",\n",
      "\"main_technical_contact\":\"tok599\",\n",
      "\"readable_nexus_ids_no1\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"readable_nexus_ids_no2\":\"tok599,col414,rxm599,mtc599,lxs599,ct8307,dpm599,jsr599,bs8763\",\n",
      "\"writable_nexus_ids\":\"tok599,dpm599\",\n",
      "\"ybeg_min\":2003,\n",
      "\"yend_max\":2009,\n",
      "\"mbeg_min\":1,\n",
      "\"mend_max\":12,\n",
      "\"dbeg_min\":1,\n",
      "\"dend_max\":31,\n",
      "\"daily_data_layout\":\"leap_1fileperyear\",\n",
      "\"monthly_data_layout\":\"leap_1fileperyear\",\n",
      "\"realisation\":\"1\",\n",
      "\"initialisation\":1,\n",
      "\"physics\":9,\n",
      "\"forcing\":1,\n",
      "\"institution\":\"Commonwealth Scientific and Industrial Research Organisation, Australia\",\n",
      "\"institution_id\":\"CSIRO\",\n",
      "\"Forecast\":\"False\"\n",
      "}\n",
      "}\n",
      "\n",
      "Found required output experiment : v1_forecast\n",
      "cafepp: idir= /OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_input_var_fh= {\n",
      "\"defaults\":{\n",
      "\"info\":\"None\", \n",
      "\"area_t\":\"None\",\n",
      "\"area_u\":\"None\"\n",
      "},\n",
      "\"siconc\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"CN\",\n",
      "\"realm\":\"ice\",\n",
      "\"ounits\":\"%\",\n",
      "\"table\":\"SImon,SIday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"aaa_newlevs_type\":\"int\",\n",
      "\"interp_fill_options\":\"griddata_scipy\",\n",
      "\"diagnostic_args_string\":\"100.0,fh_printfile\",\n",
      "\"diagnostic_function_name\":\"siconc\"\n",
      "},\n",
      "\"tos\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"sst\",\n",
      "\"inputs_alternative\":\"temp\", \n",
      "\"realm\":\"ocean\", \n",
      "\"ounits\":\"degC\", \n",
      "\"table\":\"Omon,Oday\", \n",
      "\"table_frequency\":\"month,daily\", \n",
      "\"ovars\":\"dvar\", \n",
      "\"OutputVarStructure\":\"time_lat_lon\", \n",
      "\"positive\":\"None\", \n",
      "\"output_type\":\"broadcast\", \n",
      "\"plev_type\":\"None\", \n",
      "\"lat_lon_type\":\"y_T,x_T\", \n",
      "\"aaa_newlevs_type\":\"int\", \n",
      "\"interp_fill_options\":\"griddata_scipy\"\n",
      "},\n",
      "\"sos\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"0.001\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "},\n",
      "\"tauu\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"tau_x\",\n",
      "\"realm\":\"atmos\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"ounits\":\"Pa\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"down\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"dot_weighting_regrid\"\n",
      "},\n",
      "\"tauv\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"tau_y\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"Pa\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"down\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"dot_weighting_regrid\"\n",
      "},\n",
      "\"nino34\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"sst\", \n",
      "\"inputs_alternative\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"area_t,lat_vals[:],lon_vals[:],fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"int\", \n",
      "\"newlevs\":\"0\"\n",
      "},\n",
      "\"iod\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"sst\", \n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"area_t,lat_vals[:],lon_vals[:],fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"int\", \n",
      "\"newlevs\":\"0\"\n",
      "},\n",
      "\"thetao\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "},\n",
      "\"thetao100m\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reduceddepth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"grid\":\"Upper 100m of ocean only\",\n",
      "\"grid_label\":\"gn100m\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"aaa_newlevs_type\":\"int\",\n",
      "\"newlevs\":\"0,1,2,3,4,5,6,7,8,9\"\n",
      "},\n",
      "\"so\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"0.001\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "},\n",
      "\"psl\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"slp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"Pa\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"up\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"diagnostic_args_string\":\"100.0,fh_printfile\",\n",
      "\"diagnostic_function_name\":\"psl\"\n",
      "},\n",
      "\"ts\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"t_surf\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\"\n",
      "},\n",
      "\"zg500\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"h500\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"up\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\"\n",
      "},\n",
      "\"zg\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"h\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"phalf\"\n",
      "},\n",
      "\"zg5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"hght,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"phalf\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\", \n",
      "\"plevN\":\"plev5\",\n",
      "\"grid\":\"3D vars use plev5\",\n",
      "\"grid_label\":\"gn5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\"\n",
      "},\n",
      "\"ta\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_plev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\"\n",
      "},\n",
      "\"ta5m\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"int\", \n",
      "\"newlevs\":\"0,1,2,3,4\", \n",
      "\"grid\":\"3D vars use 5 model levels\",\n",
      "\"grid_label\":\"gn5m\",\n",
      "\"plevN\":\"plev5m\"\n",
      "},\n",
      "\"ta5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\", \n",
      "\"plevN\":\"plev5\",\n",
      "\"grid\":\"3D vars use plev5\",\n",
      "\"grid_label\":\"gn5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\"\n",
      "},\n",
      "\"ta10\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"100000., 85000., 70000., 50000., 25000., 15000., 10000., 7000., 5000., 1000.\",\n",
      "\"plevN\":\"plev10\",\n",
      "\"grid\":\"3D vars use plev10\",\n",
      "\"grid_label\":\"gn10\",\n",
      "\"vertical_interpolation_method\":\"log_linear\"\n",
      "},\n",
      "\"ta17\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"100000.,92500.,85000.,70000.,60000.,50000.,40000.,30000.,25000.,20000.,15000.,10000.,7000.,5000.,3000.,2000.,1000.\",\n",
      "\"plevN\":\"plev17\",\n",
      "\"grid\":\"3D vars use plev17\",\n",
      "\"grid_label\":\"gn17\",\n",
      "\"vertical_interpolation_method\":\"log_linear\"\n",
      "},\n",
      "\"ta19\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"100000.,92500.,85000.,70000.,60000.,50000.,40000.,30000.,25000.,20000.,15000.,10000.,7000.,5000.,3000.,2000.,1000.,500.,100.\",\n",
      "\"plevN\":\"plev19\",\n",
      "\"grid\":\"3D vars use plev19\",\n",
      "\"grid_label\":\"gn19\",\n",
      "\"vertical_interpolation_method\":\"log_linear\"\n",
      "},\n",
      "\"ua\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m/sec\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\"\n",
      "},\n",
      "\"ua5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m/sec\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\", \n",
      "\"plevN\":\"plev5\",\n",
      "\"grid\":\"3D vars use plev5\",\n",
      "\"grid_label\":\"gn5\",\n",
      "\"vertical_interpolation_method\":\"linear\"\n",
      "},\n",
      "\"va\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"vcomp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m/sec\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\"\n",
      "},\n",
      "\"va5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"vcomp,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m/sec\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\", \n",
      "\"plevN\":\"plev5\",\n",
      "\"grid\":\"3D vars use plev5\",\n",
      "\"grid_label\":\"gn5\",\n",
      "\"vertical_interpolation_method\":\"linear\"\n",
      "},\n",
      "\"hus\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"sphum\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"1.0\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\"\n",
      "},\n",
      "\"hus5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"sphum,ps\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"1.0\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\", \n",
      "\"plevN\":\"plev5\",\n",
      "\"grid\":\"3D vars use plev5\",\n",
      "\"grid_label\":\"gn5\",\n",
      "\"vertical_interpolation_method\":\"pressure_cubed\"\n",
      "},\n",
      "\"huss\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"q_ref\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"1.0\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"None\"\n",
      "},\n",
      "\"hfss\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"shflx\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"W m-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\"\n",
      "},\n",
      "\"rlut\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"olr\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"W m-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\"\n",
      "},\n",
      "\"sfcWind\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"wind\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m s-1\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"None\"\n",
      "},\n",
      "\"tas\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"t_ref\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"K\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\" \n",
      "},\n",
      "\"hfls\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"shflx\", \n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"W m-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\",\n",
      "\"comment\":\"Converted from evap using 28.9, assuming latent heat of vaporization of 2.5 MJ/kg\"\n",
      "},\n",
      "\"uas\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"uas\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m s-1\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"None\"\n",
      "},\n",
      "\"vas\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"vas\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"m s-1\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"None\"\n",
      "},\n",
      "\"mlotst\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"mld\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"mlotstsq\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"mld_sq\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m2\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "},\n",
      "\"umo\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"tx_trans\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg s-1\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_C\"\n",
      "},\n",
      "\"vmo\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"ty_trans\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg s-1\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_C,x_T\"\n",
      "},\n",
      "\"zos\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"eta_t\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "},\n",
      "\"rlus\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"lwup_sfc\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"W m-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\"\n",
      "},\n",
      "\"dummy\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"lwup_sfc\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"W m-2\",\n",
      "\"table\":\"Amon\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\"\n",
      "},\n",
      "\"t16d\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"zt[:],16.0\",\n",
      "\"diagnostic_function_name\":\"isothetaoNc\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"t20d\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"zt[:],20.0\",\n",
      "\"diagnostic_function_name\":\"isothetaoNc\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"t22d\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"zt[:],22.0\",\n",
      "\"diagnostic_function_name\":\"isothetaoNc\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"northsalttrans\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"salt,v\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg/sec\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"ds_02_22_T,area_t,nlats,nlons,zt[:],z0[:],zb[:],10000.\", \n",
      "\"diagnostic_function_name\":\"north_heat_trans\"\n",
      "},\n",
      "\"northheattrans\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,v\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"Joule/sec\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"ds_02_22_T,area_t,nlats,nlons,zt[:],z0[:],zb[:],10000.\", \n",
      "\"diagnostic_function_name\":\"north_heat_trans\"\n",
      "},\n",
      "\"dTbydz\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC/m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:]\",\n",
      "\"diagnostic_function_name\":\"dTbydz\"\n",
      "},\n",
      "\"maxdTbydz\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC/m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:]\",\n",
      "\"diagnostic_function_name\":\"maxdTbydz\"\n",
      "},\n",
      "\"depmaxdTbydz\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:]\",\n",
      "\"diagnostic_function_name\":\"depmaxdTbydz\"\n",
      "},\n",
      "\"thetaot\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"3000., 0., 6000.\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"thetaot300\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"150., 0., 300.\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"thetaot700\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"350., 0., 700.\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"thetaot2000\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"1000., 0., 1000.\",\n",
      "\"interp_fill_options\":\"griddata_scipy,apply_ls_mask_regrid\"\n",
      "},\n",
      "\"so5l\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"salt\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"0.001\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"5.,10.,20.,30.,55., 0.,7.5,15.5,25.,40., 7.5,15.5,25.,40.,60.\"\n",
      "},\n",
      "\"thetao5l\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"5.,10.,20.,30.,55., 0.,7.5,15.5,25.,40., 7.5,15.5,25.,40.,60.\"\n",
      "},\n",
      "\"thetao10l\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,nzt,zt[:],z0[:],zb[:],nzt_new,zt_new[:],z0_new[:],zb_new[:]\",\n",
      "\"diagnostic_function_name\":\"varNl\",\n",
      "\"zt0b_new\":\"500.,1500.,2500.,3500.,4500., 0.,1000.,2000.,3000.,4000., 1000.,2000.,3000.,4000.,5000.\"\n",
      "},\n",
      "\"thetao0to80m\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,zt[:],z0[:],zb[:]\",\n",
      "\"diagnostic_function_name\":\"thetao0to80m\"\n",
      "},\n",
      "\"heatcontent\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"Joule\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"area_t,nlats,nlons,zt[:],z0[:],zb[:],10000.\", \n",
      "\"diagnostic_function_name\":\"heat_content\"\n",
      "},\n",
      "\"saltcontent\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"salt\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"area_t,nlats,nlons,zt[:],z0[:],zb[:],10000.\", \n",
      "\"diagnostic_function_name\":\"salt_content\"\n",
      "},\n",
      "\"heatcontent700m\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"Joule\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,zt[:],z0[:],zb[:],700.\",\n",
      "\"diagnostic_function_name\":\"heat_content\"\n",
      "},\n",
      "\"heatcontent2000m\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp\",\n",
      "\"inputs_alternative\":\"None\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"Joule\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"diagnostic_args_string\":\"nlats,nlons,zt[:],z0[:],zb[:],2000.\",\n",
      "\"diagnostic_function_name\":\"heat_content\"\n",
      "},\n",
      "\"rws500\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"comment\":\"Using model level 9 (base 0) which is 533.hPa and therefore not exactly 500hPa.\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"int\",\n",
      "\"newlevs\":\"9\"\n",
      "},\n",
      "\"rws\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_plev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],outputs_string,fh_printfile\"\n",
      "},\n",
      "\"rws5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp,ps\",\n",
      "\"inputs_shape\":\"time_plev_lat_lon,time_plev_lat_lon,time_lat_lon\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],outputs_string,fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\",\n",
      "\"plevN\":\"plev5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\",\n",
      "\"diagnostic_function_name\":\"rws5\",\n",
      "\"outputs_string\":\"rws5,div5,eta5,uchi5,vchi5\",\n",
      "\"outputs_units_string\":\"s-2,s-1,s-1,ms-1,ms-1\"\n",
      "},\n",
      "\"div5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp,ps\",\n",
      "\"inputs_shape\":\"time_plev_lat_lon,time_plev_lat_lon,time_lat_lon\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],outputs_string,fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\",\n",
      "\"plevN\":\"plev5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\",\n",
      "\"diagnostic_function_name\":\"rws5\",\n",
      "\"outputs_string\":\"rws5,div5,eta5,uchi5,vchi5\",\n",
      "\"outputs_units_string\":\"s-2,s-1,s-1,ms-1,ms-1\"\n",
      "},\n",
      "\"eta5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp,ps\",\n",
      "\"inputs_shape\":\"time_plev_lat_lon,time_plev_lat_lon,time_lat_lon\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],outputs_string,fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\",\n",
      "\"plevN\":\"plev5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\",\n",
      "\"diagnostic_function_name\":\"rws5\",\n",
      "\"outputs_string\":\"rws5,div5,eta5,uchi5,vchi5\",\n",
      "\"outputs_units_string\":\"s-2,s-1,s-1,ms-1,ms-1\"\n",
      "},\n",
      "\"uchi5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp,ps\",\n",
      "\"inputs_shape\":\"time_plev_lat_lon,time_plev_lat_lon,time_lat_lon\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],outputs_string,fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\",\n",
      "\"plevN\":\"plev5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\",\n",
      "\"diagnostic_function_name\":\"rws5\",\n",
      "\"outputs_string\":\"rws5,div5,eta5,uchi5,vchi5\",\n",
      "\"outputs_units_string\":\"s-2,s-1,s-1,ms-1,ms-1\"\n",
      "},\n",
      "\"vchi5\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"ucomp,vcomp,ps\",\n",
      "\"inputs_shape\":\"time_plev_lat_lon,time_plev_lat_lon,time_lat_lon\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"s-2\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_reducedplev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"pfull\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],outputs_string,fh_printfile\",\n",
      "\"aaa_newlevs_type\":\"float\",\n",
      "\"newlevs\":\"92500.,85000.,70000.,50000.,30000.\",\n",
      "\"plevN\":\"plev5\",\n",
      "\"vertical_interpolation_method\":\"log_linear\",\n",
      "\"diagnostic_function_name\":\"rws5\",\n",
      "\"outputs_string\":\"rws5,div5,eta5,uchi5,vchi5\",\n",
      "\"outputs_units_string\":\"s-2,s-1,s-1,ms-1,ms-1\"\n",
      "},\n",
      "\"mfo\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"tx_trans,ty_trans\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg s-1\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_oline\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"mfo\",\n",
      "\"diagnostic_args_string\":\"nlines,fh_printfile\"\n",
      "},\n",
      "\"nhbi\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"h500\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"1.0\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"nhblocking_index\",\n",
      "\"diagnostic_args_string\":\"lat_vals[:],lon_vals[:],fh_printfile\",\n",
      "\"outputs_string\":\"nhbi,GHGS,GHGN\",\n",
      "\"outputs_units_string\":\"1.0,1.0,1.0\"\n",
      "},\n",
      "\"volcello\":{\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m3\",\n",
      "\"table\":\"fx\",\n",
      "\"table_frequency\":\"month\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\", \n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"volcello\",\n",
      "\"diagnostic_args_string\":\"area_t,zt,z,nlats,nlons,fh_printfile\"\n",
      "},\n",
      "\"thkcello\":{\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m3\",\n",
      "\"table\":\"fx\",\n",
      "\"table_frequency\":\"month\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\", \n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"thkcello\",\n",
      "\"diagnostic_args_string\":\"z,nlats,nlons,fh_printfile\"\n",
      "},\n",
      "\"areacello\":{\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m3\",\n",
      "\"table\":\"fx\",\n",
      "\"table_frequency\":\"month\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\", \n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"areacello\",\n",
      "\"diagnostic_args_string\":\"area_t,fh_printfile\"\n",
      "},\n",
      "\"sftof\":{\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m3\",\n",
      "\"table\":\"fx\",\n",
      "\"table_frequency\":\"month\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\", \n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"sftof\",\n",
      "\"diagnostic_args_string\":\"wet,fh_printfile\"\n",
      "},\n",
      "\"deptho\":{\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"temp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m3\",\n",
      "\"table\":\"fx\",\n",
      "\"table_frequency\":\"month\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\", \n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"deptho\",\n",
      "\"diagnostic_args_string\":\"z,nlats,nlons,fh_printfile\"\n",
      "},\n",
      "\"msftyz\":{ \n",
      "\"inputs\":\"ty_trans,ty_trans_gm\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg s-1\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_basin_depth_lat\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"msftyz\", \n",
      "\"diagnostic_args_string\":\"atlantic_arctic_mask,indoPac_mask,global_mask,nbasins,nzb,nlats\",\n",
      "\"define_basin_mask\":\"True\"\n",
      "},\n",
      "\"cl\":{\n",
      "\"info\":\"None\",\n",
      "\"inputs\":\"cld_amt\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"%\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_plev_lat_lon\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"cl\",\n",
      "\"diagnostic_args_string\":\"None,None\", \n",
      "\"plev_type\":\"pfull\"\n",
      "},\n",
      "\"pr\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"False\",\n",
      "\"inputs\":\"precip\",\n",
      "\"realm\":\"atmos\",\n",
      "\"ounits\":\"kg m-2 s-1\",\n",
      "\"table\":\"Amon,day\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"output_type\":\"broadcast\",\n",
      "\"plev_type\":\"None\",\n",
      "\"positive\":\"up\", \n",
      "\"interp_fill_options\":\"dot_weighting_regrid\"\n",
      "},\n",
      "\"zmld_boyer\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,nlats,nlons,fh_printfile\"\n",
      "},\n",
      "\"zmld_so\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"m\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,nlats,nlons,fh_printfile\"\n",
      "},\n",
      "\"spice\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"1.0\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,nlats,nlons,fh_printfile\",\n",
      "\"comment\":\"used function diag_spice in decadal_diag.py\"\n",
      "},\n",
      "\"spiciness\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"1.0\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,lat_vals,lon_vals_360,nlats,nlons,fh_printfile\",\n",
      "\"comment\":\"used function diag_spiciness in decadal_diag.py\"\n",
      "},\n",
      "\"bigthetao\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"degC\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,lat_vals,lon_vals_360,nlats,nlons,fh_printfile\",\n",
      "\"comment\":\"\"\n",
      "},\n",
      "\"soabs\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"g/kg\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"lat_lon_type\":\"y_T,x_T\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,lat_vals,lon_vals_360,nlats,nlons,fh_printfile\",\n",
      "\"comment\":\"\"\n",
      "},\n",
      "\"potrho\":{\n",
      "\"info\":\"None\",\n",
      "\"area_t\":\"True\",\n",
      "\"inputs\":\"temp,salt\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg m-3\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_depth_lat_lon\",\n",
      "\"positive\":\"None\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"plev_type\":\"None\",\n",
      "\"interp_fill_options\":\"poisson_fill,dot_weighting_regrid,apply_ls_mask_regrid\",\n",
      "\"diagnostic_args_string\":\"zt,lat_vals,lon_vals_360,nlats,nlons,fh_printfile\",\n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "},\n",
      "\"msftyz_old\":{\n",
      "\"inputs\":\"ty_trans,ty_trans_gm\",\n",
      "\"info\":\"None\",\n",
      "\"inputs\":\"ucomp,ucomp\",\n",
      "\"realm\":\"ocean\",\n",
      "\"ounits\":\"kg s-1\",\n",
      "\"table\":\"Omon,Oday\",\n",
      "\"table_frequency\":\"month,daily\",\n",
      "\"ovars\":\"dvar\",\n",
      "\"OutputVarStructure\":\"time_basin_depth_lat\",\n",
      "\"output_type\":\"diagnostic\",\n",
      "\"diagnostic_function_name\":\"msftyyz\",\n",
      "\"diagnostic_args_string\":\"atlantic_arctic_mask,indoPac_mask,global_mask,nbasins,nzb,nlats\",\n",
      "\"define_basin_mask\":\"True\",\n",
      "\"dummy_shape\":\"1,50,300,360\", \n",
      "\"dummy_dimensions\":\"time, st_ocean, yt_ocean, xt_ocean\", \n",
      "\"lat_lon_type\":\"y_T,x_T\"\n",
      "}\n",
      "}\n",
      "\n",
      "Found required output variable: ['msftyz']\n",
      "OutputVarStructure\n",
      "define_basin_mask\n",
      "diagnostic_args_string\n",
      "diagnostic_function_name\n",
      "inputs\n",
      "ounits\n",
      "output_type\n",
      "ovars\n",
      "realm\n",
      "table\n",
      "table_frequency\n",
      "printDefinedDiagnostics= False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['msftyz']\n",
      "('Number of original/new input files=', 6, 6)\n",
      "('self.input_files=', ['/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1/ocean_month_2003_01.nc', '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1/ocean_month_2004_01.nc', '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1/ocean_month_2005_01.nc', '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1/ocean_month_2006_01.nc', '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1/ocean_month_2007_01.nc', '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2003/mn1/OUTPUT.1/ocean_month_2008_01.nc'])\n",
      "('Found season definition', 'MON', ' in self.season_map with indices ', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], ' file:ProcTime line number: 253')\n",
      "('self.time.shape=', (72,))\n",
      "('self.time=', <class 'netCDF4._netCDF4._Variable'>\n",
      "float64 time('time',)\n",
      "    long_name: time\n",
      "    units: days since 0001-01-01 00:00:00\n",
      "    cartesian_axis: T\n",
      "    calendar_type: JULIAN\n",
      "    calendar: JULIAN\n",
      "    bounds: time_bounds\n",
      "unlimited dimensions = ('time',)\n",
      "current size = (72,)\n",
      ")\n",
      "('self.timegrad=', array([ 29.5 ,  29.5 ,  30.  ,  30.5 ,  30.5 ,  30.5 ,  30.75,  30.75,\n",
      "        30.5 ,  30.5 ,  30.5 ,  30.75,  30.5 ,  30.  ,  30.25,  30.5 ,\n",
      "        30.5 ,  30.5 ,  30.75,  30.75,  30.5 ,  30.5 ,  30.5 ,  30.75,\n",
      "        30.25,  29.5 ,  30.  ,  30.5 ,  30.5 ,  30.5 ,  30.75,  30.75,\n",
      "        30.5 ,  30.5 ,  30.5 ,  30.75,  30.25,  29.5 ,  30.  ,  30.5 ,\n",
      "        30.5 ,  30.5 ,  30.75,  30.75,  30.5 ,  30.5 ,  30.5 ,  30.75,\n",
      "        30.25,  29.5 ,  30.  ,  30.5 ,  30.5 ,  30.5 ,  30.75,  30.75,\n",
      "        30.5 ,  30.5 ,  30.5 ,  30.75,  30.5 ,  30.  ,  30.25,  30.5 ,\n",
      "        30.5 ,  30.5 ,  30.75,  30.75,  30.5 ,  30.5 ,  30.5 ,  30.5 ]))\n",
      "('check_days=', (array([], dtype=int64),))\n",
      "deleting process ranges...\n",
      "('self.ybeg_min,self.yend_max,self.mbeg_min,self.mend_max,self.ybeg_season_min=', 2003, 2008, 1, 12, 2003)\n",
      "('self.ybeg_season_process,self.yend_season_process,self.mbeg_season_process,self.mend_season_process=', 2003, 2008, 1, 12)\n",
      "END of STEP1\n",
      "('self.ybeg_min,self.yend_max,self.mbeg_min,self.mend_max,self.ybeg_season_min=', 2003, 2008, 1, 12, 2003)\n",
      "('self.ybeg_season_process,self.yend_season_process,self.mbeg_season_process,self.mend_season_process=', 2003, 2008, 1, 12)\n",
      "Here we are broadcasting, for MON will print out all available months unless mbeg_season_process,mend_season_process defined otherwies.\n",
      "('self.broadcast=', True)\n",
      "('season=', 'MON')\n",
      "Special case, print out all months unless restricted by mbeg_season_process,mend_season_process.\n",
      "('self.ybeg_season_process,self.yend_season_process,self.mbeg_season_process,self.mend_season_process=', 2003, 2008, 1, 12)\n",
      "('_lll=', array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0]))\n",
      "('_lll=', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 2]))\n",
      "('_begpos,_endpos=', 0, 71)\n",
      "('self.years_defined=', [2003, 2004, 2005, 2006, 2007, 2008])\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 0, 2003, 1, 1)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 1, 2003, 2, 2)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 2, 2003, 3, 3)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 3, 2003, 4, 4)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 4, 2003, 5, 5)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 5, 2003, 6, 6)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 6, 2003, 7, 7)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 7, 2003, 8, 8)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 8, 2003, 9, 9)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 9, 2003, 10, 10)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 10, 2003, 11, 11)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 11, 2003, 12, 12)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 12, 2004, 1, 13)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 13, 2004, 2, 14)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 14, 2004, 3, 15)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 15, 2004, 4, 16)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 16, 2004, 5, 17)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 17, 2004, 6, 18)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 18, 2004, 7, 19)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 19, 2004, 8, 20)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 20, 2004, 9, 21)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 21, 2004, 10, 22)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 22, 2004, 11, 23)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 23, 2004, 12, 24)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 24, 2005, 1, 25)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 25, 2005, 2, 26)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 26, 2005, 3, 27)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 27, 2005, 4, 28)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 28, 2005, 5, 29)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 29, 2005, 6, 30)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 30, 2005, 7, 31)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 31, 2005, 8, 32)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 32, 2005, 9, 33)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 33, 2005, 10, 34)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 34, 2005, 11, 35)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 35, 2005, 12, 36)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 36, 2006, 1, 37)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 37, 2006, 2, 38)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 38, 2006, 3, 39)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 39, 2006, 4, 40)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 40, 2006, 5, 41)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 41, 2006, 6, 42)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 42, 2006, 7, 43)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 43, 2006, 8, 44)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 44, 2006, 9, 45)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 45, 2006, 10, 46)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 46, 2006, 11, 47)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 47, 2006, 12, 48)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 48, 2007, 1, 49)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 49, 2007, 2, 50)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 50, 2007, 3, 51)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 51, 2007, 4, 52)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 52, 2007, 5, 53)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 53, 2007, 6, 54)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 54, 2007, 7, 55)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 55, 2007, 8, 56)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 56, 2007, 9, 57)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 57, 2007, 10, 58)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 58, 2007, 11, 59)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 59, 2007, 12, 60)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 60, 2008, 1, 61)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 61, 2008, 2, 62)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 62, 2008, 3, 63)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 63, 2008, 4, 64)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 64, 2008, 5, 65)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 65, 2008, 6, 66)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 66, 2008, 7, 67)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 67, 2008, 8, 68)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 68, 2008, 9, 69)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 69, 2008, 10, 70)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 70, 2008, 11, 71)\n",
      "('_iii,self.npyears[_ppp],self.npmonths[_ppp],self.MonfromStart[_ppp]', 71, 2008, 12, 72)\n",
      "('self.season_indices_defined (#6) =', [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]])\n",
      "('self.season_month_indices_defined (#6) =', [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]])\n",
      "('self.years_defined (#6) =', [2003, 2004, 2005, 2006, 2007, 2008])\n",
      "('self.month_indices=', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
      " So now we could loop over years_defined, each vector of season_indices_defined can be used then be used to broadcast/average.\n",
      "END of STEP2\n",
      "('_i,_year,self.values,self.values2=', 0, 2003, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
      "('_i,_year,self.values,self.values2=', 1, 2004, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n",
      "('_i,_year,self.values,self.values2=', 2, 2005, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36])\n",
      "('_i,_year,self.values,self.values2=', 3, 2006, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48])\n",
      "('_i,_year,self.values,self.values2=', 4, 2007, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60])\n",
      "('_i,_year,self.values,self.values2=', 5, 2008, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72])\n",
      "END of STEP3\n",
      "('self.firstvalue=', 0)\n",
      "('self.npvalues=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('self.npvalues2=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 0, 2003, 1)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 1, 2003, 2)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 2, 2003, 3)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 3, 2003, 4)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 4, 2003, 5)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 5, 2003, 6)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 6, 2003, 7)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 7, 2003, 8)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 8, 2003, 9)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 9, 2003, 10)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 10, 2003, 11)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 11, 2003, 12)\n",
      "('self.firstvalue=', 0)\n",
      "('self.npvalues=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('self.npvalues2=', array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]))\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 0, 2004, 1)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 1, 2004, 2)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 2, 2004, 3)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 3, 2004, 4)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 4, 2004, 5)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 5, 2004, 6)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 6, 2004, 7)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 7, 2004, 8)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 8, 2004, 9)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 9, 2004, 10)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 10, 2004, 11)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 11, 2004, 12)\n",
      "('self.firstvalue=', 0)\n",
      "('self.npvalues=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('self.npvalues2=', array([24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]))\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 0, 2005, 1)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 1, 2005, 2)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 2, 2005, 3)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 3, 2005, 4)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 4, 2005, 5)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 5, 2005, 6)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 6, 2005, 7)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 7, 2005, 8)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 8, 2005, 9)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 9, 2005, 10)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 10, 2005, 11)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 11, 2005, 12)\n",
      "('self.firstvalue=', 0)\n",
      "('self.npvalues=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('self.npvalues2=', array([36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]))\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 0, 2006, 1)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 1, 2006, 2)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 2, 2006, 3)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 3, 2006, 4)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 4, 2006, 5)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 5, 2006, 6)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 6, 2006, 7)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 7, 2006, 8)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 8, 2006, 9)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 9, 2006, 10)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 10, 2006, 11)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 11, 2006, 12)\n",
      "('self.firstvalue=', 0)\n",
      "('self.npvalues=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('self.npvalues2=', array([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]))\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 0, 2007, 1)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 1, 2007, 2)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 2, 2007, 3)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 3, 2007, 4)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 4, 2007, 5)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 5, 2007, 6)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 6, 2007, 7)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 7, 2007, 8)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 8, 2007, 9)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 9, 2007, 10)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 10, 2007, 11)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 11, 2007, 12)\n",
      "('self.firstvalue=', 0)\n",
      "('self.npvalues=', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "('self.npvalues2=', array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]))\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 0, 2008, 1)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 1, 2008, 2)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 2, 2008, 3)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 3, 2008, 4)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 4, 2008, 5)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 5, 2008, 6)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 6, 2008, 7)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 7, 2008, 8)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 8, 2008, 9)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 9, 2008, 10)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 10, 2008, 11)\n",
      "('_j,self.npyear,self.npmonths[self.npvalues2][_j]=', 11, 2008, 12)\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 0, datetime.datetime(2003, 1, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 1, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2003, 2, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 1, datetime.datetime(2003, 2, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 2, 15, 0, 0, 0, 0, -1, 1), datetime.datetime(2003, 3, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 2, datetime.datetime(2003, 3, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 3, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2003, 4, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 3, datetime.datetime(2003, 4, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 4, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2003, 5, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 4, datetime.datetime(2003, 5, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 5, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2003, 6, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 5, datetime.datetime(2003, 6, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 6, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2003, 7, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 6, datetime.datetime(2003, 7, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 7, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2003, 8, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 7, datetime.datetime(2003, 8, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 8, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2003, 9, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 8, datetime.datetime(2003, 9, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 9, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2003, 10, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 9, datetime.datetime(2003, 10, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 10, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2003, 11, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 10, datetime.datetime(2003, 11, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 11, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2003, 12, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 11, datetime.datetime(2003, 12, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2003, 12, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 1, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 12, datetime.datetime(2004, 1, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 1, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 2, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 13, datetime.datetime(2004, 2, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 2, 15, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 3, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 14, datetime.datetime(2004, 3, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 3, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 4, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 15, datetime.datetime(2004, 4, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 4, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2004, 5, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 16, datetime.datetime(2004, 5, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 5, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 6, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 17, datetime.datetime(2004, 6, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 6, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2004, 7, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 18, datetime.datetime(2004, 7, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 7, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 8, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 19, datetime.datetime(2004, 8, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 8, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 9, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 20, datetime.datetime(2004, 9, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 9, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2004, 10, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 21, datetime.datetime(2004, 10, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 10, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2004, 11, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 22, datetime.datetime(2004, 11, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 11, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2004, 12, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 23, datetime.datetime(2004, 12, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2004, 12, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 1, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 24, datetime.datetime(2005, 1, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 1, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 2, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 25, datetime.datetime(2005, 2, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 2, 15, 0, 0, 0, 0, -1, 1), datetime.datetime(2005, 3, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 26, datetime.datetime(2005, 3, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 3, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 4, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 27, datetime.datetime(2005, 4, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 4, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2005, 5, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 28, datetime.datetime(2005, 5, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 5, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 6, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 29, datetime.datetime(2005, 6, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 6, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2005, 7, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 30, datetime.datetime(2005, 7, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 7, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 8, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 31, datetime.datetime(2005, 8, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 8, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 9, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 32, datetime.datetime(2005, 9, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 9, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2005, 10, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 33, datetime.datetime(2005, 10, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 10, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2005, 11, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 34, datetime.datetime(2005, 11, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 11, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2005, 12, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 35, datetime.datetime(2005, 12, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2005, 12, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 1, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 36, datetime.datetime(2006, 1, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 1, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 2, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 37, datetime.datetime(2006, 2, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 2, 15, 0, 0, 0, 0, -1, 1), datetime.datetime(2006, 3, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 38, datetime.datetime(2006, 3, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 3, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 4, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 39, datetime.datetime(2006, 4, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 4, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2006, 5, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 40, datetime.datetime(2006, 5, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 5, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 6, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 41, datetime.datetime(2006, 6, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 6, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2006, 7, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 42, datetime.datetime(2006, 7, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 7, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 8, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 43, datetime.datetime(2006, 8, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 8, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 9, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 44, datetime.datetime(2006, 9, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 9, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2006, 10, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 45, datetime.datetime(2006, 10, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 10, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2006, 11, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 46, datetime.datetime(2006, 11, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 11, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2006, 12, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 47, datetime.datetime(2006, 12, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2006, 12, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 1, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 48, datetime.datetime(2007, 1, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 1, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 2, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 49, datetime.datetime(2007, 2, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 2, 15, 0, 0, 0, 0, -1, 1), datetime.datetime(2007, 3, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 50, datetime.datetime(2007, 3, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 3, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 4, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 51, datetime.datetime(2007, 4, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 4, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2007, 5, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 52, datetime.datetime(2007, 5, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 5, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 6, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 53, datetime.datetime(2007, 6, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 6, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2007, 7, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 54, datetime.datetime(2007, 7, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 7, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 8, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 55, datetime.datetime(2007, 8, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 8, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 9, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 56, datetime.datetime(2007, 9, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 9, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2007, 10, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 57, datetime.datetime(2007, 10, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 10, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2007, 11, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 58, datetime.datetime(2007, 11, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 11, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2007, 12, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 59, datetime.datetime(2007, 12, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2007, 12, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 1, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 60, datetime.datetime(2008, 1, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 1, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 2, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 61, datetime.datetime(2008, 2, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 2, 15, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 3, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 62, datetime.datetime(2008, 3, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 3, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 4, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 63, datetime.datetime(2008, 4, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 4, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2008, 5, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 64, datetime.datetime(2008, 5, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 5, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 6, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 65, datetime.datetime(2008, 6, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 6, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2008, 7, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 66, datetime.datetime(2008, 7, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 7, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 8, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 67, datetime.datetime(2008, 8, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 8, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 9, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 68, datetime.datetime(2008, 9, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 9, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2008, 10, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 69, datetime.datetime(2008, 10, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 10, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2008, 11, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 70, datetime.datetime(2008, 11, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 11, 16, 0, 0, 0, 0, -1, 1), datetime.datetime(2008, 12, 1, 0, 0))\n",
      "('_dummyi,self.time_stamp_beg,avg,end=', 71, datetime.datetime(2008, 12, 1, 0, 0), netcdftime._netcdftime.DatetimeJulian(2008, 12, 16, 12, 0, 0, 0, -1, 1), datetime.datetime(2009, 1, 1, 0, 0))\n",
      "END of STEP4\n",
      "ProcTimeN.time_units= days since 0001-01-01 00:00:00\n",
      "var_size= (12, 50, 300, 360)\n",
      "var_dims= (u'time', u'st_ocean', u'yu_ocean', u'xt_ocean')\n",
      "levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "lon_vals= [-279. -278. -277. -276. -275. -274. -273. -272. -271. -270. -269. -268.\n",
      " -267. -266. -265. -264. -263. -262. -261. -260. -259. -258. -257. -256.\n",
      " -255. -254. -253. -252. -251. -250. -249. -248. -247. -246. -245. -244.\n",
      " -243. -242. -241. -240. -239. -238. -237. -236. -235. -234. -233. -232.\n",
      " -231. -230. -229. -228. -227. -226. -225. -224. -223. -222. -221. -220.\n",
      " -219. -218. -217. -216. -215. -214. -213. -212. -211. -210. -209. -208.\n",
      " -207. -206. -205. -204. -203. -202. -201. -200. -199. -198. -197. -196.\n",
      " -195. -194. -193. -192. -191. -190. -189. -188. -187. -186. -185. -184.\n",
      " -183. -182. -181. -180. -179. -178. -177. -176. -175. -174. -173. -172.\n",
      " -171. -170. -169. -168. -167. -166. -165. -164. -163. -162. -161. -160.\n",
      " -159. -158. -157. -156. -155. -154. -153. -152. -151. -150. -149. -148.\n",
      " -147. -146. -145. -144. -143. -142. -141. -140. -139. -138. -137. -136.\n",
      " -135. -134. -133. -132. -131. -130. -129. -128. -127. -126. -125. -124.\n",
      " -123. -122. -121. -120. -119. -118. -117. -116. -115. -114. -113. -112.\n",
      " -111. -110. -109. -108. -107. -106. -105. -104. -103. -102. -101. -100.\n",
      "  -99.  -98.  -97.  -96.  -95.  -94.  -93.  -92.  -91.  -90.  -89.  -88.\n",
      "  -87.  -86.  -85.  -84.  -83.  -82.  -81.  -80.  -79.  -78.  -77.  -76.\n",
      "  -75.  -74.  -73.  -72.  -71.  -70.  -69.  -68.  -67.  -66.  -65.  -64.\n",
      "  -63.  -62.  -61.  -60.  -59.  -58.  -57.  -56.  -55.  -54.  -53.  -52.\n",
      "  -51.  -50.  -49.  -48.  -47.  -46.  -45.  -44.  -43.  -42.  -41.  -40.\n",
      "  -39.  -38.  -37.  -36.  -35.  -34.  -33.  -32.  -31.  -30.  -29.  -28.\n",
      "  -27.  -26.  -25.  -24.  -23.  -22.  -21.  -20.  -19.  -18.  -17.  -16.\n",
      "  -15.  -14.  -13.  -12.  -11.  -10.   -9.   -8.   -7.   -6.   -5.   -4.\n",
      "   -3.   -2.   -1.    0.    1.    2.    3.    4.    5.    6.    7.    8.\n",
      "    9.   10.   11.   12.   13.   14.   15.   16.   17.   18.   19.   20.\n",
      "   21.   22.   23.   24.   25.   26.   27.   28.   29.   30.   31.   32.\n",
      "   33.   34.   35.   36.   37.   38.   39.   40.   41.   42.   43.   44.\n",
      "   45.   46.   47.   48.   49.   50.   51.   52.   53.   54.   55.   56.\n",
      "   57.   58.   59.   60.   61.   62.   63.   64.   65.   66.   67.   68.\n",
      "   69.   70.   71.   72.   73.   74.   75.   76.   77.   78.   79.   80.]\n",
      "time_axis_id= 0\n",
      "basin_axis_id= 1\n",
      "z_axis_id= 2\n",
      "lat_axis_id= 3\n",
      "1\n",
      "72\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12  1  2  3  4  5  6  7  8  9 10 11 12  1\n",
      "  2  3  4  5  6  7  8  9 10 11 12  1  2  3  4  5  6  7  8  9 10 11 12  1  2\n",
      "  3  4  5  6  7  8  9 10 11 12  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "1\n",
      "12\n",
      "yend_ofil= 2008\n",
      "ybeg,yend_ofil= 2003 2008\n",
      "mbeg,mend_ofil= 01 12\n",
      "len(ovars)= 1\n",
      "Output CMIP6 file: CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p1f1/Omon/msftyz/gn/v20171025/msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_200301-200812.nc\n",
      "ProcTimefirstvalue= 0\n",
      "ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "ProcTimenpvalues2= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_ProcTime: ivar= ty_trans\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data_wavg_ProcTime: ivar= ty_trans_gm\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data.shape= (12, 3, 50, 300)\n",
      "ntimes_passed= 12\n",
      "ProcTimennpvalues= 12\n",
      "ProcTimeN.time_bounds= [[ 731230.  731261.]\n",
      " [ 731261.  731289.]\n",
      " [ 731289.  731320.]\n",
      " [ 731320.  731350.]\n",
      " [ 731350.  731381.]\n",
      " [ 731381.  731411.]\n",
      " [ 731411.  731442.]\n",
      " [ 731442.  731473.]\n",
      " [ 731473.  731503.]\n",
      " [ 731503.  731534.]\n",
      " [ 731534.  731564.]\n",
      " [ 731564.  731595.]\n",
      " [ 731595.  731626.]\n",
      " [ 731626.  731655.]\n",
      " [ 731655.  731686.]\n",
      " [ 731686.  731716.]\n",
      " [ 731716.  731747.]\n",
      " [ 731747.  731777.]\n",
      " [ 731777.  731808.]\n",
      " [ 731808.  731839.]\n",
      " [ 731839.  731869.]\n",
      " [ 731869.  731900.]\n",
      " [ 731900.  731930.]\n",
      " [ 731930.  731961.]\n",
      " [ 731961.  731992.]\n",
      " [ 731992.  732020.]\n",
      " [ 732020.  732051.]\n",
      " [ 732051.  732081.]\n",
      " [ 732081.  732112.]\n",
      " [ 732112.  732142.]\n",
      " [ 732142.  732173.]\n",
      " [ 732173.  732204.]\n",
      " [ 732204.  732234.]\n",
      " [ 732234.  732265.]\n",
      " [ 732265.  732295.]\n",
      " [ 732295.  732326.]\n",
      " [ 732326.  732357.]\n",
      " [ 732357.  732385.]\n",
      " [ 732385.  732416.]\n",
      " [ 732416.  732446.]\n",
      " [ 732446.  732477.]\n",
      " [ 732477.  732507.]\n",
      " [ 732507.  732538.]\n",
      " [ 732538.  732569.]\n",
      " [ 732569.  732599.]\n",
      " [ 732599.  732630.]\n",
      " [ 732630.  732660.]\n",
      " [ 732660.  732691.]\n",
      " [ 732691.  732722.]\n",
      " [ 732722.  732750.]\n",
      " [ 732750.  732781.]\n",
      " [ 732781.  732811.]\n",
      " [ 732811.  732842.]\n",
      " [ 732842.  732872.]\n",
      " [ 732872.  732903.]\n",
      " [ 732903.  732934.]\n",
      " [ 732934.  732964.]\n",
      " [ 732964.  732995.]\n",
      " [ 732995.  733025.]\n",
      " [ 733025.  733056.]\n",
      " [ 733056.  733087.]\n",
      " [ 733087.  733116.]\n",
      " [ 733116.  733147.]\n",
      " [ 733147.  733177.]\n",
      " [ 733177.  733208.]\n",
      " [ 733208.  733238.]\n",
      " [ 733238.  733269.]\n",
      " [ 733269.  733300.]\n",
      " [ 733300.  733330.]\n",
      " [ 733330.  733361.]\n",
      " [ 733361.  733391.]\n",
      " [ 733391.  733422.]]\n",
      "ProcTimeN.time_bounds[ProcTimennpvalues]= [ 731595.  731626.]\n",
      "ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "ProcTimenpvalues2= [12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "data_wavg_ProcTime: ivar= ty_trans\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data_wavg_ProcTime: ivar= ty_trans_gm\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data.shape= (12, 3, 50, 300)\n",
      "ntimes_passed= 12\n",
      "ProcTimennpvalues= 12\n",
      "ProcTimeN.time_bounds= [[ 731230.  731261.]\n",
      " [ 731261.  731289.]\n",
      " [ 731289.  731320.]\n",
      " [ 731320.  731350.]\n",
      " [ 731350.  731381.]\n",
      " [ 731381.  731411.]\n",
      " [ 731411.  731442.]\n",
      " [ 731442.  731473.]\n",
      " [ 731473.  731503.]\n",
      " [ 731503.  731534.]\n",
      " [ 731534.  731564.]\n",
      " [ 731564.  731595.]\n",
      " [ 731595.  731626.]\n",
      " [ 731626.  731655.]\n",
      " [ 731655.  731686.]\n",
      " [ 731686.  731716.]\n",
      " [ 731716.  731747.]\n",
      " [ 731747.  731777.]\n",
      " [ 731777.  731808.]\n",
      " [ 731808.  731839.]\n",
      " [ 731839.  731869.]\n",
      " [ 731869.  731900.]\n",
      " [ 731900.  731930.]\n",
      " [ 731930.  731961.]\n",
      " [ 731961.  731992.]\n",
      " [ 731992.  732020.]\n",
      " [ 732020.  732051.]\n",
      " [ 732051.  732081.]\n",
      " [ 732081.  732112.]\n",
      " [ 732112.  732142.]\n",
      " [ 732142.  732173.]\n",
      " [ 732173.  732204.]\n",
      " [ 732204.  732234.]\n",
      " [ 732234.  732265.]\n",
      " [ 732265.  732295.]\n",
      " [ 732295.  732326.]\n",
      " [ 732326.  732357.]\n",
      " [ 732357.  732385.]\n",
      " [ 732385.  732416.]\n",
      " [ 732416.  732446.]\n",
      " [ 732446.  732477.]\n",
      " [ 732477.  732507.]\n",
      " [ 732507.  732538.]\n",
      " [ 732538.  732569.]\n",
      " [ 732569.  732599.]\n",
      " [ 732599.  732630.]\n",
      " [ 732630.  732660.]\n",
      " [ 732660.  732691.]\n",
      " [ 732691.  732722.]\n",
      " [ 732722.  732750.]\n",
      " [ 732750.  732781.]\n",
      " [ 732781.  732811.]\n",
      " [ 732811.  732842.]\n",
      " [ 732842.  732872.]\n",
      " [ 732872.  732903.]\n",
      " [ 732903.  732934.]\n",
      " [ 732934.  732964.]\n",
      " [ 732964.  732995.]\n",
      " [ 732995.  733025.]\n",
      " [ 733025.  733056.]\n",
      " [ 733056.  733087.]\n",
      " [ 733087.  733116.]\n",
      " [ 733116.  733147.]\n",
      " [ 733147.  733177.]\n",
      " [ 733177.  733208.]\n",
      " [ 733208.  733238.]\n",
      " [ 733238.  733269.]\n",
      " [ 733269.  733300.]\n",
      " [ 733300.  733330.]\n",
      " [ 733330.  733361.]\n",
      " [ 733361.  733391.]\n",
      " [ 733391.  733422.]]\n",
      "ProcTimeN.time_bounds[ProcTimennpvalues]= [ 731595.  731626.]\n",
      "ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "ProcTimenpvalues2= [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "data_wavg_ProcTime: ivar= ty_trans\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data_wavg_ProcTime: ivar= ty_trans_gm\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data.shape= (12, 3, 50, 300)\n",
      "ntimes_passed= 12\n",
      "ProcTimennpvalues= 12\n",
      "ProcTimeN.time_bounds= [[ 731230.  731261.]\n",
      " [ 731261.  731289.]\n",
      " [ 731289.  731320.]\n",
      " [ 731320.  731350.]\n",
      " [ 731350.  731381.]\n",
      " [ 731381.  731411.]\n",
      " [ 731411.  731442.]\n",
      " [ 731442.  731473.]\n",
      " [ 731473.  731503.]\n",
      " [ 731503.  731534.]\n",
      " [ 731534.  731564.]\n",
      " [ 731564.  731595.]\n",
      " [ 731595.  731626.]\n",
      " [ 731626.  731655.]\n",
      " [ 731655.  731686.]\n",
      " [ 731686.  731716.]\n",
      " [ 731716.  731747.]\n",
      " [ 731747.  731777.]\n",
      " [ 731777.  731808.]\n",
      " [ 731808.  731839.]\n",
      " [ 731839.  731869.]\n",
      " [ 731869.  731900.]\n",
      " [ 731900.  731930.]\n",
      " [ 731930.  731961.]\n",
      " [ 731961.  731992.]\n",
      " [ 731992.  732020.]\n",
      " [ 732020.  732051.]\n",
      " [ 732051.  732081.]\n",
      " [ 732081.  732112.]\n",
      " [ 732112.  732142.]\n",
      " [ 732142.  732173.]\n",
      " [ 732173.  732204.]\n",
      " [ 732204.  732234.]\n",
      " [ 732234.  732265.]\n",
      " [ 732265.  732295.]\n",
      " [ 732295.  732326.]\n",
      " [ 732326.  732357.]\n",
      " [ 732357.  732385.]\n",
      " [ 732385.  732416.]\n",
      " [ 732416.  732446.]\n",
      " [ 732446.  732477.]\n",
      " [ 732477.  732507.]\n",
      " [ 732507.  732538.]\n",
      " [ 732538.  732569.]\n",
      " [ 732569.  732599.]\n",
      " [ 732599.  732630.]\n",
      " [ 732630.  732660.]\n",
      " [ 732660.  732691.]\n",
      " [ 732691.  732722.]\n",
      " [ 732722.  732750.]\n",
      " [ 732750.  732781.]\n",
      " [ 732781.  732811.]\n",
      " [ 732811.  732842.]\n",
      " [ 732842.  732872.]\n",
      " [ 732872.  732903.]\n",
      " [ 732903.  732934.]\n",
      " [ 732934.  732964.]\n",
      " [ 732964.  732995.]\n",
      " [ 732995.  733025.]\n",
      " [ 733025.  733056.]\n",
      " [ 733056.  733087.]\n",
      " [ 733087.  733116.]\n",
      " [ 733116.  733147.]\n",
      " [ 733147.  733177.]\n",
      " [ 733177.  733208.]\n",
      " [ 733208.  733238.]\n",
      " [ 733238.  733269.]\n",
      " [ 733269.  733300.]\n",
      " [ 733300.  733330.]\n",
      " [ 733330.  733361.]\n",
      " [ 733361.  733391.]\n",
      " [ 733391.  733422.]]\n",
      "ProcTimeN.time_bounds[ProcTimennpvalues]= [ 731595.  731626.]\n",
      "ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "ProcTimenpvalues2= [36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "data_wavg_ProcTime: ivar= ty_trans\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_wavg_ProcTime: ivar= ty_trans_gm\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data.shape= (12, 3, 50, 300)\n",
      "ntimes_passed= 12\n",
      "ProcTimennpvalues= 12\n",
      "ProcTimeN.time_bounds= [[ 731230.  731261.]\n",
      " [ 731261.  731289.]\n",
      " [ 731289.  731320.]\n",
      " [ 731320.  731350.]\n",
      " [ 731350.  731381.]\n",
      " [ 731381.  731411.]\n",
      " [ 731411.  731442.]\n",
      " [ 731442.  731473.]\n",
      " [ 731473.  731503.]\n",
      " [ 731503.  731534.]\n",
      " [ 731534.  731564.]\n",
      " [ 731564.  731595.]\n",
      " [ 731595.  731626.]\n",
      " [ 731626.  731655.]\n",
      " [ 731655.  731686.]\n",
      " [ 731686.  731716.]\n",
      " [ 731716.  731747.]\n",
      " [ 731747.  731777.]\n",
      " [ 731777.  731808.]\n",
      " [ 731808.  731839.]\n",
      " [ 731839.  731869.]\n",
      " [ 731869.  731900.]\n",
      " [ 731900.  731930.]\n",
      " [ 731930.  731961.]\n",
      " [ 731961.  731992.]\n",
      " [ 731992.  732020.]\n",
      " [ 732020.  732051.]\n",
      " [ 732051.  732081.]\n",
      " [ 732081.  732112.]\n",
      " [ 732112.  732142.]\n",
      " [ 732142.  732173.]\n",
      " [ 732173.  732204.]\n",
      " [ 732204.  732234.]\n",
      " [ 732234.  732265.]\n",
      " [ 732265.  732295.]\n",
      " [ 732295.  732326.]\n",
      " [ 732326.  732357.]\n",
      " [ 732357.  732385.]\n",
      " [ 732385.  732416.]\n",
      " [ 732416.  732446.]\n",
      " [ 732446.  732477.]\n",
      " [ 732477.  732507.]\n",
      " [ 732507.  732538.]\n",
      " [ 732538.  732569.]\n",
      " [ 732569.  732599.]\n",
      " [ 732599.  732630.]\n",
      " [ 732630.  732660.]\n",
      " [ 732660.  732691.]\n",
      " [ 732691.  732722.]\n",
      " [ 732722.  732750.]\n",
      " [ 732750.  732781.]\n",
      " [ 732781.  732811.]\n",
      " [ 732811.  732842.]\n",
      " [ 732842.  732872.]\n",
      " [ 732872.  732903.]\n",
      " [ 732903.  732934.]\n",
      " [ 732934.  732964.]\n",
      " [ 732964.  732995.]\n",
      " [ 732995.  733025.]\n",
      " [ 733025.  733056.]\n",
      " [ 733056.  733087.]\n",
      " [ 733087.  733116.]\n",
      " [ 733116.  733147.]\n",
      " [ 733147.  733177.]\n",
      " [ 733177.  733208.]\n",
      " [ 733208.  733238.]\n",
      " [ 733238.  733269.]\n",
      " [ 733269.  733300.]\n",
      " [ 733300.  733330.]\n",
      " [ 733330.  733361.]\n",
      " [ 733361.  733391.]\n",
      " [ 733391.  733422.]]\n",
      "ProcTimeN.time_bounds[ProcTimennpvalues]= [ 731595.  731626.]\n",
      "ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "ProcTimenpvalues2= [48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "data_wavg_ProcTime: ivar= ty_trans\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data_wavg_ProcTime: ivar= ty_trans_gm\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data.shape= (12, 3, 50, 300)\n",
      "ntimes_passed= 12\n",
      "ProcTimennpvalues= 12\n",
      "ProcTimeN.time_bounds= [[ 731230.  731261.]\n",
      " [ 731261.  731289.]\n",
      " [ 731289.  731320.]\n",
      " [ 731320.  731350.]\n",
      " [ 731350.  731381.]\n",
      " [ 731381.  731411.]\n",
      " [ 731411.  731442.]\n",
      " [ 731442.  731473.]\n",
      " [ 731473.  731503.]\n",
      " [ 731503.  731534.]\n",
      " [ 731534.  731564.]\n",
      " [ 731564.  731595.]\n",
      " [ 731595.  731626.]\n",
      " [ 731626.  731655.]\n",
      " [ 731655.  731686.]\n",
      " [ 731686.  731716.]\n",
      " [ 731716.  731747.]\n",
      " [ 731747.  731777.]\n",
      " [ 731777.  731808.]\n",
      " [ 731808.  731839.]\n",
      " [ 731839.  731869.]\n",
      " [ 731869.  731900.]\n",
      " [ 731900.  731930.]\n",
      " [ 731930.  731961.]\n",
      " [ 731961.  731992.]\n",
      " [ 731992.  732020.]\n",
      " [ 732020.  732051.]\n",
      " [ 732051.  732081.]\n",
      " [ 732081.  732112.]\n",
      " [ 732112.  732142.]\n",
      " [ 732142.  732173.]\n",
      " [ 732173.  732204.]\n",
      " [ 732204.  732234.]\n",
      " [ 732234.  732265.]\n",
      " [ 732265.  732295.]\n",
      " [ 732295.  732326.]\n",
      " [ 732326.  732357.]\n",
      " [ 732357.  732385.]\n",
      " [ 732385.  732416.]\n",
      " [ 732416.  732446.]\n",
      " [ 732446.  732477.]\n",
      " [ 732477.  732507.]\n",
      " [ 732507.  732538.]\n",
      " [ 732538.  732569.]\n",
      " [ 732569.  732599.]\n",
      " [ 732599.  732630.]\n",
      " [ 732630.  732660.]\n",
      " [ 732660.  732691.]\n",
      " [ 732691.  732722.]\n",
      " [ 732722.  732750.]\n",
      " [ 732750.  732781.]\n",
      " [ 732781.  732811.]\n",
      " [ 732811.  732842.]\n",
      " [ 732842.  732872.]\n",
      " [ 732872.  732903.]\n",
      " [ 732903.  732934.]\n",
      " [ 732934.  732964.]\n",
      " [ 732964.  732995.]\n",
      " [ 732995.  733025.]\n",
      " [ 733025.  733056.]\n",
      " [ 733056.  733087.]\n",
      " [ 733087.  733116.]\n",
      " [ 733116.  733147.]\n",
      " [ 733147.  733177.]\n",
      " [ 733177.  733208.]\n",
      " [ 733208.  733238.]\n",
      " [ 733238.  733269.]\n",
      " [ 733269.  733300.]\n",
      " [ 733300.  733330.]\n",
      " [ 733330.  733361.]\n",
      " [ 733361.  733391.]\n",
      " [ 733391.  733422.]]\n",
      "ProcTimeN.time_bounds[ProcTimennpvalues]= [ 731595.  731626.]\n",
      "ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "ProcTimenpvalues2= [60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "data_wavg_ProcTime: ivar= ty_trans\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data_wavg_ProcTime: ivar= ty_trans_gm\n",
      "data_wavg_Proctime:ProcTimenpvalues= [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "data_wavg_Proctime:ProcTimenpvalues2= [60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "data_wavg_Proctime:data.shape= (12, 50, 300, 360)\n",
      "data_wavg_Proctime:levels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "data.shape= (12, 3, 50, 300)\n",
      "ntimes_passed= 12\n",
      "ProcTimennpvalues= 12\n",
      "ProcTimeN.time_bounds= [[ 731230.  731261.]\n",
      " [ 731261.  731289.]\n",
      " [ 731289.  731320.]\n",
      " [ 731320.  731350.]\n",
      " [ 731350.  731381.]\n",
      " [ 731381.  731411.]\n",
      " [ 731411.  731442.]\n",
      " [ 731442.  731473.]\n",
      " [ 731473.  731503.]\n",
      " [ 731503.  731534.]\n",
      " [ 731534.  731564.]\n",
      " [ 731564.  731595.]\n",
      " [ 731595.  731626.]\n",
      " [ 731626.  731655.]\n",
      " [ 731655.  731686.]\n",
      " [ 731686.  731716.]\n",
      " [ 731716.  731747.]\n",
      " [ 731747.  731777.]\n",
      " [ 731777.  731808.]\n",
      " [ 731808.  731839.]\n",
      " [ 731839.  731869.]\n",
      " [ 731869.  731900.]\n",
      " [ 731900.  731930.]\n",
      " [ 731930.  731961.]\n",
      " [ 731961.  731992.]\n",
      " [ 731992.  732020.]\n",
      " [ 732020.  732051.]\n",
      " [ 732051.  732081.]\n",
      " [ 732081.  732112.]\n",
      " [ 732112.  732142.]\n",
      " [ 732142.  732173.]\n",
      " [ 732173.  732204.]\n",
      " [ 732204.  732234.]\n",
      " [ 732234.  732265.]\n",
      " [ 732265.  732295.]\n",
      " [ 732295.  732326.]\n",
      " [ 732326.  732357.]\n",
      " [ 732357.  732385.]\n",
      " [ 732385.  732416.]\n",
      " [ 732416.  732446.]\n",
      " [ 732446.  732477.]\n",
      " [ 732477.  732507.]\n",
      " [ 732507.  732538.]\n",
      " [ 732538.  732569.]\n",
      " [ 732569.  732599.]\n",
      " [ 732599.  732630.]\n",
      " [ 732630.  732660.]\n",
      " [ 732660.  732691.]\n",
      " [ 732691.  732722.]\n",
      " [ 732722.  732750.]\n",
      " [ 732750.  732781.]\n",
      " [ 732781.  732811.]\n",
      " [ 732811.  732842.]\n",
      " [ 732842.  732872.]\n",
      " [ 732872.  732903.]\n",
      " [ 732903.  732934.]\n",
      " [ 732934.  732964.]\n",
      " [ 732964.  732995.]\n",
      " [ 732995.  733025.]\n",
      " [ 733025.  733056.]\n",
      " [ 733056.  733087.]\n",
      " [ 733087.  733116.]\n",
      " [ 733116.  733147.]\n",
      " [ 733147.  733177.]\n",
      " [ 733177.  733208.]\n",
      " [ 733208.  733238.]\n",
      " [ 733238.  733269.]\n",
      " [ 733269.  733300.]\n",
      " [ 733300.  733330.]\n",
      " [ 733330.  733361.]\n",
      " [ 733361.  733391.]\n",
      " [ 733391.  733422.]]\n",
      "ProcTimeN.time_bounds[ProcTimennpvalues]= [ 731595.  731626.]\n",
      "ovars= ['msftyz']\n",
      "o= 0\n",
      "file_name= CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p1f1/Omon/msftyz/gn/v20171025/msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_200301-200812.nc\n",
      "['msftyz', 'Omon', 'historical', 'CAFE-1-0', 'r1i1p1f1', 'gn', '200301-200812.nc']\n",
      "['200301-200812', '']\n",
      "['200301', '200812']\n",
      "ybeg,yend,mbeg,mend= 2003 2008 01 02\n",
      "<type 'list'>\n",
      "msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_2003-2008_MON.nc\n",
      "file_name:  CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p1f1/Omon/msftyz/gn/v20171025/msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_200301-200812.nc\n",
      "odir:  CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p1f1/Omon/msftyz/gn/v20171025\n",
      "ofil:  msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_200301-200812.nc\n",
      "ofil_modified:  msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_200301-200812.nc\n",
      "season:  MON\n",
      "broadcast:  True\n",
      "Will need to put in \"importance flag\", perhaps it can go in another standard metadata tag?\n",
      "Will need to move this CMIP6 file to slightly different name to clearly specify that it is a special season where the time axis is not continguous.\n",
      "Output:  CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p1f1/Omon/msftyz/gn/v20171025/msftyz_Omon_historical_CAFE-1-0_r1i1p1f1_gn_200301-200812.nc\n",
      "Finished O.K.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Forced exit file:cafepp_monthly_forecast.py line number: 143",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Forced exit file:cafepp_monthly_forecast.py line number: 143\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "#from importlib import reload\n",
    "#import importlib\n",
    "#print(dir(importlib))\n",
    "#cafepp_monthly_forecast=importlib.import_module(cafepp_monthly_forecast)\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "  #print('prodir=',prodir)\n",
    "  \n",
    "  dvar='tos'\n",
    "  dvar='msftyz'\n",
    "\n",
    "  cafe_experiment='v1_forecast'\n",
    "  ybeg=2003\n",
    "  yend=2003\n",
    "  mbeg=1\n",
    "  mend=12\n",
    "  ybeg_first=2002\n",
    "  yend_last=2016\n",
    "  mbeg_first=2\n",
    "  mend_last=5\n",
    "  ebeg=1\n",
    "  eend=1\n",
    "\n",
    "  line_kwargs='rundir='+rundir+' dvar='+dvar+' cafe_experiment='+cafe_experiment+ \\\n",
    "    ' ybeg='+str(ybeg)+' yend='+str(yend)+' mbeg='+str(mbeg)+' mend='+str(mend)+ \\\n",
    "    ' ybeg_first='+str(ybeg_first)+' yend_last='+str(yend_last)+ \\\n",
    "    ' mbeg_first='+str(mbeg_first)+' mend_last='+str(mend_last)+ \\\n",
    "    ' ebeg='+str(ebeg)+' eend='+str(eend)  \n",
    "  \n",
    "  if(script=='cafepp_monthly_forecast.py'):\n",
    "\n",
    "    if(BATCH):\n",
    "      os.chmod(script,500)\n",
    "      \n",
    "      print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "      ifh=open(prodir+'/'+'qjob.csh')\n",
    "      ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "      for i,line in enumerate(ifh):\n",
    "        line=line.replace('CAFEPP_SCRIPT','./'+script+' '+line_kwargs)\n",
    "        line=line.replace('RUNDIR',rundir)\n",
    "        line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "        line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "        print(line,file=ofh,end='')\n",
    "      ifh.close()\n",
    "      ofh.close()\n",
    "      \n",
    "      os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "    else:\n",
    "      print('Current Working Directory=',os.getcwd())\n",
    "      os.chdir(rundir)\n",
    "      \n",
    "      kwargs=dict(x.split('=', 1) for x in line_kwargs.split(' '))\n",
    "      cafepp_monthly_forecast.main(**kwargs)\n",
    "  \n",
    "#      cafepp_monthly_forecast.main(rundir, dvar=dvar, cafe_experiment='v1_forecast', \\\n",
    "#        ybeg=2002, yend=2016, mbeg=1, mend=12, \\\n",
    "#        ybeg_first=2002, yend_last=2016, mbeg_first=2, mend_last=5, \\\n",
    "#        ebeg=1, eend=11)\n",
    "    \n",
    "#      cafepp_monthly_forecast.main(rundir, dvar=dvar, cafe_experiment=cafe_experiment, \\\n",
    "#        ybeg=2015, yend=2015, mbeg=1, mend=1, \\\n",
    "#        ybeg_first=2002, yend_last=2016, mbeg_first=2, mend_last=5, \\\n",
    "#        ebeg=1, eend=11)  \n",
    "  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "#SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "  \n",
    "  import math\n",
    "  os.chdir(rundir)\n",
    "\n",
    "  colors=['black','red','green','blue','orange','brown','purple','pink']\n",
    "  \n",
    "  #forc_nens=11\n",
    "  grid_label='gr2'\n",
    "  grid_label='gn'\n",
    "  forc_files_stringA='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-9]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-9]i1p1f1_'+grid_label+'_2011??-??????.nc'\n",
    "  forc_files_stringB='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-9]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-9]i1p1f1_'+grid_label+'_2012??-??????.nc'\n",
    "  forc_files_stringC='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-9]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-9]i1p1f1_'+grid_label+'_2013??-??????.nc'\n",
    "  forc_files_stringD='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-9]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-9]i1p1f1_'+grid_label+'_2014??-??????.nc'\n",
    "\n",
    "  forc_files_stringA=''\n",
    "  forc_files_stringD=''\n",
    "\n",
    "  forc_files=sorted(restrict_input_files(glob.glob(forc_files_stringA)+glob.glob(forc_files_stringB)+glob.glob(forc_files_stringC)+glob.glob(forc_files_stringD),24,72)) #later want to split these into different ensembles. Will assume same input files for all valid ensembles.\n",
    "\n",
    "  nforc_files=len(forc_files)\n",
    "  print('forc_files[0]=',forc_files[0])\n",
    "  #print('forc input_files ('+str(nforc_files)+') =',forc_files)\n",
    "\n",
    "  datetime_all,datetime_uniq,ripf_all,ripf_uniq=file_spec_summary(forc_files,True)\n",
    "\n",
    "  #raise Exception('STOP!')\n",
    "print('END.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 46,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 3. Here we are processing uninitialised control experiment, set script='cafepp_monthly_control.py' above\n",
    "\n",
    "Either submit it to the queue or run interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# turn off scrolling on output cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%javascript\n",
    "#IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "#    return false;\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 42,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "SWITCH_OFF=False\n",
    "\n",
    "cafe_experiment='v0'\n",
    "#cafe_experiment='v1'\n",
    "#cafe_experiment='v2'\n",
    "#cafe_experiment='v3'\n",
    "\n",
    "#cafe_experiment='v0' #t_surf in atmos_month_*nc files.\n",
    "ybeg=491\n",
    "yend=500\n",
    "mbeg=1\n",
    "mend=12\n",
    "\n",
    "#dvar='so'\n",
    "#dvar='thetao'\n",
    "#dvar='tos'\n",
    "#dvar='tas'\n",
    "#dvar='siconc'\n",
    "dvar='msftyz' #was called msftyyz\n",
    "\n",
    "NoClobber=True #do not clobber\n",
    "NoClobber=False #clobber\n",
    "\n",
    "line_kwargs='NoClobber='+str(NoClobber)+' rundir='+rundir+' dvar='+dvar+' cafe_experiment='+cafe_experiment+ \\\n",
    "  ' ybeg='+str(ybeg)+' yend='+str(yend)+' mbeg='+str(mbeg)+' mend='+str(mend)\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "  \n",
    "  print('prodir=',prodir)\n",
    "  \n",
    "  if(script=='cafepp_monthly_control.py'):\n",
    "    if(BATCH):\n",
    "      os.chmod(script,500)\n",
    "    \n",
    "      print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "      ifh=open(prodir+'/'+'qjob.csh')\n",
    "      ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "      for i,line in enumerate(ifh):\n",
    "        line=line.replace('CAFEPP_SCRIPT','./'+script+' '+line_kwargs)\n",
    "        line=line.replace('RUNDIR',rundir)\n",
    "        line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "        line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "        print(line,file=ofh,end='')\n",
    "      ifh.close()\n",
    "      ofh.close()\n",
    "  \n",
    "      os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "    else:\n",
    "      print('Current Working Directory=',os.getcwd())\n",
    "      os.chdir(rundir)\n",
    "\n",
    "      kwargs=dict(x.split('=', 1) for x in line_kwargs.split(' '))\n",
    "      cafepp_monthly_control.main(**kwargs)\n",
    "  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raise Exception('STOP!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 42,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Process/Plot control run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 24,
        "hidden": false,
        "row": 50,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "pval=5\n",
    "#pval=1\n",
    "\n",
    "run='historial'\n",
    "run='piControl'\n",
    "\n",
    "cont_files=['CMIP6/CMIP/CSIRO/CAFE-1-0/'+run+'/r1i1p'+str(pval)+'f1/Omon/tos/gn/v20171025/tos_Omon_'+run+'_CAFE-1-0_r1i1p'+str(pval)+'f1_gn_009101-010012.nc', \\\n",
    "            'CMIP6/CMIP/CSIRO/CAFE-1-0/'+run+'/r1i1p'+str(pval)+'f1/Omon/tos/gn/v20171025/tos_Omon_'+run+'_CAFE-1-0_r1i1p'+str(pval)+'f1_gn_019101-020012.nc', \\\n",
    "            'CMIP6/CMIP/CSIRO/CAFE-1-0/'+run+'/r1i1p'+str(pval)+'f1/Omon/tos/gn/v20171025/tos_Omon_'+run+'_CAFE-1-0_r1i1p'+str(pval)+'f1_gn_029101-030012.nc', \\\n",
    "            'CMIP6/CMIP/CSIRO/CAFE-1-0/'+run+'/r1i1p'+str(pval)+'f1/Omon/tos/gn/v20171025/tos_Omon_'+run+'_CAFE-1-0_r1i1p'+str(pval)+'f1_gn_039101-040012.nc', \\\n",
    "            'CMIP6/CMIP/CSIRO/CAFE-1-0/'+run+'/r1i1p'+str(pval)+'f1/Omon/tos/gn/v20171025/tos_Omon_'+run+'_CAFE-1-0_r1i1p'+str(pval)+'f1_gn_049101-050012.nc']\n",
    "\n",
    "#cont_files=cont_files[0:2]\n",
    "\n",
    "cont_nexps=len(cont_files)\n",
    "\n",
    "for cont_cnt,cont_file in enumerate(cont_files):\n",
    "  \n",
    "  print('cont input file=',cont_file)\n",
    "\n",
    "  cont_ifh=netCDF4.Dataset(cont_file)\n",
    "\n",
    "  cont_lat=cont_ifh.variables['latitude'][:,0]\n",
    "  cont_lon=cont_ifh.variables['longitude'][0,:]\n",
    "\n",
    "  #forc_clat=np.zeros((nforc_files),dtype=float) #if latitude range changes will need to have custom clat.\n",
    "  cont_clat=np.cos(cont_lat[:]*rad)\n",
    "\n",
    "  cont_time=cont_ifh.variables['time']\n",
    "\n",
    "  cont_date_time_stamp=netCDF4.num2date(cont_time[:],cont_time.units,cont_time.calendar)\n",
    "\n",
    "  cont_ntime=len(cont_time)\n",
    "\n",
    "  '''\n",
    "  print('date_time_stamp=',date_time_stamp)\n",
    "  num_stamp=netCDF4.date2num(date_time_stamp,time.units,time.calendar)\n",
    "  print('num_stamp=',num_stamp)\n",
    "  print('year_fraction=',year_fraction)\n",
    "  '''\n",
    "  \n",
    "  if(cont_cnt==0):\n",
    "    cont_year_fraction_monthly=ma.zeros((cont_ntime,cont_nexps),dtype=float)\n",
    "    cont_nino_monthly=ma.zeros((cont_ntime,nindices_nino,cont_nexps),dtype=float)    \n",
    "  cont_year_fraction_monthly[:,cont_cnt]=fractional_year_from_num2date(cont_date_time_stamp,cont_time.calendar)\n",
    "\n",
    "  #print('type(cont_date_time_stamp)=',type(cont_date_time_stamp))\n",
    "  #print('cont_date_time_stamp=',cont_date_time_stamp)\n",
    "\n",
    "  #raise Exception('STOP!')\n",
    "  for cont_k,indice in enumerate(indices_nino):\n",
    "    #cont_k=indices_nino.index(indice)\n",
    "    cont_imin,cont_imax=indices_i_gn[indices_nino.index(indice)][0],indices_i_gn[indices_nino.index(indice)][1]\n",
    "    cont_jmin,cont_jmax=indices_j_gn[indices_nino.index(indice)][0],indices_j_gn[indices_nino.index(indice)][1]\n",
    "    #print('indices.index(indice),cont_imin,cont_imax,cont_jmin,cont_jmax=',indices.index(indice),cont_imin,cont_imax,cont_jmin,cont_jmax)\n",
    "    #print('cont_lat,cont_lon=',cont_lat[cont_jmin:cont_jmax],cont_lon[cont_imin:cont_imax])\n",
    "\n",
    "    cont_nino_monthly[:,cont_k,cont_cnt]=np.average(np.average(cont_ifh.variables[dvar][:,cont_jmin:cont_jmax,cont_imin:cont_imax],axis=1,weights=cont_clat[cont_jmin:cont_jmax]),axis=1)\n",
    "  cont_ifh.close()\n",
    "  #indices_i_gn,indices_j_gn=[[122,152],[122,152],[122,152]],[[110,160],[110,160],[110,160]] #check this, whether I need +1 also...\n",
    "  #raise Exception('STOP!')\n",
    "  #print('cont_year_fraction=',cont_year_fraction_monthly)\n",
    "\n",
    "  %matplotlib inline\n",
    "\n",
    "  fix,ax=plt.subplots()\n",
    "  for cont_k,indice in enumerate(indices_nino):\n",
    "    ax.plot(cont_year_fraction_monthly[:,cont_cnt],cont_nino_monthly[:,indices_nino.index(indice),cont_cnt],label=indices_label[indices_nino.index(indices_nino[cont_k])])\n",
    "  legend=ax.legend(loc='lower right',shadow=False,fontsize='x-large')\n",
    "  plt.title('Monthly values (CONTROL run)')\n",
    "  plt.xlabel('Year')\n",
    "  plt.ylabel('$^o$C')\n",
    "  #plt.show()\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "  cont_ybeg=cont_date_time_stamp[0].year\n",
    "  cont_yend=cont_date_time_stamp[-1].year\n",
    "\n",
    "  cont_ydiff=cont_yend-cont_ybeg+1\n",
    "  nmy=12\n",
    "\n",
    "  cont_MissingMonths=False\n",
    "\n",
    "  cont_first_month=cont_date_time_stamp[0].month\n",
    "  cont_last_month=cont_date_time_stamp[-1].month\n",
    "\n",
    "  cont_missing_months_beg,cont_missing_months_end=0,0\n",
    "\n",
    "  cont_cyear_beg_skip,cont_cyear_end_skip=0,1\n",
    "\n",
    "  if(cont_first_month!=1):\n",
    "    cont_missing_months_beg=12-cont_first_month\n",
    "    cont_cyear_beg_skip=1\n",
    "    cont_MissingMonths=True\n",
    "\n",
    "  if(cont_last_month!=12):\n",
    "    cont_missing_months_end=12-cont_last_month\n",
    "    cont_cyear_end_skip=2\n",
    "    cont_MissingMonths=True\n",
    "  \n",
    "  if(cont_MissingMonths):\n",
    "    print('There are missing months in the set. '+str(cont_missing_months_beg)+' at beginning and '+str(cont_missing_months_end)+' at end.')\n",
    "    print('Currently years with missing months are not used in generating long term monthly climatology.')\n",
    "    print('And missing months will be set to missing in the final time-series.')\n",
    "    cont_ts_beg,cont_ts_end,cont_ts_avg,cont_dt_beg,cont_dt_end,cont_dt_avg=get_timestamp_number(cont_ybeg,cont_yend,1,12,cont_time.units,cont_time.calendar)\n",
    "    cont_year_fraction_monthly_full=cont_fractional_year_from_num2date(cont_ts_avg,cont_time.calendar)\n",
    "  \n",
    "    cont_nino_monthly_full=ma.masked_all(nindices_nino,cont_ydiff*nmy,dtype=float) #ensure missing months are masked out.\n",
    "    cont_last_month_index=cont_ydiff*nmy-cont_last_month\n",
    "    cont_nino_monthly_full[cont_first_month-1:cont_last_month_index,:]=cont_nino_monthly\n",
    "  else:\n",
    "    print('All years have 12 months.')\n",
    "  \n",
    "    cont_nino_monthly_full=cont_nino_monthly\n",
    "    cont_year_fraction_monthly_full=cont_year_fraction_monthly\n",
    "    \n",
    "#print('cont_nino_monthly_full.shape=',cont_nino_monthly_full.shape)\n",
    "\n",
    "cont_nino_climatology,cont_nino_monthly_anomaly = calculate_monthly_climatology_anomaly_from_monthly(cont_nino_monthly_full)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "for plot_this_exp,cont_file in enumerate(cont_files):\n",
    "  cont_zero=np.zeros(len(cont_year_fraction_monthly_full[:,plot_this_exp]))\n",
    "  fix,ax=plt.subplots()\n",
    "  for cont_k,indice in enumerate(indices_nino):\n",
    "    ax.plot(cont_year_fraction_monthly_full[:,plot_this_exp],cont_nino_monthly_anomaly[:,cont_k,plot_this_exp],label=indices_label[indices_nino.index(indices_nino[cont_k])])\n",
    "  plt.plot(cont_year_fraction_monthly_full[:,plot_this_exp],cont_zero,color='black')\n",
    "\n",
    "  legend=ax.legend(loc='lower right',shadow=False,fontsize='x-large')\n",
    "  plt.title('Monthly anomalies (CONTROL run)')\n",
    "  plt.xlabel('Year')\n",
    "  plt.ylabel('$^o$C')\n",
    "  plt.show()\n",
    "\n",
    "print('END.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 74,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Now to plot data, this will depend on success of previous steps producing necessary outputs with cafepp. Note that we have data on the native grid, where we can discover the points that are in the nino3.4 region.\n",
    "\n",
    "# Process/Plot forecast run, each forecast is a seperate run.\n",
    "\n",
    "Find minimum and maximum year/month from the set of input files\n",
    "Create a dummy time stamp that spans the entire set\n",
    "Read in data into a multi dimensional array (indice, ensemble, forecast, time)\n",
    "Have a set of indices which describe the beginning and ending of each forecast, for quick retrieval\n",
    "\n",
    "Would like to have anomalies relative to various climatologies, these could include different year periods, experiments to form climatology or even zero climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 12,
        "hidden": false,
        "row": 50,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "import math\n",
    "os.chdir(rundir)\n",
    "\n",
    "colors=['black','red','green','blue','orange','brown','purple','pink']\n",
    "  \n",
    "#forc_nens=11\n",
    "grid_label='gr2'\n",
    "grid_label='gn'\n",
    "forc_files_stringA='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-3]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-3]i1p1f1_'+grid_label+'_2011??-??????.nc'\n",
    "forc_files_stringB='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-3]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-3]i1p1f1_'+grid_label+'_2012??-??????.nc'\n",
    "forc_files_stringC='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-3]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-3]i1p1f1_'+grid_label+'_2013??-??????.nc'\n",
    "forc_files_stringD='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r[1-3]i1p1f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r[1-3]i1p1f1_'+grid_label+'_2014??-??????.nc'\n",
    "\n",
    "forc_files_stringA=''\n",
    "forc_files_stringD=''\n",
    "\n",
    "forc_files=sorted(restrict_input_files(glob.glob(forc_files_stringA)+glob.glob(forc_files_stringB)+glob.glob(forc_files_stringC)+glob.glob(forc_files_stringD),24,72)) #later want to split these into different ensembles. Will assume same input files for all valid ensembles.\n",
    "\n",
    "nforc_files=len(forc_files)\n",
    "print('forc_files[0]=',forc_files[0])\n",
    "#print('forc input_files ('+str(nforc_files)+') =',forc_files)\n",
    "\n",
    "datetime_all,datetime_uniq,ripf_all,ripf_uniq=file_spec_summary(forc_files,False)\n",
    "\n",
    "#print('len(datetime_uniq)=',len(datetime_uniq))\n",
    "#print('len(datetime_all)=',len(datetime_all))\n",
    "#print('len(ripf_uniq)=',len(ripf_uniq))\n",
    "#print('len(ripf_all)=',len(ripf_all))\n",
    "\n",
    "#print(ripf_all)\n",
    "\n",
    "#if(len(datetime_all)!=(len(datetime_uniq)*len(ripf_uniq))):\n",
    "#  print('Possible issue with datetime_uniq,ripf_uniq.')\n",
    "  \n",
    "#if(len(datetime_all)!=len(ripf_all)):\n",
    "#  print('Possible issue with datetime/ripf.')\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "'''for forc_i,forc_input_file in enumerate(forc_files):\n",
    "  print('forc_i,forc_input_file=',forc_i,forc_input_file)\n",
    "\n",
    "  forc_input_file_tail=os.path.basename(forc_input_file)\n",
    "  forc_var,forc_table,forc_experiment,forc_model,forc_ripf,forc_grid,forc_datetime=cmor_file_parts(forc_input_file_tail)\n",
    "  forc_rval,forc_ival,forc_pval,forc_fval=cmor_ripf_parts(forc_ripf)\n",
    "  forc_input_file_head=string.split(forc_input_file,sep=forc_input_file_tail)[0]\n",
    "  forc_version,forc_grid,forc_var,forc_table,forc_ripf,forc_experiment,forc_model,forc_institution,forc_activity,forc_cmip=cmor_directory_parts(forc_input_file_head)\n",
    "\n",
    "  #print('forc_input_file_tail=',forc_input_file_tail)\n",
    "  #print('forc_input_file_head=',forc_input_file_head)\n",
    "\n",
    "  #print('forc_var,forc_table,forc_experiment,forc_model,forc_ripf,forc_grid,forc_datetime=',forc_var,forc_table,forc_experiment,forc_model,forc_ripf,forc_grid,forc_datetime)\n",
    "  \n",
    "  #raise Exception('STOP!')\n",
    "  #print('forc_version,forc_grid,forc_var,forc_table,forc_ripf,forc_experiment,forc_model,forc_institution,forc_activity,forc_cmip=',forc_version,forc_grid,forc_var,forc_table,forc_ripf,forc_experiment,forc_model,forc_institution,forc_activity,forc_cmip)\n",
    "  \n",
    "  #print('forc_ripf=',forc_ripf)\n",
    "  #print('forc_rval,forc_ival,forc_pval,forc_fval',forc_rval,forc_ival,forc_pval,forc_fval)\n",
    "  \n",
    "  #raise Exception('STOP!')'''\n",
    "  \n",
    "#raise Exception('STOP!')\n",
    "\n",
    "forc_ens=[]\n",
    "forc_ifhs=[]\n",
    "forc_date_time_stamps=[]\n",
    "forc_times=[]\n",
    "forc_mins=[]\n",
    "forc_maxs=[]\n",
    "for forc_i,forc_input_file in enumerate(forc_files):\n",
    "  #print('forc_i,forc_input_file=',forc_i,forc_input_file)\n",
    "  forc_input_file_tail=os.path.basename(forc_input_file)\n",
    "  forc_input_file_head=string.split(forc_input_file,sep=forc_input_file_tail)[0]\n",
    "  forc_var,forc_table,forc_experiment,forc_model,forc_ripf,forc_grid,forc_datetime=cmor_file_parts(forc_input_file_tail)\n",
    "  forc_rval,forc_ival,forc_pval,forc_fval=cmor_ripf_parts(forc_ripf)\n",
    "  forc_version,forc_grid,forc_var,forc_table,forc_ripf,forc_experiment,forc_model,forc_institution,forc_activity,forc_cmip=cmor_directory_parts(forc_input_file_head)\n",
    "  forc_ens.append(forc_rval)\n",
    "  #print('forc_i=',forc_i)\n",
    "  forc_ifhs.append(netCDF4.Dataset(forc_input_file))\n",
    "  forc_times.append(forc_ifhs[forc_i].variables['time'])\n",
    "  \n",
    "  #print(forc_ifhs[forc_i].variables['time'][:])\n",
    "  \n",
    "  #raise Exception('STOP!')                 \n",
    "\n",
    "  if(forc_i>0):  #check that same calendar/units are in use, otherwise would need to convert to common one.\n",
    "    if(forc_times[forc_i].calendar!=forc_times[forc_i-1].calendar): raise SystemExit('calendars not matching:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    if(forc_times[forc_i].units!=forc_times[forc_i-1].units): raise SystemExit('units not matching:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  forc_mins.append(min(forc_times[forc_i]))\n",
    "  forc_maxs.append(max(forc_times[forc_i]))\n",
    "  forc_date_time_stamps.append(netCDF4.num2date(forc_times[forc_i][:],forc_times[forc_i].units,forc_times[forc_i].calendar))\n",
    "  if(forc_i==0):\n",
    "    npforc_date_time_stamps=netCDF4.num2date(forc_times[forc_i][:],forc_times[forc_i].units,forc_times[forc_i].calendar)\n",
    "  else:\n",
    "    npforc_date_time_stamps=np.append(npforc_date_time_stamps,netCDF4.num2date(forc_times[forc_i][:],forc_times[forc_i].units,forc_times[forc_i].calendar))\n",
    "\n",
    "np.set_printoptions(threshold='nan') #will print out whole array\n",
    "np.set_printoptions(threshold=1000)\n",
    "\n",
    "#print('npforc_date_time_stamps=',npforc_date_time_stamps)\n",
    "#print('npforc_date_time_stamps.shape=',npforc_date_time_stamps.shape)\n",
    "\n",
    "#raise Exception('STOP!')                 \n",
    "#print('type(forc_date_time_stamps)=',type(forc_date_time_stamps))\n",
    "\n",
    "#cont_date_time_stamp=netCDF4.num2date(cont_time[:],cont_time.units,cont_time.calendar)\n",
    "\n",
    "#forc_year_fraction_monthly=fractional_year_from_num2date(npforc_date_time_stamps,forc_times[0].calendar) #get working...\n",
    "\n",
    "#print('forc_times=',forc_times[:])\n",
    "#print('len(forc_times)=',len(forc_times))\n",
    "\n",
    "forc_nptimes=np.array(forc_times)\n",
    "#print('forc_nptimes=',forc_nptimes[:])\n",
    "#print('type(forc_nptimes)=',type(forc_nptimes))\n",
    "\n",
    "forc_npftimes=forc_nptimes.flatten()\n",
    "#print('forc_npftimes=',forc_npftimes[:])\n",
    "\n",
    "#print(forc_ens)\n",
    "#print('forc_year_fraction_monthly=',forc_year_fraction_monthly[:])\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "year_min=netCDF4.num2date(min(forc_mins),forc_times[0].units,forc_times[0].calendar)\n",
    "year_max=netCDF4.num2date(max(forc_maxs),forc_times[0].units,forc_times[0].calendar) #not year maximum as need to consider end of each experiment.\n",
    "\n",
    "print('Forecast start times go from ',min(forc_mins),'to',max(forc_maxs),'or',year_min,'to',year_max)\n",
    "print('Ensembles go from ',min(forc_ens),'to',max(forc_ens)) #later on restrict to only valid ensembles to keep arrays compact eg 1,2,3,11 but not 1-11.\n",
    "\n",
    "npforc_ens=np.array(list(set(forc_ens)))\n",
    "#print(npforc_ens)\n",
    "\n",
    "forc_nens=len(npforc_ens)\n",
    "#print(forc_nens)\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "forc_ybeg,forc_yend=netCDF4.num2date(min(forc_mins),forc_times[0].units,forc_times[0].calendar).year,netCDF4.num2date(max(forc_maxs),forc_times[0].units,forc_times[0].calendar).year\n",
    "forc_mbeg,forc_mend=netCDF4.num2date(min(forc_mins),forc_times[0].units,forc_times[0].calendar).month,netCDF4.num2date(max(forc_maxs),forc_times[0].units,forc_times[0].calendar).month\n",
    "\n",
    "forc_j,forc_k,forc_date,forc_m,forc_n,forc_time=get_timestamp_number(forc_ybeg,forc_yend,forc_mbeg,forc_mend,forc_times[0].units,forc_times[0].calendar)\n",
    "\n",
    "forc_ntime=len(forc_time)\n",
    "\n",
    "forc_year_fraction_monthly=fractional_year_from_num2date(forc_date,forc_times[0].calendar)\n",
    "\n",
    "#print('forc_ntime=',forc_ntime)\n",
    "#print('forc_date=',forc_date)\n",
    "#print('forc_time',forc_time)\n",
    "#print('forc_year_fraction_monthly',forc_year_fraction_monthly)\n",
    "\n",
    "forc_beg,forc_end=np.zeros(nforc_files,dtype=int),np.zeros(nforc_files,dtype=int) #these indices define beg/end time indices.\n",
    "\n",
    "forc_beg_cnt,forc_end_cnt=np.zeros((forc_nens,(nforc_files/forc_nens)),dtype=int),np.zeros((forc_nens,(nforc_files/forc_nens)),dtype=int) #these indices define beg/end time indices.\n",
    "\n",
    "#forc_nino_monthly=ma.zeros((nindices_nino,forc_nens,nforc_files,forc_ntime),dtype=float) #set them all to missing value, then assign the forecasts to the various segments in the array.\\\\\n",
    "#forc_nino_monthly=ma.masked_equal( np.zeros((nindices_nino,forc_nens,(nforc_files/forc_nens),forc_ntime),dtype=float), 0.0) #set them all to missing value, then assign the forecasts to the various segments in the array.\\\\\n",
    "forc_nino_monthly=ma.masked_equal( np.zeros((forc_ntime,nindices_nino,forc_nens,(nforc_files/forc_nens)),dtype=float), 0.0) #set them all to missing value, then assign the forecasts to the various segments in the array.\\\\\n",
    "\n",
    "#print(forc_nino_monthly.view(ma.MaskedArray))\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "forc_check=ma.zeros((nindices_nino,forc_nens,nforc_files),dtype=int) #can use this to see how the arrays are being populated or not.\n",
    "\n",
    "#print('forc_nino_monthly.shape=',forc_nino_monthly.shape)\n",
    "\n",
    "#forc_beg_date=date_time_stamps[0][0] #this would be for total set of times.\n",
    "#forc_end_date=date_time_stamps[-1][-1] #this would be for total set of times.\n",
    "\n",
    "forc_lat=forc_ifhs[0].variables['latitude'][:,0]\n",
    "forc_lon=forc_ifhs[0].variables['longitude'][0,:]\n",
    "\n",
    "#forc_clat=np.zeros((nforc_files),dtype=float) #if latitude range changes will need to have custom clat.\n",
    "forc_clat=np.cos(forc_lat[:]*rad)\n",
    "\n",
    "#print(indices_i[0][0],indices_i[0][1])\n",
    "\n",
    "forc_ens_cnt=np.zeros(forc_nens,dtype=int)\n",
    "\n",
    "for forc_i,forc_input_file in enumerate(forc_files):\n",
    "  #print('forc_i,forc_input_file=',forc_i,forc_input_file)\n",
    "  forc_beg_date=forc_date_time_stamps[forc_i][0]\n",
    "  forc_end_date=forc_date_time_stamps[forc_i][-1]\n",
    "  #print('forc_beg_date,forc_end_date=',forc_beg_date,forc_end_date)\n",
    "\n",
    "  #print(type(forc_ens[forc_i]))\n",
    "  #raise Exception('STOP!')\n",
    "  \n",
    "  forc_begend_time=[netCDF4.date2num(forc_beg_date,forc_times[i].units,forc_times[i].calendar), netCDF4.date2num(forc_end_date,forc_times[i].units,forc_times[i].calendar)]\n",
    "  forc_loc_beg,forc_loc_end=np.where(forc_time[:]==forc_begend_time[0],1,0),np.where(forc_time[:]==forc_begend_time[1],1,0)\n",
    "  \n",
    "  #print('forc_loc_beg,end=',forc_loc_beg,forc_loc_end)\n",
    "  #raise Exception('STOP!')\n",
    "  \n",
    "  forc_beg[forc_i],forc_end[forc_i]=np.argmax(forc_loc_beg),np.argmax(forc_loc_end)\n",
    "  \n",
    "  #print('forc_beg[forc_i],end[forc_i]=',forc_beg[forc_i],forc_end[forc_i])\n",
    "  #raise Exception('STOP!')\n",
    "  forc_ens_cnt[forc_ens[forc_i]-1]+=1 #this is used to put each forecast in a unique ensemble slot in the array, the array should end up with equal values if the experiment is consistent & complete.\n",
    "  #print('forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1=',forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1)\n",
    "\n",
    "  forc_beg_cnt[forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1], forc_end_cnt[forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1]=np.argmax(forc_loc_beg),np.argmax(forc_loc_end)\n",
    "\n",
    "  for forc_k,indice in enumerate(indices_nino):\n",
    "\n",
    "    forc_imin,forc_imax=indices_i_gn[forc_k][0],indices_i_gn[forc_k][1]\n",
    "    forc_jmin,forc_jmax=indices_j_gn[forc_k][0],indices_j_gn[forc_k][1]\n",
    "    #print('forc_k,forc_imin,forc_imax,forc_jmin,forc_jmax=',forc_k,forc_imin,forc_imax,forc_jmin,forc_jmax)\n",
    "    \n",
    "    forc_check[forc_k,forc_ens[forc_i]-1,forc_i] = forc_check[forc_k,forc_ens[forc_i]-1,forc_i] + 1 #can use this for checking. For example, onece an array is set to 1 it should not be set/reset again (no overlap).\n",
    "    \n",
    "    #print('forc_nino_monthly.shape=',forc_nino_monthly.shape)\n",
    "    \n",
    "    forc_nino_monthly[forc_beg[forc_i]:forc_end[forc_i]+1,forc_k,forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1]=np.average(np.average(forc_ifhs[forc_i].variables[dvar][:,forc_jmin:forc_jmax+1,forc_imin:forc_imax+1],axis=1,weights=forc_clat[forc_jmin:forc_jmax+1]),axis=1)\n",
    "    #forc_nino_monthly[forc_k,forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,forc_beg[forc_i]:forc_end[forc_i]+1]=np.average(np.average(forc_ifhs[forc_i].variables[dvar][:,forc_jmin:forc_jmax+1,forc_imin:forc_imax+1],axis=1,weights=forc_clat[forc_jmin:forc_jmax+1]),axis=1)\n",
    "    #nb = raw_input('Press enter: ')\n",
    "    #raise Exception('STOP!')\n",
    "    \n",
    "#print('forc_check=',forc_check)\n",
    "\n",
    "#print('forc_ens_cnt=',forc_ens_cnt)\n",
    "\n",
    "#print('forc_beg=',forc_beg)\n",
    "#print('forc_end=',forc_end)\n",
    "\n",
    "#print('forc_beg_cnt=',forc_beg_cnt)\n",
    "#print('forc_end_cnt=',forc_end_cnt)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "#forc_nino_anomaly=forc_nino_monthly.copy() #make a copy in preparation for generating anomalies.\n",
    "\n",
    "forc_nino_anomaly_step1=np.expand_dims(forc_nino_monthly,-1)\n",
    "\n",
    "forc_nino_anomaly=np.tile(forc_nino_anomaly_step1,(cont_nexps))\n",
    "\n",
    "print('forc_nino_anomaly.shape=',forc_nino_anomaly.shape)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "forc_years,forc_months,forc_days,forc_hours=[],[],[],[]\n",
    "forc_yearsM1,forc_monthsM1,forc_daysM1,forc_hoursM1=[],[],[],[]\n",
    "for forc_i,forc_date_now in enumerate(forc_date):\n",
    "  forc_years.append(forc_date_now.year)\n",
    "  forc_months.append(forc_date_now.month)\n",
    "  forc_days.append(forc_date_now.day)\n",
    "  forc_hours.append(forc_date_now.hour)\n",
    "  forc_yearsM1.append(forc_date_now.year-1)\n",
    "  forc_monthsM1.append(forc_date_now.month-1)\n",
    "  forc_daysM1.append(forc_date_now.day-1)\n",
    "  forc_hoursM1.append(forc_date_now.hour-1)\n",
    "\n",
    "plot_index='nino34'\n",
    "#plot_index='nino3'\n",
    "#plot_index='nino4'\n",
    "#plot_index='nino1+2'\n",
    "\n",
    "forc_ens_cnt=np.zeros(forc_nens,dtype=int)\n",
    "\n",
    "#some of these things could be put into a function.\n",
    "for forc_i,forc_input_file in enumerate(forc_files):\n",
    "  #print('forc_input_file=',forc_input_file)\n",
    "  forc_year_beg,forc_year_end=forc_years[forc_beg[forc_i]],forc_years[forc_end[forc_i]]\n",
    "  forc_month_beg,forc_month_end=forc_months[forc_beg[forc_i]],forc_months[forc_end[forc_i]]\n",
    "  #print('forc_i,forc_year_beg,forc_year_end,forc_month_beg,forc_month_end=',forc_year_beg,forc_year_end,forc_month_beg,forc_month_end)\n",
    "  forc_mbeg,forc_mend=1,12\n",
    "  forc_ybeg,forc_yend=forc_year_beg,forc_year_end\n",
    "  if(forc_month_beg!=1): forc_ybeg,forc_mbeg=forc_year_beg+1,1\n",
    "  if(forc_month_end!=12): forc_yend,forc_mbeg=forc_year_end-1,12\n",
    "  #print('forc_ybeg,forc_yend,forc_mbeg,forc_mend=',forc_ybeg,forc_yend,forc_mbeg,forc_mend)\n",
    "  #print('forc_nino_monthly[0,forc_ens[forc_i],forc_i,forc_beg[forc_i]:forc_end[forc_i]]=',forc_nino34_monthly[0,0,forc_i,forc_beg[forc_i]:forc_end[forc_i]])\n",
    "  #print('forc_years[forc_beg[forc_i]:forc_end[forc_i]+1]=',forc_years[forc_beg[forc_i]:forc_end[forc_i]+1])\n",
    "  #print('forc_months[forc_beg[forc_i]:forc_end[forc_i]+1]=',forc_months[forc_beg[forc_i]:forc_end[forc_i]+1]) #just need to find first january and last december in this list to extract the indices...\n",
    "  #print('cont_nino_climatology.shape=',cont_nino_climatology.shape) #cont_climatology calculated in previous cell.\n",
    "  #print('cont_nino_climatology=',cont_nino_climatology)\n",
    "  #print(cont_nino_climatology[0,forc_months[forc_beg[forc_i]]-1])\n",
    "  #print(cont_nino_climatology[0,forc_monthsM1[forc_beg[forc_i]:forc_end[forc_i]+1]])\n",
    "  forc_ens_cnt[forc_ens[forc_i]-1]+=1\n",
    "  \n",
    "  for forc_k,indice in enumerate(indices_nino):\n",
    "    #None\n",
    "    #pretty cool, each month of climatology (12) will be mapped according to values of forc_monthsM1\n",
    "    #forc_nino_anomaly[forc_k,forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,forc_beg[forc_i]:forc_end[forc_i]+1] = forc_nino_anomaly[forc_k,forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,forc_beg[forc_i]:forc_end[forc_i]+1] - cont_nino_climatology[forc_k,forc_monthsM1[forc_beg[forc_i]:forc_end[forc_i]+1]]\n",
    "    for clim_cnt in range(cont_nexps):\n",
    "      forc_nino_anomaly[forc_beg[forc_i]:forc_end[forc_i]+1,forc_k,forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,clim_cnt] = \\\n",
    "      forc_nino_anomaly[forc_beg[forc_i]:forc_end[forc_i]+1,forc_k,forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,clim_cnt] - cont_nino_climatology[forc_monthsM1[forc_beg[forc_i]:forc_end[forc_i]+1],forc_k,clim_cnt]\n",
    "  \n",
    "  #raise Exception('STOP!')\n",
    "  \n",
    "  forc_year_fraction_monthly_now=forc_year_fraction_monthly[forc_beg[forc_i]:forc_end[forc_i]+1]\n",
    "  #forc_zero=np.zeros(len(forc_year_fraction_monthly_now))\n",
    "  #print('forc_ens[forc_i]=',forc_ens[forc_i])\n",
    "  \n",
    "  plt.plot(forc_year_fraction_monthly_now,forc_nino_anomaly[forc_beg[forc_i]:forc_end[forc_i]+1,indices_nino.index(plot_index),forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,0],color=colors[forc_ens[forc_i]-1])\n",
    "  #plt.plot(forc_year_fraction_monthly_now,forc_nino_monthly[indices_nino.index(plot_index),forc_ens[forc_i]-1,forc_ens_cnt[forc_ens[forc_i]-1]-1,forc_beg[forc_i]:forc_end[forc_i]+1],color=colors[forc_ens[forc_i]-1])\n",
    "\n",
    "#  print('Times go from ',min(forc_mins),'to',max(forc_maxs),'or',\n",
    "#    netCDF4.num2date(min(forc_mins),forc_times[0].units,forc_times[0].calendar),'to',netCDF4.num2date(max(forc_maxs),forc_times[0].units,forc_times[0].calendar))\n",
    "\n",
    "#year_min=netCDF4.num2date(min(forc_mins),forc_times[0].units,forc_times[0].calendar)\n",
    "#year_max=netCDF4.num2date(max(forc_maxs),forc_times[0].units,forc_times[0].calendar)\n",
    "all_years=np.linspace(year_min.year,year_max.year,20)\n",
    "forc_zero=np.zeros(len(all_years))\n",
    "plt.plot(all_years,forc_zero,color='black',linestyle=':')\n",
    "\n",
    "plt.title('Monthly anomalies')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(indices_label[indices_nino.index(plot_index)]+' ($^o$C)')\n",
    "plt.show()\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('BEGIN')\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "nmy=12\n",
    "\n",
    "#del(generate_daily_month_indices)\n",
    "#from decadal_diag import generate_daily_month_indices\n",
    "\n",
    "ivar_str_ncep2='skt'\n",
    "#ybeg_data_ncep2=2000 #2000;assume 12 months in every year.\n",
    "#yend_data_ncep2=2016 #2016;assume 12 months in every year.\n",
    "\n",
    "grid_label='ncep2'\n",
    "ncep2_files_string='/short/v14/mac599/ncep2/skt.sfc.gauss.????.nc'\n",
    "ncep2_files=sorted(glob.glob(ncep2_files_string))\n",
    "nncep2_files=len(ncep2_files)\n",
    "print('ncep2 input_files ('+str(nncep2_files)+') =',ncep2_files)\n",
    "\n",
    "ifhN_ncep2=netCDF4.MFDataset(ncep2_files)\n",
    "ifh0_ncep2=netCDF4.MFDataset(ncep2_files[0])\n",
    "\n",
    "time_daily_ncep2=ifhN_ncep2.variables['time']\n",
    "#lat=ifh0.variables['lat']\n",
    "#lon=ifh0.variables['lon']\n",
    "\n",
    "lat_ncep2=ifh0_ncep2.variables['lat'][:]\n",
    "lon_ncep2=ifh0_ncep2.variables['lon'][:]\n",
    "\n",
    "ntime_daily_ncep2=len(time_daily_ncep2)\n",
    "#print('lat=',lat)\n",
    "\n",
    "ifh0_ncep2.close()\n",
    "\n",
    "#print('rad=',rad)\n",
    "clat_ncep2=np.cos(lat_ncep2[:]*rad)\n",
    "\n",
    "#time_daily_ncep2_calendar='julian'\n",
    "time_daily_ncep2_calendar='proleptic_gregorian'\n",
    "\n",
    "date_time_stamp_daily_ncep2=netCDF4.num2date(time_daily_ncep2[:],time_daily_ncep2.units,time_daily_ncep2_calendar)\n",
    "\n",
    "year_fraction_daily_ncep2=fractional_year_from_num2date(date_time_stamp_daily_ncep2,time_daily_ncep2_calendar)\n",
    "\n",
    "nino_daily_ncep2=ma.zeros((ntime_daily_ncep2,nindices_nino),dtype=float)\n",
    "#raise Exception('STOP!')\n",
    "for ncep2_k,indice in enumerate(indices_nino):\n",
    "  #ncep2_k=indices_nino.index(indice)\n",
    "  ncep2_imin,ncep2_imax=indices_i_ncep2[indices_nino.index(indice)][0],indices_i_ncep2[indices_nino.index(indice)][1]\n",
    "  ncep2_jmin,ncep2_jmax=indices_j_ncep2[indices_nino.index(indice)][0],indices_j_ncep2[indices_nino.index(indice)][1]\n",
    "  #print('indices.index(indice),imin_ncep2,imax_ncep2,jmin_ncep2,jmax_ncep2=',indices.index(indice),imin_ncep2,imax_ncep2,jmin_ncep2,jmax_ncep2)\n",
    "  #print('lat_ncep2,lon_ncep2=',lat_ncep2[jmin_ncep2:jmax_ncep2],lon_ncep2[imin_ncep2:imax_ncep2])\n",
    "\n",
    "  nino_daily_ncep2[:,ncep2_k]=np.average(np.average(ifhN_ncep2.variables['skt'][:,ncep2_jmin:ncep2_jmax,ncep2_imin:ncep2_imax],axis=1,weights=clat_ncep2[ncep2_jmin:ncep2_jmax]),axis=1)\n",
    "\n",
    "#indices_i_gn,indices_j_gn=[[122,152],[122,152],[122,152]],[[110,160],[110,160],[110,160]] #check this, whether I need +1 also...\n",
    "#raise Exception('STOP!')\n",
    "#print('year_fraction_ncep2=',year_fraction_monthly_ncep2)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fix,ax=plt.subplots()\n",
    "for ncep2_k,indice in enumerate(indices_nino):\n",
    "  ax.plot(year_fraction_daily_ncep2,nino_daily_ncep2[:,indices_nino.index(indice)]-273.15,label=indices_label[indices_nino.index(indices_nino[ncep2_k])])\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(2.0))\n",
    "legend=ax.legend(loc='lower right',shadow=False,fontsize='x-large')\n",
    "plt.title('Daily values (NCEP2)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('$^o$C')\n",
    "plt.grid(True,linestyle='-')\n",
    "plt.show()\n",
    "\n",
    "what_to_keep='all_times'\n",
    "#what_to_keep='all_but_first'\n",
    "#what_to_keep='all_but_last'\n",
    "#what_to_keep='all_but_first_and_last'\n",
    "\n",
    "if(what_to_keep=='all_times'):\n",
    "  #all times kept:\n",
    "  date_time_stamp_daily_new_ncep2=date_time_stamp_daily_ncep2\n",
    "  nino_daily_new_ncep2=nino_daily_ncep2\n",
    "  year_fraction_daily_new_ncep2=year_fraction_daily_ncep2\n",
    "  \n",
    "elif(what_to_keep=='all_but_first'):\n",
    "  #remove first day:\n",
    "  date_time_stamp_daily_new_ncep2=date_time_stamp_daily_ncep2[1::]\n",
    "  nino_daily_new_ncep2=nino_daily_ncep2[1::,:]\n",
    "  year_fraction_daily_new_ncep2=year_fraction_daily_ncep2[1::]\n",
    "  \n",
    "elif(what_to_keep=='all_but_last'):\n",
    "  #remove last day:\n",
    "  date_time_stamp_daily_new_ncep2=date_time_stamp_daily_ncep2[0:-1]\n",
    "  nino_daily_new_ncep2=nino_daily_ncep2[0:-1,:]\n",
    "  year_fraction_daily_new_ncep2=year_fraction_daily_ncep2[0:-1]\n",
    "\n",
    "elif(what_to_keep=='all_but_first_and_last'):\n",
    "  #remove first and last day:\n",
    "  date_time_stamp_daily_new_ncep2=date_time_stamp_daily_ncep2[1:-1]\n",
    "  nino_daily_new_ncep2=nino_daily_ncep2[1:-1,:]\n",
    "  year_fraction_daily_new_ncep2=year_fraction_daily_ncep2[1:-1]\n",
    "  \n",
    "else:\n",
    "  raise Exception('That what_to_keep option doesnt exist.')\n",
    "\n",
    "#print('len(date_time_stamp_daily_new_ncep2)=',len(date_time_stamp_daily_new_ncep2))\n",
    "\n",
    "daily_month_indice_beg_ncep2,daily_month_indice_end_ncep2,daily_year_beg_ncep2,daily_year_end_ncep2,daily_month_beg_ncep2,daily_month_end_ncep2,daily_day_beg_ncep2,daily_day_end_ncep2,beg_month_partial_ncep2,end_month_partial_ncep2 = \\\n",
    "  generate_daily_month_indices(date_time_stamp_daily_new_ncep2,time_daily_ncep2.units,time_daily_ncep2_calendar,24)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "nino_monthly_ncep2=ma.zeros((len(daily_month_indice_beg_ncep2),nindices_nino),dtype=float)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "for k,indice in enumerate(indices_nino):\n",
    "  for month in range(0,len(daily_month_indice_beg_ncep2)):\n",
    "    nino_monthly_ncep2[month,k]=np.average(nino_daily_new_ncep2[daily_month_indice_beg_ncep2[month]:daily_month_indice_end_ncep2[month]+1,k])\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "year_fraction_monthly_ncep2=ma.zeros(len(daily_month_indice_beg_ncep2))\n",
    "for month in range(0,len(daily_month_indice_beg_ncep2)):\n",
    "  year_fraction_monthly_ncep2[month]=np.average(year_fraction_daily_new_ncep2[daily_month_indice_beg_ncep2[month]:daily_month_indice_end_ncep2[month]+1])\n",
    "\n",
    "num_stamp_new_ncep2=netCDF4.date2num(date_time_stamp_daily_new_ncep2,time_daily_ncep2.units,time_daily_ncep2_calendar)\n",
    "\n",
    "num_stamp_monthly_ncep2=np.zeros(len(daily_month_indice_beg_ncep2))\n",
    "#print('num_stamp_monthly_ncep2.shape=',num_stamp_monthly_ncep2.shape)\n",
    "\n",
    "for month in range(0,len(daily_month_indice_beg_ncep2)):\n",
    "  num_stamp_monthly_ncep2[month]=np.average(num_stamp_new_ncep2[daily_month_indice_beg_ncep2[month]:daily_month_indice_end_ncep2[month]+1])\n",
    "\n",
    "date_time_stamp_monthly_ncep2=netCDF4.num2date(num_stamp_monthly_ncep2,time_daily_ncep2.units,time_daily_ncep2_calendar)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "  \n",
    "EndOption=1 #use months with no days missing at begin and end months (i.e. discard partial months if they exist).\n",
    "#EndOption=2 #use months with days missing at both begin and end months (i.e. don't discard partial months if they exist @ beg/end).\n",
    "\n",
    "print('beg,end_month_partial_ncep2=',beg_month_partial_ncep2,end_month_partial_ncep2)\n",
    "\n",
    "if(EndOption==1):\n",
    "  print('Discarding beg&/end month if they exist.')\n",
    "  if(beg_month_partial_ncep2 or end_month_partial_ncep2):\n",
    "    if(beg_month_partial_ncep2 and end_month_partial_ncep2):\n",
    "      print('type#1')\n",
    "      nino_monthly_new_ncep2=nino_monthly_ncep2[1:-1,:]\n",
    "      year_fraction_monthly_new_ncep2=year_fraction_monthly_ncep2[1:-1]\n",
    "      date_time_stamp_monthly_new_ncep2=date_time_stamp_monthly_ncep2[1:-1]\n",
    "      \n",
    "    elif(not beg_month_partial_ncep2 and end_month_partial_ncep2):\n",
    "      print('type#2')\n",
    "      nino_monthly_new_ncep2=nino_monthly_ncep2[0:-1,:]\n",
    "      year_fraction_monthly_new_ncep2=year_fraction_monthly_ncep2[0:-1]\n",
    "      date_time_stamp_monthly_new_ncep2=date_time_stamp_monthly_ncep2[0:-1]\n",
    "\n",
    "    elif(beg_month_partial_ncep2 and not end_month_partial_ncep2):\n",
    "      print('type#3')\n",
    "      nino_monthly_newnino_ncep2=nino_monthly_ncep2[1::,:]\n",
    "      year_fraction_monthly_new_ncep2=year_fraction_monthly_ncep2[1::]\n",
    "      date_time_stamp_monthly_new_ncep2=date_time_stamp_monthly_ncep2[1::]\n",
    "\n",
    "    else:\n",
    "      raise SystemExit('Shouldnt get here:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  else:\n",
    "    print('type#4')\n",
    "    nino_monthly_new_ncep2=nino_monthly_ncep2\n",
    "    year_fraction_monthly_new_ncep2=year_fraction_monthly_ncep2\n",
    "    date_time_stamp_monthly_new_ncep2=date_time_stamp_monthly_ncep2\n",
    "    \n",
    "elif(EndOption==2):\n",
    "  print('Keeping beg/end month or both.')\n",
    "  nino_monthly_new_ncep2=nino_monthly_ncep2\n",
    "  year_fraction_monthly_new_ncep2=year_fraction_monthly_ncep2\n",
    "  date_time_stamp_monthly_new_ncep2=date_time_stamp_monthly_ncep2\n",
    "  \n",
    "else:\n",
    "  raise SystemExit('EndOption can be only 1 or 2:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "#raise Exception('STOP!')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#print(nino_monthly_new)\n",
    "\n",
    "#print('year_fraction_monthly_new=',year_fraction_monthly_new)\n",
    "\n",
    "plot_index='nino34'\n",
    "#plot_index='nino1+2'\n",
    "#plot_index='nino4'\n",
    "\n",
    "fix,ax=plt.subplots()\n",
    "ax.plot(year_fraction_monthly_new_ncep2,nino_monthly_new_ncep2[:,indices_nino.index(plot_index)]-273.15,color='blue',label='mon_from_day')\n",
    "legend=ax.legend(loc='lower left',shadow=False,fontsize='large')\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(2.0))\n",
    "plt.title('Monthly values (NCEP2)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(indices_label[indices_nino.index(plot_index)] +'($^o$C)')\n",
    "plt.grid(True,linestyle='-')\n",
    "plt.show()\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "#print('date_time_stamp_monthly_new_ncep2=',date_time_stamp_monthly_new_ncep2)\n",
    "ybeg_ncep2=date_time_stamp_monthly_new_ncep2[0].year\n",
    "yend_ncep2=date_time_stamp_monthly_new_ncep2[-1].year\n",
    "\n",
    "ydiff_monthly_ncep2=yend_ncep2-ybeg_ncep2+1\n",
    "\n",
    "MissingMonths_ncep2=False\n",
    "\n",
    "first_month_ncep2=date_time_stamp_monthly_new_ncep2[0].month\n",
    "last_month_ncep2=date_time_stamp_monthly_new_ncep2[-1].month\n",
    "\n",
    "#print('ybeg,yend_ncep2=',ybeg_ncep2,yend_ncep2)\n",
    "\n",
    "#print('first,last_month_ncep2=',first_month_ncep2,last_month_ncep2)\n",
    "\n",
    "missing_months_beg_ncep2,missing_months_end_ncep2=0,0\n",
    "\n",
    "cyear_beg_skip_ncep2,cyear_end_skip_ncep2=0,1\n",
    "\n",
    "if(first_month_ncep2!=1):\n",
    "  missing_months_beg_ncep2=12-first_month_ncep2\n",
    "  cyear_beg_skip_ncep2=1\n",
    "  MissingMonths_ncep2=True\n",
    "\n",
    "if(last_month_ncep2!=12):\n",
    "  missing_months_end_ncep2=12-last_month_ncep2\n",
    "  cyear_end_skip_ncep2=2\n",
    "  MissingMonths_ncep2=True\n",
    "  \n",
    "if(MissingMonths_ncep2):\n",
    "  print('There are missing months in the set. '+str(missing_months_beg_ncep2)+' at beginning and '+str(missing_months_end_ncep2)+' at end.')\n",
    "  print('Currently years with missing months are not used in generating long term monthly climatology.')\n",
    "  print('And missing months will be set to missing in the final time-series.')\n",
    "  ts_beg_ncep2,ts_end_ncep2,ts_avg_ncep2,dt_beg_ncep2,dt_end_ncep2,dt_avg_ncep2=get_timestamp_number(ybeg_ncep2,yend_ncep2,1,12,time_ncep2.units,time_ncep2_calendar)\n",
    "  year_fraction_monthly_full_ncep2=fractional_year_from_num2date(ts_avg_ncep2,time_ncep2_calendar)\n",
    "  \n",
    "  nino_monthly_full_ncep2=ma.masked_all((ydiff_monthly_ncep2*nmy,nindices_nino),dtype=float) #ensure missing months are masked out.\n",
    "  last_month_index_ncep2=ydiff_monthly_ncep2*nmy-last_month_ncep2\n",
    "  nino_monthly_full_ncep2[first_month_ncep2-1:last_month_index_ncep2,:]=nino_monthly_ncep2\n",
    "else:\n",
    "  print('All years have 12 months.')\n",
    "  \n",
    "  nino_monthly_full_ncep2=nino_monthly_ncep2.copy()\n",
    "  year_fraction_monthly_full_ncep2=year_fraction_monthly_ncep2.copy()\n",
    "\n",
    "  print('nino_monthly_full_ncep2.shape=',nino_monthly_full_ncep2.shape)\n",
    "\n",
    "nino_climatology_ncep2,nino_monthly_anomaly_ncep2 = calculate_monthly_climatology_anomaly_from_monthly(nino_monthly_full_ncep2)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "zero_ncep2=np.zeros(len(year_fraction_monthly_full_ncep2))\n",
    "fix,ax=plt.subplots()\n",
    "for ncep2_k,indice in enumerate(indices_nino):\n",
    "  ax.plot(year_fraction_monthly_full_ncep2,nino_monthly_anomaly_ncep2[:,ncep2_k],label=indices_label[indices_nino.index(indices_nino[ncep2_k])])\n",
    "plt.plot(year_fraction_monthly_full_ncep2,zero_ncep2,color='black')\n",
    "\n",
    "legend=ax.legend(loc='upper left',shadow=False,fontsize='x-large')\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(2.0))\n",
    "plt.title('Monthly anomalies (NCEP2)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('$^o$C')\n",
    "plt.grid(True,linestyle='-')\n",
    "plt.show()\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 18,
        "hidden": false,
        "row": 50,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#https://www.youtube.com/watch?v=6SHnmho7zCs\n",
    "\n",
    "def plot_map_box(ind,indices_label,indices_nino,lats_nino,lons_nino):\n",
    "  \n",
    "  colors=['black','red','green','blue','orange','brown','purple','pink']\n",
    "\n",
    "  ind_list=[]\n",
    "  for f,ff in enumerate(ind):\n",
    "    ind_list.append(indices_nino.index(ind[f])) \n",
    "  \n",
    "  map = Basemap(projection='cyl', \n",
    "  llcrnrlat=-30, llcrnrlon=100, \n",
    "  urcrnrlat=30, urcrnrlon=320,\n",
    "  lat_0=0, lon_0=180)\n",
    "\n",
    "  map.drawmapboundary() #fill_color='aqua'\n",
    "  map.fillcontinents() #color='coral',lake_color='aqua'\n",
    "  map.drawcoastlines()\n",
    "\n",
    "  #print('len(lons_nino)=',len(lons_nino))\n",
    "\n",
    "  for i,ii in enumerate(ind_list):\n",
    "    x,y = map(lons_nino[ii], lats_nino[ii])\n",
    "    map.plot(x, y, marker=None,color=colors[i],linewidth=1)\n",
    "    xmid,ymid = map((lons_nino[ii][0]+lons_nino[ii][1])/2,(lats_nino[ii][0]+lats_nino[ii][2])/2)\n",
    "    plt.text(xmid,ymid,indices_nino[ii],fontsize=6,horizontalalignment='left',verticalalignment='center')  \n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def plot_xy_climatology(ind,obs,mod,clim,indices_label,obs_toggle):\n",
    "\n",
    "  colors=['black','red','green','blue','orange','brown','purple','pink']\n",
    "\n",
    "  ind_list=[]\n",
    "  for f,ff in enumerate(ind):\n",
    "    ind_list.append(indices_nino.index(ind[f])) \n",
    "\n",
    "  #print('indices_label=',indices_label)\n",
    "  #print('ind=',ind)\n",
    "  #print('ind_list=',ind_list)\n",
    "  \n",
    "  fix,ax=plt.subplots()\n",
    "  if(obs_toggle):\n",
    "    plt.title('Monthly climatology (obs:dashed)')\n",
    "  else:\n",
    "    plt.title('Monthly climatology')\n",
    "\n",
    "  plt.xlabel('Month')\n",
    "  plt.ylabel('$^o$C')\n",
    "  plt.xticks(range(12), ['J','F','M','A','M','J','J','A','S','O','N','D'], rotation='horizontal')\n",
    "\n",
    "  for j in ind_list:\n",
    "    ax.plot(range(12),mod[:,j,clim],color=colors[j],label=indices_label[j])\n",
    "    if(obs_toggle):\n",
    "      ax.plot(range(12),obs[:,j]-273.15,color=colors[j],linestyle=':')\n",
    "  plt.grid(True,linestyle='-')\n",
    "  legend=ax.legend(loc='lower right',shadow=False,fontsize='small',title='model indice')\n",
    "  plt.show()\n",
    "  \n",
    "def plot_xy_ensemble(mod_month,mod_anom,mod_time,obs_month,obs_anom,obs_time,indices_nino,ensembles, \\\n",
    "  ind,ens,forc,clim,indices_label,forc_beg,forc_end,forc_beg_cnt,forc_end_cnt,files,anom_toggle, \\\n",
    "  ensemble_average_toggle,obs_toggle,print_file):\n",
    "  #print('data.shape=',data.shape)\n",
    "  #print('ind,indices_nino=',ind,indices_nino)\n",
    "  #print('ens,ensembles=',ens,ensembles)\n",
    "  #x=range(len(data[0,0,0,:]))\n",
    "  #print('data.shape=',data.shape)\n",
    "  #print('forc_beg=',forc_beg)\n",
    "  #print('x=',x)\n",
    "  #plt.plot(time,data[ind,ens,0,0:24])\n",
    "  \n",
    "  colors=['black','red','green','blue','orange','brown','purple','pink']\n",
    "\n",
    "  #print('Current Working Directory=',os.getcwd())\n",
    "  \n",
    "  #print('ensemble_average_toggle=',ensemble_average_toggle)\n",
    "\n",
    "  #if(print_file==None):\n",
    "  #  print('No print file.')\n",
    "  #else:\n",
    "  #  print('print_file=',print_file)\n",
    "  #print('jjj=',jjj)\n",
    "  if(anom_toggle):\n",
    "    mod_data=mod_anom[:,:,:,:,clim]\n",
    "    obs_data=obs_anom\n",
    "  else:\n",
    "    mod_data=mod_month\n",
    "    obs_data=obs_month-273.15\n",
    "  #print('obs_data=',obs_data)\n",
    "  \n",
    "  ens_list=[]\n",
    "  for e,ee in enumerate(ens):\n",
    "    ens_list.append(ensembles.index(ens[e]))\n",
    "    \n",
    "  ind_list=[]\n",
    "  for f,ff in enumerate(ind):\n",
    "    ind_list.append(indices_nino.index(ind[f])) \n",
    "    \n",
    "  fix,ax=plt.subplots()\n",
    "  #for i in range(len(files)/len(ensembles)):\n",
    "  for i in forc:\n",
    "    #print('i=',i)\n",
    "    ival=int(i.split(':')[0])\n",
    "    #print('ival=',ival)\n",
    "    #time_now=time[forc_beg[i]:forc_end[i]+1]\n",
    "    for j in ind_list:\n",
    "      #print('i,j,k=',i,j,k)\n",
    "      for k in ens_list:\n",
    "          mod_time_now_test=mod_time[forc_beg_cnt[k,ival]:forc_end_cnt[k,ival]+1]\n",
    "      #print('time_now=',time_now)\n",
    "          if(i==forc[0] and j==ind_list[0]):\n",
    "            legend_label=str(k+1)\n",
    "          else:\n",
    "            legend_label=None\n",
    "          ax.plot(mod_time_now_test,mod_data[forc_beg_cnt[k,ival]:forc_end_cnt[k,ival]+1,j,k,ival],color=colors[k],label=legend_label) #indice, ensemble, forecast, date/time\n",
    "          if(k==ens_list[-1] and ensemble_average_toggle):\n",
    "            #xxx=np.average(data[j,ens_list,ival,forc_beg_cnt[k,ival]:forc_end_cnt[k,ival]+1],axis=0)\n",
    "            #print(xxx.shape)\n",
    "            ax.plot(mod_time_now_test,np.average(mod_data[forc_beg_cnt[k,ival]:forc_end_cnt[k,ival]+1,j,ens_list,ival],axis=0),color='pink',linewidth=5,label='EA')\n",
    "          if(k==ens_list[-1] and i==forc[-1] and obs_toggle):\n",
    "            #print('hello')\n",
    "            ax.plot(obs_time,obs_data[:,j],color='lightblue',label='ncep2')\n",
    "  legend=ax.legend(loc='lower right',shadow=False,fontsize='small',title='ensemble')\n",
    "  if(anom_toggle):\n",
    "    plt.title('Monthly anomalies')\n",
    "    plt.ylim([-6,6])\n",
    "  else:\n",
    "    plt.title('Monthly values')\n",
    "  plt.xlabel('Year')\n",
    "  #plt.ylabel(indices_label[ind]+' ($^o$C)')\n",
    "  plt.ylabel('$^o$C')\n",
    "  #plt.ylim([-6,6])\n",
    "  #plt.xlim([x[0],x[-1]])\n",
    "  plt.xlim([mod_time[0],mod_time[-1]])\n",
    "  plt.grid(True,linestyle='-')\n",
    "  if(anom_toggle):\n",
    "   cont_zero=np.zeros(len(mod_time))\n",
    "   plt.plot(mod_time,cont_zero,color='black',linestyle=':')\n",
    "  \n",
    "  if(print_file==None or print_file==''):\n",
    "    None\n",
    "  else:\n",
    "    print('Print to file ',os.getcwd()+'/'+print_file+'.png')\n",
    "    dummy=plt.savefig(print_file)\n",
    "    print_file=None\n",
    "  #return()\n",
    "  plt.show()\n",
    "\n",
    "#print('datetime_uniq=',datetime_uniq+range(24))\n",
    "datetime_uniq_xtra=[str(i)+': '+datetime_uniq[i] for i,x in enumerate(datetime_uniq)]\n",
    "#print('datetime_uniq_xtra=',datetime_uniq_xtra)\n",
    "#print('len(datetime_uniq_xtra)=',len(datetime_uniq_xtra))\n",
    "\n",
    "clim_list=[int(i) for i in range(cont_nexps)]\n",
    "\n",
    "ensembles=[str(x) for x in npforc_ens]\n",
    "indice_nino_multi = widgets.SelectMultiple(description='nino indice',options=indices_nino,value=indices_nino)\n",
    "ensemble_multi = widgets.SelectMultiple(description='ensemble',options=ensembles,value=ensembles)\n",
    "forecast_multi = widgets.SelectMultiple(description='forecast',options=datetime_uniq_xtra,value=datetime_uniq_xtra,rows=10)\n",
    "climatology_select = widgets.Select(description='climatology',options=clim_list,value=clim_list[0])\n",
    "anom_toggle=widgets.ToggleButton(description='Show Anoms.',value=False,button_style='danger')\n",
    "\n",
    "obs_toggle=widgets.ToggleButton(description='Show Obs.',value=False,button_style='danger')\n",
    "\n",
    "ensemble_average_toggle=widgets.ToggleButton(description='Show E.A.',value=False,button_style='danger')\n",
    "style = {'description_width': 'initial'}\n",
    "print_file=widgets.Text(value=None,placeholder='Print file name (delete to stop printing it):',continuous_update=False,style=style)\n",
    "\n",
    "#container=widgets.HBox([indice_nino_multi,ensemble_multi,forecast_multi,anom_toggle])\n",
    "#display(container)\n",
    "  \n",
    "#raise Exception('STOP!')\n",
    "#print(print_file.keys)\n",
    "#print(anom_toggle.keys)\n",
    "\n",
    "mod_month_to_plot=forc_nino_monthly.copy()\n",
    "mod_anom_to_plot=forc_nino_anomaly.copy()\n",
    "\n",
    "obs_month_to_plot=nino_monthly_full_ncep2.copy()\n",
    "obs_anom_to_plot=nino_monthly_anomaly_ncep2.copy()\n",
    "\n",
    "dummy1=widgets.interact(plot_xy_ensemble, mod_time=widgets.fixed(forc_year_fraction_monthly), mod_month=widgets.fixed(mod_month_to_plot), mod_anom=widgets.fixed(mod_anom_to_plot), \\\n",
    "  obs_time=widgets.fixed(year_fraction_monthly_full_ncep2), obs_month=widgets.fixed(obs_month_to_plot), obs_anom=widgets.fixed(obs_anom_to_plot), \\\n",
    "  indices_label=widgets.fixed(indices_label), forc_beg=widgets.fixed(forc_beg), forc_end=widgets.fixed(forc_end), \\\n",
    "  forc_beg_cnt=widgets.fixed(forc_beg_cnt), forc_end_cnt=widgets.fixed(forc_end_cnt), files=widgets.fixed(forc_files), \\\n",
    "  ensembles=widgets.fixed(ensembles), indices_nino=widgets.fixed(indices_nino), \\\n",
    "  ind=indice_nino_multi, ens=ensemble_multi, forc=forecast_multi, clim=climatology_select, anom_toggle=anom_toggle, ensemble_average_toggle=ensemble_average_toggle, obs_toggle=obs_toggle, print_file=print_file)\n",
    "\n",
    "dummy2=widgets.interact(plot_xy_climatology, \\\n",
    "  obs=widgets.fixed(nino_climatology_ncep2), mod=widgets.fixed(cont_nino_climatology), \\\n",
    "  indices_label=widgets.fixed(indices_label), \\\n",
    "  ind=indice_nino_multi, clim=climatology_select, obs_toggle=obs_toggle)\n",
    "\n",
    "dummy3=widgets.interact(plot_map_box, indices_label=widgets.fixed(indices_label), indices_nino=widgets.fixed(indices_nino), lats_nino=widgets.fixed(lats_nino), lons_nino=widgets.fixed(lons_nino), \\\n",
    "  ind=indice_nino_multi, obs_toggle=obs_toggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 62,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "for i in [0,3,5]:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_ function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib nbagg\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print('forc_nino_anomaly.shape=',forc_nino_anomaly.shape) #indice, ensemble, forecast, date/time\n",
    "\n",
    "#indices_nino=['nino34','nino3','nino4']\n",
    "\n",
    "print('indices_nino=',indices_nino)\n",
    "\n",
    "indices_nino_dict={}\n",
    "for i,d in enumerate(indices_nino):\n",
    "  indices_nino_dict[d]=i\n",
    "\n",
    "print('indices_nino_dict=',indices_nino_dict)\n",
    "\n",
    "ensembles=[str(x) for x in npforc_ens]\n",
    "\n",
    "print('ensembles=',ensembles)\n",
    "\n",
    "print('forc_nens=',forc_nens)\n",
    "\n",
    "#fig, ax = plt.subplots(1,figsize=(10,4))\n",
    "#plt.suptitle('Monthly anomalies')\n",
    "\n",
    "def test_plot(ensembles, indices_nino):\n",
    "  #from IPython.display import display\n",
    "  print('ensembles,indces_nino=',ensembles,indices_nino)\n",
    "  #display(ensemble_range, indice_nino_range)\n",
    "  #ax.clear()\n",
    "  #all_years=np.linspace(2001,2020,20)\n",
    "  #line=all_years-2001+.1\n",
    "  #t = np.arange(0., 5., 0.2)\n",
    "  #ax.plot( t, t**2, 'bs')\n",
    "  #ax.plot(all_years,line,color='black',linestyle=':')\n",
    "  #ax.legend(loc=1)\n",
    "  #plt.show()\n",
    "  plt.figure(2)\n",
    "  x=np.linspace(-10,10,num=100)\n",
    "  plt.plot(x,x**ensembles+ensembles*10)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "#ensemble_range = widgets.SelectMultiple(description='ensemble',options=ensembles,value=ensembles,disabled=False)\n",
    "\n",
    "#indice_nino_range = widgets.SelectMultiple(description='nino indice',options=indices_nino,value=indices_nino,disabled=False)\n",
    "\n",
    "#display(ensemble_range, indice_nino_range)\n",
    "\n",
    "#interactive_plot=widgets.interactive(interactive_plot, ensembles=(0,forc_nens-1,1), indices_nino={'nino34':0, 'nino3':1, 'nino4':2})\n",
    "testit=widgets.interactive(test_plot, ensembles=(0,forc_nens-1,1), indices_nino=indices_nino_dict)\n",
    "\n",
    "#print(testit.value)\n",
    "\n",
    "#del(interactive_plot)\n",
    "#ensemble_range.observe(update_plot, names='value')\n",
    "\n",
    "#indice_nino_range.observe(update_plot, names='value')\n",
    "\n",
    "testit\n",
    "#interactive_plot\n",
    "\n",
    "#forc_nino_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('npforc_ens=',npforc_ens)\n",
    "\n",
    "ensembles=[str(x) for x in npforc_ens]\n",
    "print('ensembles=',ensembles)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#print(widgets.Button.on_click.__doc__)\n",
    "\n",
    "ensemble_range = widgets.SelectMultiple(description='ensemble',options=ensembles,value=ensembles)\n",
    "\n",
    "#print(ensemble_range.keys)\n",
    "\n",
    "#indice_nino_range = widgets.SelectMultiple(description='nino indice',options=['nino34','nino3'],value=['nino34'])\n",
    "indice_nino_range = widgets.SelectMultiple(description='nino indice',options=indices_nino,value=indices_nino)\n",
    "\n",
    "container=widgets.HBox([ensemble_range,indice_nino_range])\n",
    "\n",
    "display(container)\n",
    "#display(ensemble_range, indice_nino_range)\n",
    "#display(indice_nino_range)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "#def plotit():\n",
    "fig, ax = plt.subplots(1,figsize=(10,4))\n",
    "\n",
    "def on_value_change(change):\n",
    "  #ax.clear()\n",
    "  plt.figure(2)\n",
    "  x=np.linspace(-10,10,num=100)\n",
    "  plt.plot(x,x**3+1*10)\n",
    "  plt.show()\n",
    "  print('hello')\n",
    "  print('old',change['old'])\n",
    "  print('new',change['new'])\n",
    "  print('name',change['name'])\n",
    "\n",
    "ensemble_range.observe(on_value_change, names='value')\n",
    "\n",
    "indice_nino_range.observe(on_value_change, names='value')\n",
    "\n",
    "print('ensemble_range=',ensemble_range.value)\n",
    "\n",
    "print('indice_nino_range=',indice_nino_range.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(m, b):\n",
    "    plt.figure(2)\n",
    "    x = np.linspace(-10, 10, num=1000)\n",
    "    plt.plot(x, m * x + b)\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(f, m=(-2.0, 2.0), b=(-3, 3, 0.5))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a=[0,1,2,3,4,0,1,2,3]\n",
    "b=np.array([10,20,30,40,50])\n",
    "print(b[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 66,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Process/Plot assimilation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "import math\n",
    "\n",
    "rad = 4.0*math.atan(1.0)/180.0\n",
    "#print('rad=',rad)\n",
    "\n",
    "os.chdir(rundir)\n",
    "\n",
    "grid_label='gr2'\n",
    "grid_label='gn'\n",
    "assim_files_string='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p2f1/Omon/'+dvar+'/'+grid_label+'/v20171025/'+dvar+'_Omon_historical_CAFE-1-0_r1i1p2f1_'+grid_label+'_??????-??????.nc'\n",
    "assim_files=glob.glob(assim_files_string)\n",
    "\n",
    "print('assim input_files ('+str(len(assim_files))+') =',assim_files)\n",
    "\n",
    "assim_input_file=assim_files[5]\n",
    "\n",
    "#print(datetime.datetime.fromtimestamp(os.stat(input_file).st_mtime))\n",
    "print('assim input file=',assim_input_file,'time=',datetime.datetime.fromtimestamp(os.stat(assim_input_file).st_mtime))\n",
    "\n",
    "assim_ifh0=netCDF4.Dataset(assim_input_file) #choose if more than 1.\n",
    "\n",
    "assim_time=assim_ifh0.variables['time']\n",
    "assim_lat=assim_ifh0.variables['latitude'][:,0]\n",
    "assim_lon=assim_ifh0.variables['longitude'][0,:]\n",
    "assim_clat=np.cos(assim_lat[:]*rad)\n",
    "\n",
    "#print('lat=',lat[122:152])\n",
    "#print('lon=',lon[110:160])\n",
    "#print('clat=',clat)\n",
    "#break\n",
    "\n",
    "assim_nino34_monthly=np.average(np.average(assim_ifh0.variables[dvar][:,122:152,110:160],axis=1,weights=assim_clat[122:152]),axis=1) #need to add in area weighting strictly\n",
    "\n",
    "'''\n",
    "print('time.units=',time.units)\n",
    "print('time.calendar=',time.calendar)\n",
    "print('time=',time)\n",
    "print('time[:]=',time[:])\n",
    "'''\n",
    "\n",
    "assim_date_time_stamp=netCDF4.num2date(assim_time[:],assim_time.units,assim_time.calendar)\n",
    "\n",
    "'''\n",
    "print('date_time_stamp=',date_time_stamp)\n",
    "num_stamp=netCDF4.date2num(date_time_stamp,time.units,time.calendar)\n",
    "print('num_stamp=',num_stamp)\n",
    "print('year_fraction=',year_fraction)\n",
    "'''\n",
    "assim_year_fraction_monthly=fractional_year_from_num2date(assim_date_time_stamp,assim_time.calendar)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title('Monthly values')\n",
    "plt.plot(assim_year_fraction_monthly,assim_nino34_monthly[:])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ni$\\~{n}$o34 ($^o$C)')\n",
    "plt.show()\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 68,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "In the following monthly values will be calculated and then plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 81,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "From the monthly values now we can calculate long term monthly climatologies and the month-to-month anomalies, and then plot the time-series. These are generally of more interest than the full monthly values.\n",
    "\n",
    "Want to generalise climatology, anomaly generation so that any data product can be processed (e.g. (time), (time, lat, lon), (time, depth, lat, lon), (time, lev, lat, lon).\n",
    "\n",
    "Also want to pad out years with missing months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "ybeg=date_time_stamp[0].year\n",
    "yend=date_time_stamp[-1].year\n",
    "\n",
    "ydiff=yend-ybeg+1\n",
    "nmy=12\n",
    "\n",
    "MissingMonths=False\n",
    "\n",
    "first_month=date_time_stamp[0].month\n",
    "last_month=date_time_stamp[-1].month\n",
    "\n",
    "missing_months_beg,missing_months_end=0,0\n",
    "\n",
    "cyear_beg_skip,cyear_end_skip=0,1\n",
    "\n",
    "if(first_month!=1):\n",
    "  missing_months_beg=12-first_month\n",
    "  cyear_beg_skip=1\n",
    "  MissingMonths=True\n",
    "\n",
    "if(last_month!=12):\n",
    "  missing_months_end=12-last_month\n",
    "  cyear_end_skip=2\n",
    "  MissingMonths=True\n",
    "  \n",
    "if(MissingMonths):\n",
    "  print('There are missing months in the set. '+str(missing_months_beg)+' at beginning and '+str(missing_months_end)+' at end.')\n",
    "  print('Currently years with missing months are not used in generating long term monthly climatology.')\n",
    "  print('And missing months will be set to missing in the final time-series.')\n",
    "  ts_beg,ts_end,ts_avg,dt_beg,dt_end,dt_avg=get_timestamp_number(ybeg,yend,1,12,time.units,time.calendar)\n",
    "  year_fraction_monthly_full=fractional_year_from_num2date(ts_avg,time.calendar)\n",
    "  \n",
    "  nino34_monthly_full=ma.masked_all(ydiff*nmy,dtype=float) #ensure missing months are masked out.\n",
    "  last_month_index=ydiff*nmy-last_month\n",
    "  nino34_monthly_full[first_month-1:last_month_index]=nino34_monthly\n",
    "else:\n",
    "  print('All years have 12 months.')\n",
    "  \n",
    "  nino34_monthly_full=nino34_monthly\n",
    "  year_fraction_monthly_full=year_fraction_monthly\n",
    "  \n",
    "nino34_monthly_reshaped=np.reshape(nino34_monthly_full,new_monthly_array_shape(nino34_monthly.shape,ydiff,nmy)) #check this works on large multi-dimensional arrays.\n",
    "\n",
    "'''\n",
    "#print('nino34_monthly_reshaped.shape=',nino34_monthly_reshaped.shape)\n",
    "#print('cyear_beg,end_skip=',cyear_beg_skip,cyear_end_skip)\n",
    "#print('ydiff=',ydiff)\n",
    "#j=nino34_monthly_reshaped[cyear_beg_skip:-cyear_end_skip]\n",
    "#print('j=',j)\n",
    "'''\n",
    "\n",
    "climatology=np.average(nino34_monthly_reshaped[cyear_beg_skip:-cyear_end_skip],axis=0) #average over full years only, this could be an option as could use for all years present.\n",
    "nino34_monthly_climatology=np.expand_dims(climatology,0)\n",
    "nino34_monthly_climatology=np.tile(nino34_monthly_climatology,(ydiff,1))\n",
    "nino34_monthly_climatology_flat=nino34_monthly_climatology.flatten()\n",
    "nino34_monthly_anomaly=nino34_monthly_full-nino34_monthly_climatology_flat\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "zero=np.zeros(len(year_fraction_monthly_full))\n",
    "plt.plot(year_fraction_monthly_full,nino34_monthly_anomaly)\n",
    "plt.plot(year_fraction_monthly_full,zero)\n",
    "\n",
    "plt.title('Monthly anomalies')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ni$\\~{n}$o34 ($^o$C)')\n",
    "plt.show()\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "# random Person\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    @staticmethod\n",
    "    def fromFathersAge(name, fatherAge, fatherPersonAgeDiff):\n",
    "        return Person(name, date.today().year - fatherAge + fatherPersonAgeDiff)\n",
    "\n",
    "    @classmethod\n",
    "    def fromBirthYear(cls, name, birthYear):\n",
    "        return cls(name, date.today().year - birthYear)\n",
    "\n",
    "    def display(self):\n",
    "        print(self.name + \"'s age is: \" + str(self.age))\n",
    "\n",
    "class Man(Person):\n",
    "    sex = 'Male'\n",
    "\n",
    "man = Man.fromBirthYear('John', 1985)\n",
    "print(isinstance(man, Man))\n",
    "\n",
    "man1 = Man.fromFathersAge('John', 1965, 20)\n",
    "print(isinstance(man1, Man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man1.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    TITLES = ('Dr', 'Mr', 'Mrs', 'Ms')\n",
    "\n",
    "    def __init__(self, name, surname):\n",
    "        self.name = name\n",
    "        self.surname = surname\n",
    "\n",
    "    def fullname(self): # instance method\n",
    "        # instance object accessible through self\n",
    "        return \"%s %s\" % (self.name, self.surname)\n",
    "\n",
    "    @classmethod\n",
    "    def allowed_titles_starting_with(cls, startswith): # class method\n",
    "        # class or instance object accessible through cls\n",
    "        return [t for t in cls.TITLES if t.startswith(startswith)]\n",
    "\n",
    "    @staticmethod\n",
    "    def allowed_titles_ending_with(endswith): # static method\n",
    "        # no parameter for class or instance object\n",
    "        # we have to use Person directly\n",
    "        return [t for t in Person.TITLES if t.endswith(endswith)]\n",
    "\n",
    "\n",
    "jane = Person(\"Jane\", \"Smith\")\n",
    "\n",
    "print(jane.fullname())\n",
    "\n",
    "print(jane.allowed_titles_starting_with(\"M\"))\n",
    "print(Person.allowed_titles_starting_with(\"M\"))\n",
    "\n",
    "print(jane.allowed_titles_ending_with(\"s\"))\n",
    "print(Person.allowed_titles_ending_with(\"s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://python-textbok.readthedocs.io/en/1.0/Object_Oriented_Programming.html\n",
    "#following fails, possibly need to run python3.\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, surname, number):\n",
    "        self.name = name\n",
    "        self.surname = surname\n",
    "        self.number = number\n",
    "\n",
    "\n",
    "class Student(Person):\n",
    "    UNDERGRADUATE, POSTGRADUATE = range(2)\n",
    "\n",
    "    def __init__(self, student_type, *args, **kwargs):\n",
    "        self.student_type = student_type\n",
    "        self.classes = []\n",
    "        super(Student, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def enrol(self, course):\n",
    "        self.classes.append(course)\n",
    "\n",
    "\n",
    "class StaffMember(Person):\n",
    "    PERMANENT, TEMPORARY = range(2)\n",
    "\n",
    "    def __init__(self, employment_type, *args, **kwargs):\n",
    "        self.employment_type = employment_type\n",
    "        super(StaffMember, self).__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class Lecturer(StaffMember):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.courses_taught = []\n",
    "        super(Lecturer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def assign_teaching(self, course):\n",
    "        self.courses_taught.append(course)\n",
    "\n",
    "\n",
    "jane = Student(Student.POSTGRADUATE, \"Jane\", \"Smith\", \"SMTJNX045\")\n",
    "jane.enrol(a_postgrad_course)\n",
    "\n",
    "bob = Lecturer(StaffMember.PERMANENT, \"Bob\", \"Jones\", \"123456789\")\n",
    "bob.assign_teaching(an_undergrad_course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song:\n",
    "\n",
    "    def __init__(self, title, artist, album, track_number):\n",
    "        self.title = title\n",
    "        self.artist = artist\n",
    "        self.album = album\n",
    "        self.track_number = track_number\n",
    "\n",
    "        artist.add_song(self)\n",
    "\n",
    "\n",
    "class Album:\n",
    "\n",
    "    def __init__(self, title, artist, year):\n",
    "        self.title = title\n",
    "        self.artist = artist\n",
    "        self.year = year\n",
    "\n",
    "        self.tracks = []\n",
    "\n",
    "        artist.add_album(self)\n",
    "\n",
    "    def add_track(self, title, artist=None):\n",
    "        if artist is None:\n",
    "            artist = self.artist\n",
    "\n",
    "        track_number = len(self.tracks)\n",
    "\n",
    "        song = Song(title, artist, self, track_number)\n",
    "\n",
    "        self.tracks.append(song)\n",
    "\n",
    "\n",
    "class Artist:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "        self.albums = []\n",
    "        self.songs = []\n",
    "\n",
    "    def add_album(self, album):\n",
    "        self.albums.append(album)\n",
    "\n",
    "    def add_song(self, song):\n",
    "        self.songs.append(song)\n",
    "\n",
    "\n",
    "class Playlist:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.songs = []\n",
    "\n",
    "    def add_song(self, song):\n",
    "        self.songs.append(song)\n",
    "\n",
    "band = Artist(\"Bob's Awesome Band\")\n",
    "album = Album(\"Bob's First Single\", band, 2013)\n",
    "album.add_track(\"A Ballad about Cheese\")\n",
    "album.add_track(\"A Ballad about Cheese (dance remix)\")\n",
    "album.add_track(\"A Third Song to Use Up the Rest of the Space\")\n",
    "\n",
    "playlist = Playlist(\"My Favourite Songs\")\n",
    "\n",
    "for song in album.tracks:\n",
    "    playlist.add_song(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album.artist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import relativedelta\n",
    "\n",
    "DateTickInterval = 6\n",
    "date1 = datetime.date(2013, 1, 1)\n",
    "date2 = datetime.date(2015, 12, 31)\n",
    "r = relativedelta.relativedelta(date2, date1)\n",
    "NumMonths = r.years*12 + r.months\n",
    "dates = [ date1 + relativedelta.relativedelta(months=n) for n in range(0,NumMonths+1,DateTickInterval)]\n",
    "date_strings = [dt.strftime(\"%d/%m/%Y\") for dt in dates]\n",
    "print date_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
