{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_netcdf_compression\n",
    "\n",
    "# last edited 2 October 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "hostname= oa-32-cdc\n",
      "this is vm32\n",
      "Current Working Directory= /OSM/CBR/OA_DCFP/work/col414/cafepp\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "__file__='jupyter_notebook' #this can be deleted when written to a python script and loaded as module.\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4\n",
    "import inspect\n",
    "# import pickle\n",
    "# import bz2\n",
    "# import glob\n",
    "import socket\n",
    "import re\n",
    "import os\n",
    "import timeit\n",
    "# import scipy.stats as st\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# from scipy import stats\n",
    "# import pandas as pd\n",
    "# from matplotlib.ticker import ScalarFormatter, FormatStrFormatter, FixedLocator\n",
    "\n",
    "CRED = '\\033[91m'\n",
    "CEND = '\\033[0m'\n",
    "\n",
    "hostname=socket.gethostname()\n",
    "\n",
    "print('hostname=',hostname)\n",
    "\n",
    "if(re.match('raijin',hostname)):\n",
    "  print('this is rajin')\n",
    "  rundir='/short/v14/mac599/cafepp/rundir'\n",
    "  topdir=''\n",
    "elif(re.match('oa-3.-cdc',hostname)):\n",
    "  print('this is vm32')\n",
    "  rundir='/OSM/CBR/OA_DCFP/work/col414/cafepp'\n",
    "  topdir='/OSM/CBR/OA_DCFP/data/CAFEPP/CMIP6'\n",
    "\n",
    "os.chdir(rundir)\n",
    "\n",
    "os.chdir('/OSM/CBR/OA_DCFP/work/col414/cafepp')\n",
    "\n",
    "print('Current Working Directory=',os.getcwd())\n",
    "\n",
    "from n_data_funcs import n_data_funcs\n",
    "\n",
    "from decadal_diag import \\\n",
    "  convert_bytes, \\\n",
    "  file_size, \\\n",
    "  compress_nc\n",
    "  \n",
    "#   box_indices, \\\n",
    "#   diag_isothetaoNc, \\\n",
    "#   calc_isoN, \\\n",
    "#   shade_2d_latlon, \\\n",
    "#   shade_2d_simple, \\\n",
    "#   smooth, \\\n",
    "#   plot_xy, \\\n",
    "#   plot_box_indices, \\\n",
    "#   nino_indices, \\\n",
    "#   plot_2d_scatter, \\\n",
    "#   lagcorr, \\\n",
    "#   file_sort_ripf, \\\n",
    "#   file_spec_summary, \\\n",
    "#   basic_stats\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "      \n",
    "def compress_nc(input_file, output_file, **kwargs):\n",
    "  '''\n",
    "  Copy the entire contents of a file and apply compression to output variables.\n",
    "  Note all options & combinations tested.\n",
    "  \n",
    "  If Diag=True, put it first in the list of option/arguments.\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  import numpy as np\n",
    "  import netCDF4\n",
    "  import inspect\n",
    "  import os\n",
    "  import timeit\n",
    "  import datetime\n",
    "\n",
    "  Diag=zlib=Clobber=False\n",
    "  history=True\n",
    "  nc_model='NETCDF4_CLASSIC'\n",
    "\n",
    "  for key, value in kwargs.items():\n",
    "    if(key=='Diag'):\n",
    "      Diag=bool(value)\n",
    "      if(Diag): print('Turning on diagnostics.')\n",
    "    elif(key=='nc_model'):\n",
    "      nc_model=value\n",
    "      if(Diag): print('Using nc model=',nc_model)\n",
    "    elif(key=='compression'):\n",
    "      zlib=True\n",
    "      complevel=int(value)\n",
    "      if(Diag and zlib): print('Compressing with level (b/w 1-9)=',complevel)\n",
    "    elif(key=='history'):\n",
    "      history=bool(value)\n",
    "      if(Diag and history): print('global history attribute being appended to or created.')\n",
    "    elif(key=='Clobber'):\n",
    "      Clobber=bool(value)\n",
    "      if(Diag and Clobber): print('Overwriting output file if it exists.')\n",
    "    \n",
    "  #if(Diag): time_start = timeit.timeit()\n",
    "  \n",
    "  input_file_size=file_size(input_file)\n",
    "  \n",
    "  print('Input file: '+input_file+', File size='+input_file_size)\n",
    "  print('Output file: '+output_file)\n",
    "  \n",
    "  if(Clobber and os.path.exists(output_file)):\n",
    "    os.remove(output_file)\n",
    "      \n",
    "  ifh = netCDF4.Dataset(input_file, 'r')\n",
    "\n",
    "  global_dictionary = {}\n",
    "  for attr in ifh.ncattrs():\n",
    "    global_dictionary[attr] = getattr(ifh,attr)\n",
    "\n",
    "  #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "  dims_dictionary = {}\n",
    "  for dims in ifh.dimensions.keys():\n",
    "    dims_dictionary[ifh.dimensions[dims].name] = ifh.dimensions[dims].size\n",
    "\n",
    "  ofh = netCDF4.Dataset(output_file, 'w', format=nc_model)\n",
    "\n",
    "  dims_dictionary_out = {}\n",
    "  for dims in dims_dictionary.keys():\n",
    "\n",
    "    dims_dictionary_out[dims] = ofh.createDimension(dims, dims_dictionary[dims])\n",
    "\n",
    "  vars_dictionary_out = {}\n",
    "  for cnt, var in enumerate(ifh.variables.keys()):\n",
    "    if(Diag): print('cnt,var=',cnt,var)\n",
    "\n",
    "    input_variable = ifh.variables[var]\n",
    "    \n",
    "    input_variable_atts_tmp=input_variable.ncattrs()\n",
    "    \n",
    "    try:\n",
    "      fill_value_locator=input_variable_atts_tmp.index('_FillValue')\n",
    "    except ValueError:\n",
    "      fill_value_locator=-1\n",
    "    \n",
    "    #print('fill_value_locator=',fill_value_locator)\n",
    "    \n",
    "    if(fill_value_locator>=0):\n",
    "      fill_value=getattr(input_variable, '_FillValue')\n",
    "    else:\n",
    "      fill_value=None\n",
    "      \n",
    "    #print('fill_value=',fill_value)\n",
    "    \n",
    "    #print('input_variable_atts_tmp',input_variable_atts_tmp)\n",
    "    \n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "      \n",
    "    dims_dictionary_out[var] = ofh.createVariable(var, \\\n",
    "                                                    ifh.variables[var].datatype, \\\n",
    "                                                    ifh.variables[var].dimensions, \\\n",
    "                                                    zlib=zlib, \\\n",
    "                                                    complevel=complevel, fill_value=fill_value)\n",
    "\n",
    "\n",
    "    \n",
    "    #print('var_dictionary=',var_dictionary)\n",
    "    \n",
    "    var_dictionary = {}\n",
    "    \n",
    "    #strip off _FillValue as defined at variable definition time.\n",
    "    input_variable_atts=[]\n",
    "    for input_variable_att in input_variable_atts_tmp:\n",
    "      if(input_variable_att!='_FillValue'):\n",
    "        input_variable_atts.append(input_variable_att)\n",
    "        \n",
    "    #print('input_variable_atts=',input_variable_atts)\n",
    "    \n",
    "    for attr in input_variable_atts:\n",
    "      #print('attr=',attr)\n",
    "      var_dictionary[attr] = getattr(input_variable, attr)\n",
    "      \n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    \n",
    "    #print('var_dictionary=',var_dictionary)\n",
    "    \n",
    "    dims_dictionary_out[var][:] = input_variable[:]\n",
    "    \n",
    "    dims_dictionary_out[var].setncatts(var_dictionary)\n",
    "\n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    \n",
    "  ofh.sync()\n",
    "  \n",
    "  output_file_size=file_size(output_file)\n",
    "  \n",
    "  compression=100* (1 - float(output_file_size.split()[0])/float(input_file_size.split()[0]))\n",
    "  \n",
    "  if(history):\n",
    "    history_to_append = ' compress_nc.py: input_file='+input_file+ \\\n",
    "    ', output file='+output_file+ \\\n",
    "    ', compressions='+str(compression)+ \\\n",
    "    ', creation time='+str(datetime.datetime.now())+'.'\n",
    "  \n",
    "    try:\n",
    "      history_value=global_dictionary['history']+history_to_append\n",
    "    except KeyError:\n",
    "      history_value=history_to_append\n",
    "    \n",
    "  #print(history)\n",
    "  \n",
    "    global_dictionary['history'] = history_value\n",
    "  \n",
    "  ofh.setncatts(global_dictionary)\n",
    "\n",
    "  print('Output file: '+output_file+', File size='+output_file_size+', Compression (approx.)='+str(compression)+'%.')\n",
    "    \n",
    "  ofh.close()\n",
    "\n",
    "  #if(Diag): print('Total time =',timeit.timeit() - time_start)\n",
    "  \n",
    "  return(0) #end of compress_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "kwargs.items()= dict_items([('Diag', True), ('nc_model', 'NETCDF4_CLASSIC'), ('compression', 1), ('Clobber', True), ('history', True)])\n",
      "Turning on diagnostics.\n",
      "Using nc model= NETCDF4_CLASSIC\n",
      "Compressing with level (b/w 1-9)= 1\n",
      "Overwriting output file if it exists.\n",
      "global history attribute being appended to or created.\n",
      "Input file: /OSM/CBR/OA_DCFP/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT/land_month_0500_01.nc, File size=28.0 MB\n",
      "Output file: ./test.nc\n",
      "cnt,var= 0 lon\n",
      "cnt,var= 1 lonb\n",
      "cnt,var= 2 lat\n",
      "cnt,var= 3 latb\n",
      "cnt,var= 4 time\n",
      "cnt,var= 5 nv\n",
      "cnt,var= 6 scalar_axis\n",
      "cnt,var= 7 zfull\n",
      "cnt,var= 8 zhalf\n",
      "cnt,var= 9 disch_w\n",
      "cnt,var= 10 disch_s\n",
      "cnt,var= 11 area\n",
      "cnt,var= 12 ground_type\n",
      "cnt,var= 13 hlf\n",
      "cnt,var= 14 hlv\n",
      "cnt,var= 15 lfrac\n",
      "cnt,var= 16 albedo\n",
      "cnt,var= 17 evap\n",
      "cnt,var= 18 flw\n",
      "cnt,var= 19 fsw\n",
      "cnt,var= 20 frozen\n",
      "cnt,var= 21 groundwater\n",
      "cnt,var= 22 latent\n",
      "cnt,var= 23 precip\n",
      "cnt,var= 24 sens\n",
      "cnt,var= 25 temp\n",
      "cnt,var= 26 water\n",
      "cnt,var= 27 average_T1\n",
      "cnt,var= 28 average_T2\n",
      "cnt,var= 29 average_DT\n",
      "cnt,var= 30 time_bounds\n",
      "Output file: ./test.nc, File size=6.5 MB, Compression (approx.)=76.78571428571428%.\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "idir='/OSM/CBR/OA_DCFP/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT'\n",
    "ifil='land_month_0500_01.nc'\n",
    "\n",
    "#idir='/OSM/CBR/OA_DCFP/data/CAFEPP'\n",
    "#ifil='coastal-stns-Vol-monthly.updated-oct2007.nc'\n",
    "\n",
    "status = compress_nc(idir+'/'+ifil, './test.nc', Diag=True, nc_model='NETCDF4_CLASSIC', compression=1, Clobber=True, history=True)\n",
    "  \n",
    "if(status!=0):\n",
    "  raise SystemExit('compress_nc non-zero return status:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "#===============================================================================\n",
    "\n",
    "idir='/OSM/CBR/OA_DCFP/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT'\n",
    "ifil='ocean_month_0500_01.nc'\n",
    "\n",
    "idir='/OSM/CBR/OA_DCFP/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT'\n",
    "ifil='atmos_month_0500_01.nc'\n",
    "\n",
    "print('Input file: '+idir+'/'+ifil)\n",
    "\n",
    "odir='.'\n",
    "\n",
    "nc_models = ['nc4_classic', 'nc4_classic', 'nc4_classic']\n",
    "zlibs = [False, True, True]\n",
    "complevel = [1, 1, 9]\n",
    "\n",
    "for nc_cnt,nc_model in enumerate(nc_models):\n",
    "  \n",
    "  time_start = timeit.timeit()\n",
    "  \n",
    "  name_tokens=['nccomp']\n",
    "  \n",
    "  if(nc_model=='nc4_classic'):\n",
    "    name_tokens.append('nc4c')\n",
    "  \n",
    "  if(zlibs[nc_cnt]):\n",
    "    name_tokens.append('zlib'+str(complevel[nc_cnt]))\n",
    "\n",
    "  ofil=('_'.join(name_tokens))+'.nc'\n",
    "  \n",
    "  print('Output file: '+odir+'/'+ofil)\n",
    "  \n",
    "  if(os.path.exists(odir+'/'+ofil)):\n",
    "    os.remove(odir+'/'+ofil)\n",
    "  #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "  ifh = netCDF4.Dataset(idir+'/'+ifil, 'r')\n",
    "\n",
    "  global_dictionary = {}\n",
    "  for attr in ifh.ncattrs():\n",
    "    global_dictionary[attr] = getattr(ifh,attr)\n",
    "  #global_dictionary['history'] = 'File generated using raijin:~mac599/decadal/paper_analysis/matt_ozone.ipynb combining CMIP6 ozone files and modified units to be in kg/kg suitable for reading into coupled model. Written as NETCDF3_CLASSIC.'\n",
    "\n",
    "  print('global_dictionary=',global_dictionary)\n",
    "\n",
    "  # print('ifh.dimensions=',ifh.dimensions)\n",
    "  # print('ifh.dimensions.values=',ifh.dimensions.values)\n",
    "\n",
    "  dims_dictionary = {}\n",
    "  for dims in ifh.dimensions.keys():\n",
    "    dims_dictionary[ifh.dimensions[dims].name] = ifh.dimensions[dims].size\n",
    "  # print('dims_dictionary=',dims_dictionary)\n",
    "\n",
    "  ofh = netCDF4.Dataset(odir+'/'+ofil, 'w', format='NETCDF4_CLASSIC') #NETCDF3_64BIT_OFFSET, NETCDF3_CLASSIC, NETCDF4_CLASSIC, NETCDF4\n",
    "\n",
    "  dims_dictionary_out = {}\n",
    "  for dims in dims_dictionary.keys():\n",
    "    #print('dims=',dims)\n",
    "    dims_dictionary_out[dims] = ofh.createDimension(dims, dims_dictionary[dims])\n",
    "  #print(dims_dictionary_out)\n",
    "\n",
    "  #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "  #print('ifh.variables.keys()=',ifh.variables.keys())\n",
    "  vars_dictionary_out = {}\n",
    "  cnt=0\n",
    "  for var in ifh.variables.keys():\n",
    "    print('cnt,var=',cnt,var)\n",
    "  #   print('name=',ifh.variables['xt_ocean'].name)\n",
    "  #   print('dimensions=',ifh.variables['xt_ocean'].dimensions)\n",
    "  #   print('datatype=',ifh.variables['xt_ocean'].datatype)\n",
    "  #   print('dir(ifh.variables[\"xt_ocean\"])=',dir(ifh.variables['xt_ocean']))\n",
    "    #print('dir(ifh.variables[var])=',dir(ifh.variables[var]))\n",
    "\n",
    "    if(zlibs[nc_cnt]):\n",
    "        dims_dictionary_out[var] = ofh.createVariable(var, \\\n",
    "                                                      ifh.variables[var].datatype, \\\n",
    "                                                      ifh.variables[var].dimensions, \\\n",
    "                                                      zlib=True, \\\n",
    "                                                      complevel=complevel[nc_cnt])\n",
    "    else:\n",
    "      dims_dictionary_out[var] = ofh.createVariable(var, \\\n",
    "                                                    ifh.variables[var].datatype, \\\n",
    "                                                    ifh.variables[var].dimensions)\n",
    "\n",
    "    #print('dims_dictionary_out=',dims_dictionary_out)\n",
    "    \n",
    "    input_variable = ifh.variables[var]\n",
    "    \n",
    "    var_dictionary = {}\n",
    "    for attr in input_variable.ncattrs():\n",
    "      var_dictionary[attr] = getattr(input_variable, attr)\n",
    "      \n",
    "    #print('var_dictionary=',var_dictionary)\n",
    "\n",
    "    dims_dictionary_out[var][:] = input_variable[:]\n",
    "    \n",
    "    dims_dictionary_out[var].setncatts(var_dictionary)\n",
    "\n",
    "    #ofh.close()\n",
    "\n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "  #   if(cnt==3):\n",
    "  #     ofh.close()\n",
    "  #     break\n",
    "\n",
    "\n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    cnt+=1\n",
    "\n",
    "  ofh.setncatts(global_dictionary)\n",
    "  \n",
    "  print('Total time =',timeit.timeit() - time_start)\n",
    "  \n",
    "  ofh.close()\n",
    "\n",
    "#===============================================================================\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
