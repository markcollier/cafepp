{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_vertical_interpolation\n",
    "\n",
    "see interpolate_f1_to_isobaric.ipynb\n",
    "\n",
    "\n",
    "# last edited 12 October 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "hostname= oa-35-cdc\n",
      "this is vm32\n",
      "Current Working Directory= /OSM/CBR/OA_DCFP/work/col414/cafepp\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "__file__='jupyter_notebook' #this can be deleted when written to a python script and loaded as module.\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4\n",
    "import inspect\n",
    "# import pickle\n",
    "# import bz2\n",
    "import glob\n",
    "import socket\n",
    "import re\n",
    "import os\n",
    "import timeit\n",
    "import subprocess\n",
    "# import scipy.stats as st\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# from scipy import stats\n",
    "# import pandas as pd\n",
    "# from matplotlib.ticker import ScalarFormatter, FormatStrFormatter, FixedLocator\n",
    "import sys\n",
    "import shlex\n",
    "from subprocess import Popen, PIPE\n",
    "import shutil\n",
    "\n",
    "def get_exitcode_stdout_stderr(cmd):\n",
    "    \"\"\"\n",
    "    Execute the external command and get its exitcode, stdout and stderr.\n",
    "    \"\"\"\n",
    "    args = shlex.split(cmd)\n",
    " \n",
    "    proc = Popen(args, stdout=PIPE, stderr=PIPE)\n",
    "    out, err = proc.communicate()\n",
    "    exitcode = proc.returncode\n",
    "    #\n",
    "    return exitcode, out, err\n",
    "\n",
    "CRED = '\\033[91m'\n",
    "CEND = '\\033[0m'\n",
    "\n",
    "hostname=socket.gethostname()\n",
    "\n",
    "print('hostname=',hostname)\n",
    "\n",
    "if(re.match('raijin',hostname)):\n",
    "  print('this is rajin')\n",
    "  rundir='/short/v14/mac599/cafepp/rundir'\n",
    "  topdir=''\n",
    "elif(re.match('oa-3.-cdc',hostname)):\n",
    "  print('this is vm32')\n",
    "  rundir='/OSM/CBR/OA_DCFP/work/col414/cafepp'\n",
    "  topdir='/OSM/CBR/OA_DCFP/data/CAFEPP/CMIP6'\n",
    "\n",
    "os.chdir(rundir)\n",
    "\n",
    "os.chdir('/OSM/CBR/OA_DCFP/work/col414/cafepp')\n",
    "\n",
    "print('Current Working Directory=',os.getcwd())\n",
    "\n",
    "from n_data_funcs import n_data_funcs\n",
    "\n",
    "from decadal_diag import \\\n",
    "  convert_bytes, \\\n",
    "  file_size, \\\n",
    "  compress_nc\n",
    "  \n",
    "#   box_indices, \\\n",
    "#   diag_isothetaoNc, \\\n",
    "#   calc_isoN, \\\n",
    "#   shade_2d_latlon, \\\n",
    "#   shade_2d_simple, \\\n",
    "#   smooth, \\\n",
    "#   plot_xy, \\\n",
    "#   plot_box_indices, \\\n",
    "#   nino_indices, \\\n",
    "#   plot_2d_scatter, \\\n",
    "#   lagcorr, \\\n",
    "#   file_sort_ripf, \\\n",
    "#   file_spec_summary, \\\n",
    "#   basic_stats\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('BEGIN')\n",
    "\n",
    "# input_files=sorted(glob.glob('/OSM/CBR/OA_DCFP/data/intermediate_products/squ027/f1_isobaric/yr2003/mn1/OUTPUT.1/atmos_daily_????_01_01.plevel.nc'))\n",
    "\n",
    "# ifhN=netCDF4.MFDataset(input_files)\n",
    "\n",
    "# print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n"
     ]
    }
   ],
   "source": [
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "      \n",
    "def prepare_vertintp(input_data_file, input_grid_file, output_file, **kwargs):\n",
    "  '''\n",
    "  Copy the entire contents of a file and apply compression to output variables.\n",
    "  Note all options & combinations tested.\n",
    "  \n",
    "  If Diag=True, put it first in the list of option/arguments.\n",
    "\n",
    "  prepare_vertintp(input_data_file, input_grid_file, output_filet, Diag=True/False, nc_model=['NETCDF4_CLASSIC',...], compresssion=[1...9], history=True/False, Clobber=True/False)\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  import numpy as np\n",
    "  import netCDF4\n",
    "  import inspect\n",
    "  import os\n",
    "  import timeit\n",
    "  import datetime\n",
    "\n",
    "  Diag=zlib=Clobber=False\n",
    "  history=True\n",
    "  nc_model='NETCDF4_CLASSIC'\n",
    "\n",
    "  #print('kwargs.items()=',kwargs.items())\n",
    "\n",
    "  for key, value in kwargs.items():\n",
    "    if(key=='Diag'):\n",
    "      if(str(value)=='True'):\n",
    "        Diag=True\n",
    "      elif(str(value)=='False'):\n",
    "        Diag=False\n",
    "      else:\n",
    "        raise SystemExit('Diag either True or False:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "      if(Diag): print('Turning on diagnostics.')\n",
    "    elif(key=='nc_model'):\n",
    "      nc_model=value\n",
    "      if(Diag): print('Using nc model=',nc_model)\n",
    "    elif(key=='compression'):\n",
    "      zlib=True\n",
    "      complevel=int(value)\n",
    "      if(Diag and zlib): print('Compressing with level (b/w 1-9)=',complevel)\n",
    "    elif(key=='history'):\n",
    "      if(str(value)=='True'):\n",
    "        history=True\n",
    "      elif(str(value)=='False'):\n",
    "        history=False\n",
    "      else:\n",
    "        raise SystemExit('history either True or False:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "      if(Diag and history): print('global history attribute being appended to or created.')\n",
    "    elif(key=='Clobber'):\n",
    "      if(str(value)=='True'):\n",
    "        Clobber=True\n",
    "      elif(str(value)=='False'):\n",
    "        Clobber=False\n",
    "      else:\n",
    "        raise SystemExit('Clobber either True or False:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "      if(Diag and Clobber): print('Overwriting output file if it exists.')\n",
    "    \n",
    "  #print('input grid file=',input_grid_file)\n",
    "  \n",
    "  if(not os.path.exists(input_data_file)):\n",
    "    raise SystemExit('input data file, '+input_data_file+', doesnt exist:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "  if(type(input_grid_file)!=type(None) and not os.path.exists(input_grid_file)):\n",
    "    raise SystemExit('input grid file, '+input_grid_file+', doesnt exist:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    \n",
    "  #print('Clobber=',Clobber)\n",
    "  #print('type(Clobber)=',type(Clobber))\n",
    "\n",
    "  #if(Diag): time_start = timeit.timeit()\n",
    "  \n",
    "  input_data_file_size=file_size(input_data_file)\n",
    "  \n",
    "  if(type(input_grid_file)!=type(None)):\n",
    "    input_grid_file_size=file_size(input_grid_file)\n",
    "  \n",
    "  print('Input data file: '+input_data_file+', File size='+input_data_file_size)\n",
    "  if(type(input_grid_file)!=type(None)):\n",
    "    print('Input grid file: '+input_grid_file+', File size='+input_grid_file_size)\n",
    "  print('Output file: '+output_file)\n",
    "  \n",
    "  if(not Clobber and os.path.exists(output_file)):\n",
    "    raise SystemExit('not Clobber and output exists:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "  if(Clobber and os.path.exists(output_file)):\n",
    "    os.remove(output_file)\n",
    "\n",
    "  #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "  if(type(input_grid_file)!=type(None)):\n",
    "    ifh_grid = netCDF4.Dataset(input_grid_file, 'r')\n",
    "\n",
    "    ak = ifh_grid.variables['ak']\n",
    "    bk = ifh_grid.variables['bk']\n",
    "    zsurf = ifh_grid.variables['zsurf']\n",
    "  \n",
    "      \n",
    "  ifh_data = netCDF4.Dataset(input_data_file, 'r')\n",
    "\n",
    "#   print(dir(ifh_data.dimensions['lat']))\n",
    "#   print(ifh_data.dimensions['lat'].size)\n",
    "#   print(ifh_data.dimensions['lat'].isunlimited)\n",
    "  \n",
    "#   raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "  ofh = netCDF4.Dataset(output_file, 'w', format=nc_model)\n",
    "    \n",
    "  global_dictionary = {}\n",
    "  for attr in ifh_data.ncattrs():\n",
    "    global_dictionary[attr] = getattr(ifh_data,attr)\n",
    "\n",
    "  dims_dictionary = {}\n",
    "  for dims in ifh_data.dimensions.keys():\n",
    "#     print('dims=', dims, ifh_data.dimensions[dims].size, ifh_data.dimensions[dims].isunlimited)\n",
    "    \n",
    "#     if(ifh_data.dimensions[dims].isunlimited):\n",
    "#       print('yes')\n",
    "    \n",
    "#currently, convert all time dimensions to unlimited.\n",
    "    if(dims=='time'): #PLEV.exe seems to need unlimited time dimensions to work.\n",
    "      dims_dictionary[ifh_data.dimensions[dims].name] = 0\n",
    "      #dims_dictionary[ifh_data.dimensions[dims].name] = ifh_data.dimensions[dims].size\n",
    "    else:\n",
    "      dims_dictionary[ifh_data.dimensions[dims].name] = ifh_data.dimensions[dims].size\n",
    "\n",
    "  #dims_dictionary['phalf'] = ifh_grid.dimensions['phalf'].size\n",
    "  \n",
    "  #print(dims_dictionary)\n",
    "  \n",
    "#   phalf_test=True #assume in file.\n",
    "  ps_test=phalf_test=bk_test=pk_test=zsurf_test=False #assume not in file.\n",
    "  \n",
    "#   try:\n",
    "#     dummy=dims_dictionary['phalf']\n",
    "#   except KeyError:\n",
    "#     dims_dictionary['phalf'] = ifh_grid.dimensions['phalf'].size\n",
    "#     phalf = ifh_grid.variables['phalf']\n",
    "#     phalf_test=False\n",
    "\n",
    "  #ofh.close()\n",
    "  #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))      \n",
    "\n",
    "  dims_dictionary_out = {}\n",
    "  for dims in dims_dictionary.keys():\n",
    "    #print('xxx',dims,dims_dictionary[dims],ifh_data.dimensions[dims].isunlimited)\n",
    "    \n",
    "#     if(ifh_data.dimensions[dims].isunlimited):\n",
    "#       print('aaa')\n",
    "#     else:\n",
    "#       print('bbb')\n",
    "\n",
    "#     if(dims=='time'):\n",
    "#       dims_size = None\n",
    "#     else:\n",
    "#       dims_size = ifh_data.dimensions[dims].size\n",
    "      \n",
    "    dims_dictionary_out[dims] = ofh.createDimension(dims, dims_dictionary[dims])\n",
    "    #dims_dictionary_out[dims] = ofh.createDimension(dims, size=dims_size)\n",
    "    #dims_dictionary_out[dims] = ofh.createDimension(dims), size=ifh_data.dimensions[dims].isunlimited)\n",
    "    \n",
    "#     if(dims=='time'):\n",
    "#       ofh.sync()\n",
    "#       ofh.close()\n",
    "#       raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "#   all_vars=ifh_data.variables\n",
    "  \n",
    "#   print(type(all_vars))\n",
    "  \n",
    "#   #print(ifh_data.variables.values())\n",
    "\n",
    "#   pk_test = all_vars.get('pk', None)\n",
    "  \n",
    "  #print(pk_test)\n",
    "  \n",
    "#   try:\n",
    "#     dummy=dims_dictionary['phalf']\n",
    "#   except KeyError:\n",
    "#     dims_dictionary['phalf'] = ifh_grid.dimensions['phalf'].size\n",
    "#     phalf = ifh_grid.variables['phalf']\n",
    "#     phalf_test=False\n",
    "\n",
    "  #if all_vars.has_key('key1'):\n",
    "    \n",
    "  #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    \n",
    "  #vars_dictionary_out = {}\n",
    "\n",
    "\n",
    "  for cnt, var in enumerate(ifh_data.variables.keys()):\n",
    "    if(Diag): print('cnt,var=',cnt,var)\n",
    "      \n",
    "    if(var=='pk'):\n",
    "      pk_test=True\n",
    "    elif(var=='bk'):\n",
    "      bk_test=True\n",
    "    elif(var=='zsurf'):\n",
    "      zsurf_test=True\n",
    "    elif(var=='phalf'):\n",
    "      phalf_test=True\n",
    "    elif(var=='ps'):\n",
    "      ps_test=True   \n",
    "      \n",
    "    input_variable = ifh_data.variables[var]\n",
    "    \n",
    "    input_variable_atts_tmp=input_variable.ncattrs()\n",
    "    \n",
    "    try:\n",
    "      fill_value_locator=input_variable_atts_tmp.index('_FillValue')\n",
    "    except ValueError:\n",
    "      fill_value_locator=-1\n",
    "    \n",
    "    #print('fill_value_locator=',fill_value_locator)\n",
    "    \n",
    "    if(fill_value_locator>=0):\n",
    "      fill_value=getattr(input_variable, '_FillValue')\n",
    "    else:\n",
    "      fill_value=None\n",
    "      \n",
    "    #print('fill_value=',fill_value)\n",
    "    \n",
    "    #print('input_variable_atts_tmp',input_variable_atts_tmp)\n",
    "    \n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "      \n",
    "#     dims_dictionary_out[var] = ofh.createVariable(var, \\\n",
    "#                                                     ifh_data.variables[var].datatype, \\\n",
    "#                                                     ifh_data.variables[var].dimensions, \\\n",
    "#                                                     zlib=zlib, \\\n",
    "#                                                     complevel=complevel, fill_value=fill_value)\n",
    "\n",
    "\n",
    "    dims_dictionary_out[var] = ofh.createVariable(var, \\\n",
    "                                                    ifh_data.variables[var].datatype, \\\n",
    "                                                    ifh_data.variables[var].dimensions, \\\n",
    "                                                    zlib=False, \\\n",
    "                                                    complevel=complevel, fill_value=fill_value)\n",
    "    \n",
    "    #print('var_dictionary=',var_dictionary)\n",
    "    \n",
    "    var_dictionary = {}\n",
    "    \n",
    "    #strip off _FillValue as defined at variable definition time.\n",
    "    input_variable_atts=[]\n",
    "    for input_variable_att in input_variable_atts_tmp:\n",
    "      if(input_variable_att!='_FillValue'):\n",
    "        input_variable_atts.append(input_variable_att)\n",
    "        \n",
    "    #print('input_variable_atts=',input_variable_atts)\n",
    "    \n",
    "    for attr in input_variable_atts:\n",
    "      #print('attr=',attr)\n",
    "      var_dictionary[attr] = getattr(input_variable, attr)\n",
    "      \n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    \n",
    "    #print('var_dictionary=',var_dictionary)\n",
    "    \n",
    "    dims_dictionary_out[var][:] = input_variable[:]\n",
    "    \n",
    "    dims_dictionary_out[var].setncatts(var_dictionary)\n",
    "\n",
    "    #raise SystemExit('STOP!:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  if(not ps_test):\n",
    "    raise SystemExit('ps missing from data file:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "    \n",
    "  if(type(input_grid_file)!=type(None)):\n",
    "\n",
    "    if(not pk_test):\n",
    "      try:\n",
    "        pk_fill=ifh_grid.variables['ak']._FillValue\n",
    "      except:\n",
    "        pk_fill=None\n",
    "      pk_var = ofh.createVariable('pk', ifh_grid.variables['ak'].datatype, \\\n",
    "                                 ifh_grid.variables['ak'].dimensions, \\\n",
    "                                fill_value=pk_fill \\\n",
    "                                 )\n",
    "      pk_var[:] = ak[:]\n",
    "      ak_atts=ak.ncattrs()\n",
    "      ak_dictionary={}\n",
    "      for ak_att in ak_atts:\n",
    "        if(ak_att!='_FillValue'):\n",
    "          ak_dictionary[ak_att] = getattr(ak, ak_att)\n",
    "      pk_setatts=pk_var.setncatts(ak_dictionary)\n",
    "    \n",
    "    if(not bk_test):\n",
    "      try:\n",
    "        bk_fill=ifh_grid.variables['bk']._FillValue\n",
    "      except:\n",
    "        bk_fill=None\n",
    "      bk_var = ofh.createVariable('bk', ifh_grid.variables['bk'].datatype, \\\n",
    "                                 ifh_grid.variables['bk'].dimensions, \\\n",
    "                                fill_value=bk_fill \\\n",
    "                                 )\n",
    "      bk_var[:] = bk[:]\n",
    "      bk_atts=bk.ncattrs()\n",
    "      bk_dictionary={}\n",
    "      for bk_att in bk_atts:\n",
    "        if(bk_att!='_FillValue'):\n",
    "          bk_dictionary[bk_att] = getattr(bk, bk_att)\n",
    "      bk_setatts=bk_var.setncatts(bk_dictionary)\n",
    "    \n",
    "    if(not zsurf_test):\n",
    "      try:\n",
    "        zsurf_fill=ifh_grid.variables['zsurf']._FillValue\n",
    "      except:\n",
    "        zsurf_fill=None\n",
    "      zsurf_var = ofh.createVariable('zsurf', ifh_grid.variables['zsurf'].datatype, \\\n",
    "                                 ifh_grid.variables['zsurf'].dimensions, \\\n",
    "                                fill_value=zsurf_fill \\\n",
    "                                 )\n",
    "      zsurf_var[:] = zsurf[:]\n",
    "      zsurf_atts=zsurf.ncattrs()\n",
    "      zsurf_dictionary={}\n",
    "      for zsurf_att in zsurf_atts:\n",
    "        if(zsurf_att!='_FillValue'):\n",
    "          zsurf_dictionary[zsurf_att] = getattr(zsurf, zsurf_att)\n",
    "      zsurf_setatts=zsurf_var.setncatts(zsurf_dictionary)\n",
    "    \n",
    "    if(not phalf_test):\n",
    "      try:\n",
    "        phalf_fill=ifh_grid.variables['phalf']._FillValue\n",
    "      except:\n",
    "        phalf_fill=None      \n",
    "      phalf_var = ofh.createVariable('phalf', ifh_grid.variables['phalf'].datatype, \\\n",
    "                               ifh_grid.variables['phalf'].dimensions, \\\n",
    "                              fill_value=phalf_fill \\\n",
    "                               )\n",
    "      phalf_var[:] = phalf[:]\n",
    "      \n",
    "      phalf_atts=phalf.ncattrs()\n",
    "      phalf_dictionary={}\n",
    "      for phalf_att in phalf_atts:\n",
    "        if(phalf_att!='_FillValue'):\n",
    "          phalf_dictionary[phalf_att] = getattr(phalf, phalf_att)\n",
    "      phalf_setatts=phalf_var.setncatts(phalf_dictionary)\n",
    "    \n",
    "  ofh.sync()\n",
    "  \n",
    "  output_file_size=file_size(output_file)\n",
    "  \n",
    "  compression=100* (1 - float(output_file_size.split()[0])/float(input_data_file_size.split()[0]))\n",
    "  \n",
    "  if(history):\n",
    "    history_to_append = ' prepare_vertintp.py:'+ \\\n",
    "    ' input_data_file='+input_data_file+ \\\n",
    "    ' input_grid_file='+str(input_grid_file)+ \\\n",
    "    ', output file='+output_file+ \\\n",
    "    ', compressions='+str(compression)+ \\\n",
    "    ', creation time='+str(datetime.datetime.now())+'.'\n",
    "  \n",
    "    try:\n",
    "      history_value=global_dictionary['history']+history_to_append\n",
    "    except KeyError:\n",
    "      history_value=history_to_append\n",
    "    \n",
    "  #print(history)\n",
    "  \n",
    "    global_dictionary['history'] = history_value\n",
    "  \n",
    "  ofh.setncatts(global_dictionary)\n",
    "\n",
    "  print('Output file: '+output_file+', File size='+output_file_size+', Compression (approx.)='+str(compression)+'%.')\n",
    "    \n",
    "  ofh.close()\n",
    "\n",
    "  #if(Diag): print('Total time =',timeit.timeit() - time_start)\n",
    "  \n",
    "  return(0) #end of prepare_vertintp\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "Turning on diagnostics.\n",
      "Using nc model= NETCDF4_CLASSIC\n",
      "Compressing with level (b/w 1-9)= 1\n",
      "Overwriting output file if it exists.\n",
      "global history attribute being appended to or created.\n",
      "Input data file: /OSM/CBR/OA_DCFP/work/col414/CAFEPP/short/v19/mac599/ao_am2/oct18a/OUTPUT/atmos_daily_1980_01_01.nc, File size=2.4 GB\n",
      "Input grid file: /OSM/CBR/OA_DCFP/work/squ027/squire_scratch/projects/cafe_hybrid_to_isobaric/shared/cafe_grid_info.nc, File size=118.1 KB\n",
      "Output file: ./test4.nc\n",
      "cnt,var= 0 lon\n",
      "cnt,var= 1 lonb\n",
      "cnt,var= 2 lat\n",
      "cnt,var= 3 latb\n",
      "cnt,var= 4 time\n",
      "cnt,var= 5 nv\n",
      "cnt,var= 6 phalf\n",
      "cnt,var= 7 pfull\n",
      "cnt,var= 8 evap\n",
      "cnt,var= 9 lwflx\n",
      "cnt,var= 10 shflx\n",
      "cnt,var= 11 t_ref\n",
      "cnt,var= 12 q_ref\n",
      "cnt,var= 13 u_ref\n",
      "cnt,var= 14 v_ref\n",
      "cnt,var= 15 t_surf\n",
      "cnt,var= 16 t_ref_min\n",
      "cnt,var= 17 t_ref_max\n",
      "cnt,var= 18 ps\n",
      "cnt,var= 19 h500\n",
      "cnt,var= 20 hght\n",
      "cnt,var= 21 sphum\n",
      "cnt,var= 22 temp\n",
      "cnt,var= 23 ucomp\n",
      "cnt,var= 24 vcomp\n",
      "cnt,var= 25 precip\n",
      "cnt,var= 26 lwdn_sfc\n",
      "cnt,var= 27 olr\n",
      "cnt,var= 28 swdn_sfc\n",
      "cnt,var= 29 swup_toa\n",
      "cnt,var= 30 average_T1\n",
      "cnt,var= 31 average_T2\n",
      "cnt,var= 32 average_DT\n",
      "cnt,var= 33 time_bounds\n",
      "Output file: ./test4.nc, File size=2.4 GB, Compression (approx.)=0.0%.\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "\n",
    "idir_data='/OSM/CBR/OA_DCFP/data3/CAFEPP/short/v14/tok599/coupled/ao_am2/coupled_da/workdir2/OUTPUT-2step-nobreeding-carbon2/20020101'\n",
    "ifil_data='atmos_daily_2002_01_01.nc'\n",
    "\n",
    "idir_data='/OSM/CBR/OA_DCFP/data/CAFEPP/g/data1/v14/coupled_model/v0/OUTPUT'\n",
    "ifil_data='atmos_month_0500_01.nc'\n",
    "\n",
    "idir_data='/OSM/CBR/OA_DCFP/data1/model_output/CAFE/forecasts/f1/hybrid/yr2008/mn1/OUTPUT.1'\n",
    "ifil_data='atmos_daily_2008_01_01.nc'\n",
    "\n",
    "idir_data='/OSM/CBR/OA_DCFP/data1/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT'\n",
    "ifil_data='atmos_daily_0500_01_01.nc'\n",
    "\n",
    "#idir_data='/OSM/CBR/OA_DCFP/data1/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT'\n",
    "idir_data='/OSM/CBR/OA_DCFP/work/col414/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT'\n",
    "ifil_data='atmos_month_0500_01.nc'\n",
    "\n",
    "idir_data='/OSM/CBR/OA_DCFP/work/col414/CAFEPP/short/v19/mac599/ao_am2/oct18a/OUTPUT'\n",
    "ifil_data='atmos_month_1980_01.nc'\n",
    "\n",
    "idir_data='/OSM/CBR/OA_DCFP/work/col414/CAFEPP/short/v19/mac599/ao_am2/oct18a/OUTPUT'\n",
    "ifil_data='atmos_daily_1980_01_01.nc'\n",
    "\n",
    "idir_grid='/OSM/CBR/OA_DCFP/work/squ027/squire_scratch/projects/cafe_hybrid_to_isobaric/shared'\n",
    "ifil_grid='cafe_grid_info.nc3.nc'\n",
    "ifil_grid='cafe_grid_info.nc'\n",
    "\n",
    "#status = prepare_vertintp(idir_data+'/'+ifil_data, idir_grid+'/'+ifil_grid, './test.nc', Diag=False, nc_model='NETCDF4_CLASSIC', compression=1, Clobber=True, history=True)\n",
    "\n",
    "#nc_model='NETCDF3_64BIT_OFFSET'\n",
    "#nc_model='NETCDF3_64BIT_DATA'\n",
    "#nc_model='NETCDF3_CLASSIC'\n",
    "nc_model='NETCDF4_CLASSIC'\n",
    "#nc_model='NETCDF4'\n",
    "\n",
    "status = prepare_vertintp(idir_data+'/'+ifil_data, \\\n",
    "                          idir_grid+'/'+ifil_grid, \\\n",
    "                          './test4.nc', \\\n",
    "                          Diag=True, \\\n",
    "                          nc_model=nc_model, \\\n",
    "                          compression=1, \\\n",
    "                          Clobber=True, \\\n",
    "                          history=True)\n",
    "  \n",
    "if(status!=0):\n",
    "  raise SystemExit('prepare_vertintp non-zero return status:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "status=os.system('nccopy -6 test4.nc test.cpy.nc')\n",
    "\n",
    "#shutil.copy('test4.nc', 'test.cpy.nc')\n",
    "            \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dims_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mjupyter_notebook\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#status=os.system('nccopy -6 test4.nc test.cpy.nc')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dims_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "#print(dims_dictionary)\n",
    "#status=os.system('nccopy -6 test4.nc test.cpy.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "Current Working Directory= /OSM/CBR/OA_DCFP/work/col414/cafepp\n",
      "status, out, err= 0 b'itime =       1\\nitime =       2\\nitime =       3\\nitime =       4\\nitime =       5\\nitime =       6\\nitime =       7\\nitime =       8\\nitime =       9\\nitime =      10\\nitime =      11\\nitime =      12\\nitime =      13\\nitime =      14\\nitime =      15\\nitime =      16\\nitime =      17\\nitime =      18\\nitime =      19\\nitime =      20\\nitime =      21\\nitime =      22\\nitime =      23\\nitime =      24\\nitime =      25\\nitime =      26\\nitime =      27\\nitime =      28\\nitime =      29\\nitime =      30\\nitime =      31\\nitime =      32\\nitime =      33\\nitime =      34\\nitime =      35\\nitime =      36\\nitime =      37\\nitime =      38\\nitime =      39\\nitime =      40\\nitime =      41\\nitime =      42\\nitime =      43\\nitime =      44\\nitime =      45\\nitime =      46\\nitime =      47\\nitime =      48\\nitime =      49\\nitime =      50\\nitime =      51\\nitime =      52\\nitime =      53\\nitime =      54\\nitime =      55\\nitime =      56\\nitime =      57\\nitime =      58\\nitime =      59\\nitime =      60\\nitime =      61\\nitime =      62\\nitime =      63\\nitime =      64\\nitime =      65\\nitime =      66\\nitime =      67\\nitime =      68\\nitime =      69\\nitime =      70\\nitime =      71\\nitime =      72\\nitime =      73\\nitime =      74\\nitime =      75\\nitime =      76\\nitime =      77\\nitime =      78\\nitime =      79\\nitime =      80\\nitime =      81\\nitime =      82\\nitime =      83\\nitime =      84\\nitime =      85\\nitime =      86\\nitime =      87\\nitime =      88\\nitime =      89\\nitime =      90\\nitime =      91\\nitime =      92\\nitime =      93\\nitime =      94\\nitime =      95\\nitime =      96\\nitime =      97\\nitime =      98\\nitime =      99\\nitime =     100\\nitime =     101\\nitime =     102\\nitime =     103\\nitime =     104\\nitime =     105\\nitime =     106\\nitime =     107\\nitime =     108\\nitime =     109\\nitime =     110\\nitime =     111\\nitime =     112\\nitime =     113\\nitime =     114\\nitime =     115\\nitime =     116\\nitime =     117\\nitime =     118\\nitime =     119\\nitime =     120\\nitime =     121\\nitime =     122\\nitime =     123\\nitime =     124\\nitime =     125\\nitime =     126\\nitime =     127\\nitime =     128\\nitime =     129\\nitime =     130\\nitime =     131\\nitime =     132\\nitime =     133\\nitime =     134\\nitime =     135\\nitime =     136\\nitime =     137\\nitime =     138\\nitime =     139\\nitime =     140\\nitime =     141\\nitime =     142\\nitime =     143\\nitime =     144\\nitime =     145\\nitime =     146\\nitime =     147\\nitime =     148\\nitime =     149\\nitime =     150\\nitime =     151\\nitime =     152\\nitime =     153\\nitime =     154\\nitime =     155\\nitime =     156\\nitime =     157\\nitime =     158\\nitime =     159\\nitime =     160\\nitime =     161\\nitime =     162\\nitime =     163\\nitime =     164\\nitime =     165\\nitime =     166\\nitime =     167\\nitime =     168\\nitime =     169\\nitime =     170\\nitime =     171\\nitime =     172\\nitime =     173\\nitime =     174\\nitime =     175\\nitime =     176\\nitime =     177\\nitime =     178\\nitime =     179\\nitime =     180\\nitime =     181\\nitime =     182\\nitime =     183\\nitime =     184\\nitime =     185\\nitime =     186\\nitime =     187\\nitime =     188\\nitime =     189\\nitime =     190\\nitime =     191\\nitime =     192\\nitime =     193\\nitime =     194\\nitime =     195\\nitime =     196\\nitime =     197\\nitime =     198\\nitime =     199\\nitime =     200\\nitime =     201\\nitime =     202\\nitime =     203\\nitime =     204\\nitime =     205\\nitime =     206\\nitime =     207\\nitime =     208\\nitime =     209\\nitime =     210\\nitime =     211\\nitime =     212\\nitime =     213\\nitime =     214\\nitime =     215\\nitime =     216\\nitime =     217\\nitime =     218\\nitime =     219\\nitime =     220\\nitime =     221\\nitime =     222\\nitime =     223\\nitime =     224\\nitime =     225\\nitime =     226\\nitime =     227\\nitime =     228\\nitime =     229\\nitime =     230\\nitime =     231\\nitime =     232\\nitime =     233\\nitime =     234\\nitime =     235\\nitime =     236\\nitime =     237\\nitime =     238\\nitime =     239\\nitime =     240\\nitime =     241\\nitime =     242\\nitime =     243\\nitime =     244\\nitime =     245\\nitime =     246\\nitime =     247\\nitime =     248\\nitime =     249\\nitime =     250\\nitime =     251\\nitime =     252\\nitime =     253\\nitime =     254\\nitime =     255\\nitime =     256\\nitime =     257\\nitime =     258\\nitime =     259\\nitime =     260\\nitime =     261\\nitime =     262\\nitime =     263\\nitime =     264\\nitime =     265\\nitime =     266\\nitime =     267\\nitime =     268\\nitime =     269\\nitime =     270\\nitime =     271\\nitime =     272\\nitime =     273\\nitime =     274\\nitime =     275\\nitime =     276\\nitime =     277\\nitime =     278\\nitime =     279\\nitime =     280\\nitime =     281\\nitime =     282\\nitime =     283\\nitime =     284\\nitime =     285\\nitime =     286\\nitime =     287\\nitime =     288\\nitime =     289\\nitime =     290\\nitime =     291\\nitime =     292\\nitime =     293\\nitime =     294\\nitime =     295\\nitime =     296\\nitime =     297\\nitime =     298\\nitime =     299\\nitime =     300\\nitime =     301\\nitime =     302\\nitime =     303\\nitime =     304\\nitime =     305\\nitime =     306\\nitime =     307\\nitime =     308\\nitime =     309\\nitime =     310\\nitime =     311\\nitime =     312\\nitime =     313\\nitime =     314\\nitime =     315\\nitime =     316\\nitime =     317\\nitime =     318\\nitime =     319\\nitime =     320\\nitime =     321\\nitime =     322\\nitime =     323\\nitime =     324\\nitime =     325\\nitime =     326\\nitime =     327\\nitime =     328\\nitime =     329\\nitime =     330\\nitime =     331\\nitime =     332\\nitime =     333\\nitime =     334\\nitime =     335\\nitime =     336\\nitime =     337\\nitime =     338\\nitime =     339\\nitime =     340\\nitime =     341\\nitime =     342\\nitime =     343\\nitime =     344\\nitime =     345\\nitime =     346\\nitime =     347\\nitime =     348\\nitime =     349\\nitime =     350\\nitime =     351\\nitime =     352\\nitime =     353\\nitime =     354\\nitime =     355\\nitime =     356\\nitime =     357\\nitime =     358\\nitime =     359\\nitime =     360\\nitime =     361\\nitime =     362\\nitime =     363\\nitime =     364\\nitime =     365\\n' b''\n",
      "Input file: /OSM/CBR/OA_DCFP/work/col414/cafepp/test2.nc, File size=2.0 GB\n",
      "Output file: ./test3.nc\n",
      "Output file: ./test3.nc, File size=1.3 GB, Compression (approx.)=35.0%.\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "#import commands\n",
    "import sys\n",
    "\n",
    "os.chdir(rundir)\n",
    "\n",
    "os.chdir('/OSM/CBR/OA_DCFP/work/col414/cafepp')\n",
    "\n",
    "print('Current Working Directory=',os.getcwd())\n",
    "\n",
    "levels = [100, 500, 1000, 2000, 3000, 5000, 7000, 10000, 15000, 20000, 25000, \\\n",
    " 30000, 40000, 50000, 60000, 70000, 85000, 92500, 100000] #cmip6 19 standard pressure levels\n",
    "                \n",
    "#levels = [20000, 30000, 40000, 45000, 50000, 55000, 60000, 70000, 85000, 100000]\n",
    "\n",
    "if(os.path.exists('/OSM/CBR/OA_DCFP/work/col414/cafepp/test2.nc')):\n",
    "  print('Output file exists, deleting.')\n",
    "  os.remove('/OSM/CBR/OA_DCFP/work/col414/cafepp/test2.nc')\n",
    "\n",
    "  #        ' -t 1,10,3' + \\\n",
    "command='/OSM/CBR/OA_DCFP/work/col414/cafepp/plevel_col414.bash ' + \\\n",
    "        ' -a' + \\\n",
    "        ' -i /OSM/CBR/OA_DCFP/work/col414/cafepp/test.cpy.nc' + \\\n",
    "        ' -o /OSM/CBR/OA_DCFP/work/col414/cafepp/test2.nc' + \\\n",
    "        ' -p \"' + ' '.join(map(str, levels)) + '\"' + \\\n",
    "        ' hght'\n",
    "\n",
    "status, out, err = get_exitcode_stdout_stderr(command)\n",
    "\n",
    "#print('status, out, err=',status, out, err)\n",
    "\n",
    "if(status!=0):\n",
    "  raise SystemExit('plevel_col414.bash non-zero return status:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "idir='/OSM/CBR/OA_DCFP/work/col414/cafepp'\n",
    "ifil='test2.nc'\n",
    "\n",
    "status = compress_nc(idir+'/'+ifil, \\\n",
    "                     './test3.nc', \\\n",
    "                     Diag='False', \\\n",
    "                     nc_model='NETCDF4_CLASSIC', \\\n",
    "                     compression=1, \\\n",
    "                     Clobber='True', \\\n",
    "                     history='True')\n",
    "  \n",
    "if(status!=0):\n",
    "  raise SystemExit('compress_nc non-zero return status:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "Input file: /OSM/CBR/OA_DCFP/work/col414/cafepp/test2.nc, File size=150.2 MB\n",
      "Output file: ./test3.nc\n",
      "Output file: ./test3.nc, File size=99.3 MB, Compression (approx.)=33.88814913448734%.\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "idir='/OSM/CBR/OA_DCFP/work/col414/cafepp'\n",
    "ifil='test2.nc'\n",
    "\n",
    "status = compress_nc(idir+'/'+ifil, \\\n",
    "                     './test3.nc', \\\n",
    "                     Diag='False', \\\n",
    "                     nc_model='NETCDF4_CLASSIC', \\\n",
    "                     compression=1, \\\n",
    "                     Clobber='True', \\\n",
    "                     history='True')\n",
    "  \n",
    "if(status!=0):\n",
    "  raise SystemExit('compress_nc non-zero return status:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory= /OSM/CBR/OA_DCFP/work/col414/cafepp\n",
      "exitcode, out, err= 0 b'hello\\nitime =       1\\nitime, otime =       4       2\\nitime, otime =       7       3\\nitime, otime =      10       4\\n' b''\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import shlex\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def get_exitcode_stdout_stderr(cmd):\n",
    "    \"\"\"\n",
    "    Execute the external command and get its exitcode, stdout and stderr.\n",
    "    \"\"\"\n",
    "    args = shlex.split(cmd)\n",
    " \n",
    "    proc = Popen(args, stdout=PIPE, stderr=PIPE)\n",
    "    out, err = proc.communicate()\n",
    "    exitcode = proc.returncode\n",
    "    #\n",
    "    return exitcode, out, err\n",
    "  \n",
    "os.chdir('/OSM/CBR/OA_DCFP/work/col414/cafepp')\n",
    "\n",
    "print('Current Working Directory=',os.getcwd())\n",
    "\n",
    "#status = subprocess.call('/apps/fre-nctools/20180125/bin/PLEV.exe', shell=True)\n",
    "\n",
    "#command='/apps/fre-nctools/20180125/bin/PLEV.exe'\n",
    "\n",
    "#command='/OSM/CBR/OA_DCFP/work/col414/cafepp/plevel_col414.bash -t 1,10,3 -a -i /OSM/CBR/OA_DCFP/data1/col414/atmos_daily_2003_01_01.nc -o /OSM/CBR/OA_DCFP/data1/col414/atmos_daily_2003_01_01.plevel.nc'\n",
    "\n",
    "command='/OSM/CBR/OA_DCFP/work/col414/cafepp/plevel_col414.bash ' + \\\n",
    "        ' -t 1,10,3' + \\\n",
    "        ' -a' + \\\n",
    "        ' -i /OSM/CBR/OA_DCFP/work/col414/cafepp/test.cpy.nc' + \\\n",
    "        ' -o /OSM/CBR/OA_DCFP/work/col414/cafepp/test2.nc' + \\\n",
    "        ' -p \"' + ' '.join(map(str, levels)) + '\"' + \\\n",
    "        ' hght'\n",
    "\n",
    "exitcode, out, err = get_exitcode_stdout_stderr(command)\n",
    "\n",
    "print('exitcode, out, err=',exitcode, out, err)\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
