{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAFEPP (utilising cafepp_daily(.py))\n",
    "\n",
    "***\n",
    "\n",
    "## This example will produce a set of daily SST files across the V1 assimilation run (interpolated onto a 1x1 latxlon grid), and upon success, generate an average over the nino3.4 region and plot the time-series.\n",
    "\n",
    "***\n",
    "\n",
    "# Various settings required:\n",
    "\n",
    "## BATCH determines whether it will be sent to the queue via qsub command or run interactively.\n",
    "\n",
    "## CLEAN determines whether the run directory will be emptied prior to processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "sys.version= 2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \n",
      "[GCC 7.2.0]\n",
      "hostname= oa-32-cdc\n",
      "Removing run directory and reestablish it.\n",
      "Running in directory /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Using script cafepp_daily_control.py\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "from __future__ import print_function #this is to allow print(,file=xxx) feature\n",
    "\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "\n",
    "###\n",
    "\n",
    "print('sys.version=',sys.version)\n",
    "hostname=socket.gethostname()\n",
    "print('hostname=',hostname)\n",
    "\n",
    "#dvar='tos' #variable to generate as well as further proces and plot.\n",
    "#dvar='ts'\n",
    "#dvar='tas'\n",
    "#dvar='thetao'\n",
    "#dvar='psl'\n",
    "#dvar='pr'\n",
    "#dvar='dummy'\n",
    "\n",
    "BATCH=True #submit to queue\n",
    "BATCH=False #run interactively but in a batch temporary area.\n",
    "\n",
    "CLEAN=False #don't remove rundir, just use it.\n",
    "CLEAN=True #remove rundir and recreate it.\n",
    "\n",
    "if(BATCH):\n",
    "  print('Submitting to queue.')\n",
    "\n",
    "if(CLEAN):\n",
    "  print('Removing run directory and reestablish it.')\n",
    "\n",
    "if(re.match('raijin',hostname)):\n",
    "  cmipdir='/short/v14/mac599' #this might be different to predir for other users.\n",
    "  predir='/short/v14/mac599' #this is directory area for temporary cafepp files.\n",
    "elif(re.match('oa-32-cdc',hostname) or re.match('oa-33-cdc',hostname)):\n",
    "  cmipdir='/OSM/CBR/OA_DCFP/data/CAFEPP/CMIP6' #this might be different to predir for other users.\n",
    "  predir='/OSM/CBR/OA_DCFP/data/col414' #this is directory area for temporary cafepp files.\n",
    "else:\n",
    "  raise SystemExit('hostname not known:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "topdir=predir+'/'+'cafepp'\n",
    "#script='cafepp_daily_assimilation_year_month.py'\n",
    "#script='cafepp_daily_assimilation.py'\n",
    "script='cafepp_daily_control.py'\n",
    "#script='cafepp_daily_forecast.py'\n",
    "\n",
    "#rundir=topdir+'/'+'rundir20180601103944'\n",
    "#rundir=topdir+'/'+'rundir'+datetime.datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "rundir=topdir+'/'+'rundir' #temporary running directory\n",
    "rundir=topdir+'/'+'rundir_tmp'\n",
    "\n",
    "print('Running in directory '+rundir)\n",
    "print('Using script '+script)\n",
    "\n",
    "if(re.match('raijin',hostname)):\n",
    "  srcdir='/home/599/mac599/decadal' #location of main cafepp code\n",
    "  prodir=srcdir+'/paper_analysis' #project directory\n",
    "elif(re.match('oa-32-cdc',hostname) or re.match('oa-33-cdc',hostname)):\n",
    "  srcdir='/OSM/CBR/OA_DCFP/work/col414/cafepp' #'/home/599/mac599/decadal' #location of main cafepp code\n",
    "  prodir='/OSM/CBR/OA_DCFP/work/col414/cafepp' #srcdir+'/paper_analysis' #project directory\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we make directories, copy across necessary JSON and python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "copying json files, generating symlinks, cmor tables, queue script, if necessary.\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/decadal_diag.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/decadal_diag_py2.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/decadal_diag_py3.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/cafepp_daily.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/app_funcs.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/ProcTime.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/cafepp_daily_control.py to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/cafepp_experiments.json to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/JsonTemplates/cafepp_csiro-gfdl.json to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/JsonTemplates/cafepp_vars.json to  /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "Copying /OSM/CBR/OA_DCFP/work/col414/cafepp/cafepp_daily_assimilation.json /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp/cafepp_daily_assimilation.json\n",
      "prodir= /OSM/CBR/OA_DCFP/work/col414/cafepp\n",
      "rundir= /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "print('copying json files, generating symlinks, cmor tables, queue script, if necessary.')\n",
    "if(os.path.exists(rundir) and CLEAN):\n",
    "  shutil.rmtree(rundir)\n",
    "  os.mkdir(rundir)\n",
    "  os.mkdir(rundir+'/'+'JsonTemplates') # exist_ok=True only python3\n",
    "elif(not os.path.exists(rundir)):\n",
    "  os.mkdir(rundir)\n",
    "  os.mkdir(rundir+'/'+'JsonTemplates') # exist_ok=True only python3\n",
    "\n",
    "# os.symlink(predir+'/'+'CMIP6',rundir+'/'+'CMIP6')\n",
    "# os.symlink(prodir+'/'+'TablesTemplates',rundir+'/'+'TablesTemplates')\n",
    "# os.symlink(prodir+'/'+'cmip6-cmor-tables',rundir+'/'+'cmip6-cmor-tables')\n",
    "\n",
    "if(os.path.isdir(cmipdir+'/'+'CMIP6')):\n",
    "  #print('hello')\n",
    "  os.symlink(cmipdir+'/'+'CMIP6',rundir+'/'+'CMIP6')\n",
    "else:\n",
    "  print('there')\n",
    "  os.mkdir(cmipdir)\n",
    "os.symlink(prodir+'/'+'TablesTemplates',rundir+'/'+'TablesTemplates')\n",
    "os.symlink(prodir+'/'+'cmip6-cmor-tables',rundir+'/'+'cmip6-cmor-tables')\n",
    "\n",
    "if(BATCH):\n",
    "  print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "  ifh=open(prodir+'/'+'qjob.csh')\n",
    "  ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "  for i,line in enumerate(ifh):\n",
    "    line=line.replace('CAFEPP_SCRIPT','./'+script+' RUNDIR')\n",
    "    line=line.replace('RUNDIR',rundir)\n",
    "    line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "    line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "    print(line,file=ofh,end='')\n",
    "  ifh.close()\n",
    "  ofh.close()\n",
    "\n",
    "vector_string=['decadal_diag.py','decadal_diag_py2.py','decadal_diag_py3.py','cafepp_daily.py','app_funcs.py','ProcTime.py'] #dont need ProcTime\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+srcdir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(srcdir+'/'+file_now,rundir+'/'+file_now)\n",
    "  \n",
    "vector_string=[script]\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+prodir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(prodir+'/'+file_now,rundir+'/'+file_now)\n",
    "  os.chmod(rundir+'/'+script,500) #make executable incase want to run it interacively from terminal.\n",
    "  \n",
    "vector_string=[]\n",
    "#vector_string.append(script) #may need to do edits?\n",
    "#vector_string.append('cafepp_monthly_assimilation.json')\n",
    "vector_string.append('cafepp_experiments.json')\n",
    "#vector_string.append('JsonTemplates'+'/'+'cafepp_csiro-gfdl.json')\n",
    "#vector_string.append('JsonTemplates'+'/'+'cafepp_vars.json')\n",
    "#vector_string.append('cafepp_monthly_forecast.py')\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+prodir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(prodir+'/JsonTemplates/'+file_now,rundir+'/'+file_now)\n",
    "\n",
    "vector_string=[]\n",
    "#vector_string.append(script) #may need to do edits?\n",
    "#vector_string.append('cafepp_monthly_assimilation.json')\n",
    "#vector_string.append('JsonTemplates'+'/'+'cafepp_experiments.json')\n",
    "vector_string.append('JsonTemplates'+'/'+'cafepp_csiro-gfdl.json')\n",
    "vector_string.append('JsonTemplates'+'/'+'cafepp_vars.json')\n",
    "#vector_string.append('cafepp_monthly_forecast.py')\n",
    "for i,file_now in enumerate(vector_string):\n",
    "  print('Copying '+prodir+'/'+file_now+' to ',rundir)\n",
    "  shutil.copyfile(prodir+'/'+file_now,rundir+'/'+file_now)\n",
    "  \n",
    "print('Copying '+prodir+'/'+'cafepp_daily_assimilation.json',rundir+'/'+'cafepp_daily_assimilation.json')\n",
    "shutil.copyfile(prodir+'/'+'cafepp_daily_assimilation.json',rundir+'/'+'cafepp_daily_assimilation.json')\n",
    "  \n",
    "#vector_string=[script]\n",
    "#for i,file_now in enumerate(vector_string):\n",
    "#  print('Copying '+prodir+'/'+file_now+' to ',rundir)\n",
    "#  shutil.copyfile(prodir+'/'+file_now,rundir+'/'+file_now)\n",
    "  \n",
    "# vector_string=[]\n",
    "# vector_string.append(script) #may need to do edits?\n",
    "# vector_string.append('cafepp_daily_assimilation.json')\n",
    "# #vector_string.append('cafepp_daily_forecast_experiments.json')\n",
    "# vector_string.append('JsonTemplates'+'/'+'cafepp_experiments.json')\n",
    "# vector_string.append('JsonTemplates'+'/'+'cafepp_csiro-gfdl.json')\n",
    "# vector_string.append('JsonTemplates'+'/'+'cafepp_vars.json')\n",
    "# for i,file_now in enumerate(vector_string):\n",
    "#   print('Copying '+prodir+'/'+file_now+' to ',rundir+'/'+file_now)\n",
    "#   shutil.copyfile(prodir+'/'+file_now,rundir+'/'+file_now)\n",
    "  \n",
    "# vector_string=[]\n",
    "# vector_string.append('cafepp_experiments.json')\n",
    "# for i,file_now in enumerate(vector_string):\n",
    "#   print('Copying '+prodir+'/JsonTemplates/'+file_now+' to '+rundir+'/'+file_now)\n",
    "#   shutil.copyfile(prodir+'/JsonTemplates/'+file_now,rundir+'/'+file_now)\n",
    "  \n",
    "# print('Processing cafepp_daily_assimilation.json')\n",
    "# ifh=open(prodir+'/'+'cafepp_daily_assimilation.json')\n",
    "# ofh=open(rundir+'/'+'cafepp_daily_assimilation.json','w')\n",
    "# for i,line in enumerate(ifh):\n",
    "#   token1=[str(x) for x in line.split(':')]\n",
    "#   token2=(token1[0].replace(' ',''))\n",
    "#   token3=(token2.replace('\"',''))\n",
    "#   if(token3=='dvar'):\n",
    "#     line='     \"dvar\":\"'+dvar+'\",\\n'\n",
    "# #  elif(token3=='grid_label'):\n",
    "# #    line='     \"grid_label\":\"gr2\",\\n'\n",
    "# #  elif(token3=='grid'):\n",
    "# #    line='     \"grid\":\"data regridded via linear interpolation to a 1x1 degree latxlon  (180x360)grid from the native 300x360 latxlon tri-polar grid\",\\n'\n",
    "#   print(line,file=ofh,end='')\n",
    "# ifh.close()\n",
    "# ofh.close()\n",
    "\n",
    "#break\n",
    "\n",
    "if(not os.path.exists(rundir+'/'+'CMIP5')):\n",
    "  if(re.match('raijin',hostname)):\n",
    "    print('No need to set CMIP5 symbolic link on raijin.')\n",
    "  elif(re.match('oa-32-cdc',hostname) or re.match('oa-33-cdc',hostname)):\n",
    "    os.symlink('/OSM/CBR/OA_DCFP/data/CAFEPP/g/data/p66/mac599/CMIP5',rundir+'/'+'CMIP5')\n",
    "  elif(re.match('tube-hba',hostname)):\n",
    "    os.symlink('/OSM/HBA/OA_DECADAL_CLIMATE/work/col414/CMIP5',rundir+'/'+'CMIP5')\n",
    "  else:\n",
    "    raise SystemExit('Dont know how to set CMIP5 symbolic link on this machine.'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "\n",
    "#   srcdir='/home/599/mac599/decadal' #location of main cafepp code\n",
    "#   prodir=srcdir+'/paper_analysis' #project directory\n",
    " \n",
    "print('prodir=',prodir)\n",
    "print('rundir=',rundir)\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We establish where to execute the job.\n",
    "\n",
    "## We import a function that is relatively simple to loop over all necessary years, months, ensembles as required.\n",
    "## Different applications will require a different module to be written (often small and relatively simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "Current Working Directory= /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      ".\n",
      "you have not specified the environment variable: 'CDAT_LOCATION' , trying to import cdms2 anyway\n",
      "function_name= cafepp_daily_control\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "os.chdir(rundir)\n",
    "print('Current Working Directory=',os.getcwd())\n",
    "\n",
    "os.environ['APP_OUTPATH'] = '.'\n",
    "print(os.getenv('APP_OUTPATH'))\n",
    "\n",
    "import getpass\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "from time import strftime\n",
    "import netCDF4\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import seawater\n",
    "#import sys\n",
    "import getopt\n",
    "import string\n",
    "from decadal_diag import MustHaveAllLevs,diag_acc_drake,diag_acc_africa,diag_mozmbq,diag_aabw,diag_nadw,\\\n",
    "diag_pp,diag_nflux,diag_ep,diag_ssh,diag_moc,diag_moc_atlantic,diag_moc_pacific,diag_moc_indian,\\\n",
    "diag_shice_cover,diag_nhice_cover,diag_nino34,xtra_nino34,init_data,sum_data,avg_data,filemonth_index,\\\n",
    "data_wavg,time_avg,diag_nhblocking_index,diag_rws5,finish,diag_msftyz,make_mask3D,diag_mfo,transPort,\\\n",
    "diag_rws500,create_odirs,create_ofils,diag_iod,diag_iod,xtra_iod,atmos_vertical_interpolate,diag_isothetaoNc,\\\n",
    "calc_iso_surface,calc_isoN,grab_var_meta,diag_psl,diag_hfls,diag_heat_content,diag_salt_content,\\\n",
    "diag_north_heat_trans,diag_north_salt_trans,ocean_vertical_interpolate,diag_thetao0to80m,diag_varNl,\\\n",
    "uncomment_json,process_json,get_daily_indices_for_monthlyave,generate_daily_month_indices,diag_maxdTbydz,diag_depmaxdTbydz,\\\n",
    "diag_dTbydz,shade_2d_simple,shade_2d_latlon,diag_zmld_boyer,zmld_boyer,sigmatheta,diag_zmld_so,\\\n",
    "zmld_so,diag_spice,spice,diag_bigthetao,diag_soabs,diag_spiciness,diag_potrho,fractional_year_from_num2date,\\\n",
    "new_monthly_array_shape,restrict_input_files,get_timestamp_number\n",
    "\n",
    "#from decadal_diag import generate_daily_month_indices\n",
    "\n",
    "import cmor\n",
    "import cdtime\n",
    "from app_funcs import *\n",
    "import json\n",
    "import pprint\n",
    "from datetime import date\n",
    "import filecmp\n",
    "from shutil import copyfile\n",
    "import cdms2\n",
    "import inspect\n",
    "import socket\n",
    "import glob\n",
    "from matplotlib.mlab import griddata\n",
    "import scipy.sparse as sps\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['mathtext.default'] = 'regular'\n",
    "import matplotlib.pyplot as plt\n",
    "from gridfill import fill as poisson_fill\n",
    "\n",
    "function_name=script.split('.py')[0]\n",
    "print('function_name=',function_name)\n",
    "import importlib\n",
    "\n",
    "#import cafepp_daily_assimilation_year_month\n",
    "#import eval(function_name)\n",
    "\n",
    "#cafepp_daily = importlib.import_module(function_name)\n",
    "\n",
    "#script='cafepp_daily_forecast.py'\n",
    "#script='cafepp_daily_assimilation_year_month.py'\n",
    "#script='cafepp_daily_assimilation.py'\n",
    "script='cafepp_daily_control.py'\n",
    "\n",
    "if(script=='cafepp_daily_forecast.py'):\n",
    "  import cafepp_daily_forecast as cafepp_daily #this script/function needs to be edited to limit variable.\n",
    "elif(script=='cafepp_daily_assimilation_year_month.py'):\n",
    "  import cafepp_daily_assimilation_year_month as cafepp_daily #this script/function needs to be edited to limit year,month,ensemble range,variable if desired. Will need to restart kernel for it to take effect.\n",
    "elif(script=='cafepp_daily_assimilation.py'):\n",
    "  import cafepp_daily_assimilation as cafepp_daily\n",
    "elif(script=='cafepp_daily_control.py'):\n",
    "  import cafepp_daily_control as cafepp_daily\n",
    "  \n",
    "#print(dir(cafepp_daily_control))\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Either submit it to the queue or run interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "#SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "  if(BATCH):\n",
    "    os.chmod(script,500)\n",
    "    os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "  else:\n",
    "    print('Current Working Directory=',os.getcwd())\n",
    "    os.chdir(rundir)\n",
    "    cafepp_daily.main(rundir)\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process daily assimilation output into one continuous file...\n",
    "\n",
    "working but issue with too many open files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "\n",
    "  cafe_experiment='coupled_da/OUTPUT-2step-nobreeding-carbon2'\n",
    "  ybeg_first=2002 #2002\n",
    "  yend_last=2016 #2016\n",
    "  ybeg=2009 #2002\n",
    "  yend=2016 #2016\n",
    "  mbeg_first=1 #2\n",
    "  mend_last=6 #6\n",
    "  mbeg_norm=1 #1\n",
    "  mend_norm=12 #12\n",
    "  \n",
    "  dvar='tas'\n",
    "  #dvar='pr'\n",
    "  #dvar='tos'\n",
    "  #dvar='psl'\n",
    "  \n",
    "  line_kwargs= \\\n",
    "    'rundir='+rundir+ \\\n",
    "    ' cafe_experiment='+cafe_experiment+ \\\n",
    "    ' dvar='+dvar+ \\\n",
    "    ' ybeg_first='+str(ybeg_first)+' yend_last='+str(yend_last)+ \\\n",
    "    ' ybeg='+str(ybeg)+' yend='+str(yend)+ \\\n",
    "    ' mbeg_first='+str(mbeg_first)+' mend_last='+str(mend_last)+ \\\n",
    "    ' mbeg_norm='+str(mbeg_norm)+' mend_norm='+str(mend_norm) #no space after first item ' is important\n",
    "\n",
    "  if(BATCH):\n",
    "    os.chmod(script,500)\n",
    "    print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "    ifh=open(prodir+'/'+'qjob.csh')\n",
    "    ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "    for i,line in enumerate(ifh):\n",
    "      line=line.replace('CAFEPP_SCRIPT','./'+script+' '+line_kwargs)\n",
    "      line=line.replace('RUNDIR',rundir)\n",
    "      line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "      line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "      print(line,file=ofh,end='')\n",
    "    ifh.close()\n",
    "    ofh.close()\n",
    "    os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "  else:\n",
    "    print('Current Working Directory=',os.getcwd())\n",
    "    os.chdir(rundir)\n",
    "    \n",
    "    kwargs=dict(x.split('=', 1) for x in line_kwargs.split(' '))\n",
    "    print('kwargs=',kwargs)\n",
    "      \n",
    "    cafepp_daily.main(**kwargs)\n",
    "        \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process daily assimilation output into separate year/month files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "#SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "\n",
    "  cafe_experiment='coupled_da/OUTPUT-2step-nobreeding-carbon2'\n",
    "  ybeg_first=2002 #2002\n",
    "  yend_last=2016 #2016\n",
    "  ybeg=2002\n",
    "  yend=2016\n",
    "  mbeg_first=1 #2\n",
    "  mend_last=6 #6\n",
    "  mbeg_norm=1 #1\n",
    "  mend_norm=12 #12\n",
    "  \n",
    "  line_kwargs= \\\n",
    "    'rundir='+rundir+ \\\n",
    "    ' cafe_experiment='+cafe_experiment+ \\\n",
    "    ' ybeg_first='+str(ybeg_first)+' yend_last='+str(yend_last)+ \\\n",
    "    ' ybeg='+str(ybeg)+' yend='+str(yend)+ \\\n",
    "    ' mbeg_first='+str(mbeg_first)+' mend_last='+str(mend_last)+ \\\n",
    "    ' mbeg_norm='+str(mbeg_norm)+' mend_norm='+str(mend_norm) #no space after first item ' is important\n",
    "\n",
    "  if(BATCH):\n",
    "    os.chmod(script,500)\n",
    "    print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "    ifh=open(prodir+'/'+'qjob.csh')\n",
    "    ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "    for i,line in enumerate(ifh):\n",
    "      line=line.replace('CAFEPP_SCRIPT','./'+script+' '+line_kwargs)\n",
    "      line=line.replace('RUNDIR',rundir)\n",
    "      line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "      line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "      print(line,file=ofh,end='')\n",
    "    ifh.close()\n",
    "    ofh.close()\n",
    "    os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "  else:\n",
    "    print('Current Working Directory=',os.getcwd())\n",
    "    os.chdir(rundir)\n",
    "    \n",
    "    kwargs=dict(x.split('=', 1) for x in line_kwargs.split(' '))\n",
    "    print('kwargs=',kwargs)\n",
    "      \n",
    "    cafepp_daily.main(**kwargs)\n",
    "        \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process daily multi-ensemble forecast output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "\n",
    "  ###\n",
    "  \n",
    "  cafe_experiment='v1_forecast'\n",
    "  #cafe_experiment='v0_forecast'\n",
    "  \n",
    "  dvar='pr'\n",
    "  #dvar='psl'\n",
    "  #dvar='tas'\n",
    "  #dvar='tos'\n",
    "  \n",
    "  NoClobber=True #do not clobber\n",
    "  #NoClobber=False #clobber\n",
    "  \n",
    "  ybeg_first=2016 #2002\n",
    "  yend_last=2016 #2016\n",
    "  ybeg=2016\n",
    "  yend=2016\n",
    "  mbeg_first=1 #2\n",
    "  mend_last=5 #5\n",
    "  mbeg_norm=1 #1\n",
    "  mend_norm=12 #12\n",
    "  ebeg=2 #1\n",
    "  eend=11 #11\n",
    "  \n",
    "  line_kwargs= \\\n",
    "    'dvar='+dvar+ \\\n",
    "    ' NoClobber='+str(NoClobber)+ \\\n",
    "    ' rundir='+rundir+ \\\n",
    "    ' cafe_experiment='+cafe_experiment+ \\\n",
    "    ' ybeg_first='+str(ybeg_first)+' yend_last='+str(yend_last)+ \\\n",
    "    ' ybeg='+str(ybeg)+' yend='+str(yend)+ \\\n",
    "    ' mbeg_first='+str(mbeg_first)+' mend_last='+str(mend_last)+ \\\n",
    "    ' mbeg_norm='+str(mbeg_norm)+' mend_norm='+str(mend_norm)+ \\\n",
    "    ' ebeg='+str(ebeg)+' eend='+str(eend)  #no space after first item ' is important\n",
    "\n",
    "  if(BATCH):\n",
    "    os.chmod(script,500)\n",
    "    print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "    ifh=open(prodir+'/'+'qjob.csh')\n",
    "    ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "    for i,line in enumerate(ifh):\n",
    "      line=line.replace('CAFEPP_SCRIPT','./'+script+' '+line_kwargs)\n",
    "      line=line.replace('RUNDIR',rundir)\n",
    "      line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "      line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "      print(line,file=ofh,end='')\n",
    "    ifh.close()\n",
    "    ofh.close()\n",
    "    os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "  else:\n",
    "    print('Current Working Directory=',os.getcwd())\n",
    "    os.chdir(rundir)\n",
    "    \n",
    "    kwargs=dict(x.split('=', 1) for x in line_kwargs.split(' '))\n",
    "    print('kwargs=',kwargs)\n",
    "      \n",
    "    cafepp_daily.main(**kwargs)\n",
    "        \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process daily control output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "Current Working Directory= /OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp\n",
      "kwargs= {'dvar': 'pr', 'daily_data_layout': 'noleap_1fileperyear', 'mbeg_first': '1', 'yend': '490', 'ybeg': '481', 'rundir': '/OSM/CBR/OA_DCFP/data/col414/cafepp/rundir_tmp', 'NoClobber': 'True', 'cafe_experiment': 'v1', 'mend_last': '12'}\n",
      "Processing cafepp_experiments.json\n",
      "doing it...\n",
      "Found required output experiment : v1\n",
      "Processing cafepp_daily_assimilation.json\n",
      "MAIN\n",
      "hostname= oa-32-cdc\n",
      "Running cafepp from JSON instructions: cafepp.json\n",
      "fh_printfile= <ipykernel.iostream.OutStream object at 0x7fc99baa1a90>\n",
      "Found required output experiment : v1\n",
      "cafepp_daily: idir= /OSM/CBR/OA_DCFP/data/CAFEPP/g/data1/v14/coupled_model/v1/OUTPUT\n",
      "hostname= oa-32-cdc\n",
      "['/OSM/CBR/OA_DCFP/apps/col414/anaconda3/envs/cafepp_27_scipy/lib/python2.7/site-packages/ipykernel_launcher.py', '-f', '/OSM/HOME-CDC/col414/.local/share/jupyter/runtime/kernel-42f08671-1d1a-400b-ac7b-2bd27af9d2ee.json']\n",
      "Found required output variable: pr\n",
      "Producing monthly output from daily input (not yet operational).\n",
      "Output CMIP6 file: CMIP6/CMIP/CSIRO/CAFE-1-0/piControl/r1i1p9f1/day/pr/gn/v20171025/pr_day_piControl_CAFE-1-0_r1i1p9f1_gn_04810101-04901231.nc\n",
      "No Clobber set and  CMIP6/CMIP/CSIRO/CAFE-1-0/piControl/r1i1p9f1/day/pr/gn/v20171025/pr_day_piControl_CAFE-1-0_r1i1p9f1_gn_04810101-04901231.nc  exists\n",
      "Finished O.K.:cafepp_daily_control.py line number: 182\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "SWITCH_OFF=True #temporary for easy skipping of this section.\n",
    "SWITCH_OFF=False\n",
    "\n",
    "if(not SWITCH_OFF):\n",
    "  \n",
    "  daily_data_layout='noleap_1fileperyear' #this should not be necessary as found in json file for each experiment.\n",
    "#  dvar='tas'\n",
    "#   dvar='thetao'\n",
    "#   dvar='tos'\n",
    "  dvar='pr'\n",
    "\n",
    "  NoClobber='True' #do not clobber\n",
    "  #NoClobber='False' #clobber\n",
    "  \n",
    "  cafe_experiment='v1'\n",
    "\n",
    "  ybeg=481\n",
    "  yend=490\n",
    "  mbeg_first=1\n",
    "  mend_last=12\n",
    "  \n",
    "  line_kwargs= \\\n",
    "    'NoClobber='+NoClobber+ \\\n",
    "    ' cafe_experiment='+cafe_experiment+ \\\n",
    "    ' rundir='+rundir+ \\\n",
    "    ' dvar='+dvar+ \\\n",
    "    ' ybeg='+str(ybeg)+ \\\n",
    "    ' yend='+str(yend)+ \\\n",
    "    ' mbeg_first='+str(mbeg_first)+ \\\n",
    "    ' mend_last='+str(mend_last)+ \\\n",
    "    ' daily_data_layout='+daily_data_layout\n",
    "  \n",
    "  if(BATCH):\n",
    "    os.chmod(script,500)\n",
    "    \n",
    "    print('Copying and editing '+prodir+'/'+'qjob.csh to '+rundir+'/'+'qjob.csh')\n",
    "    ifh=open(prodir+'/'+'qjob.csh')\n",
    "    ofh=open(rundir+'/'+'qjob.csh','w')\n",
    "    for i,line in enumerate(ifh):\n",
    "      line=line.replace('CAFEPP_SCRIPT','./'+script+' '+line_kwargs)\n",
    "      line=line.replace('RUNDIR',rundir)\n",
    "      line=line.replace('CONDA_SOURCE','. /short/v14/mac599/anaconda3/etc/profile.d/conda.sh')\n",
    "      line=line.replace('CONDA_ACTIVATE','conda activate cafepp_27_scipy')\n",
    "      print(line,file=ofh,end='')\n",
    "    ifh.close()\n",
    "    ofh.close()\n",
    "      \n",
    "    os.system('qsub '+rundir+'/'+'qjob.csh')\n",
    "  else:\n",
    "    print('Current Working Directory=',os.getcwd())\n",
    "    os.chdir(rundir)\n",
    "    \n",
    "    kwargs=dict(x.split('=', 1) for x in line_kwargs.split(' '))\n",
    "    print('kwargs=',kwargs\n",
    "         )\n",
    "    #cafepp_monthly_forecast.main(**kwargs)\n",
    "      \n",
    "    cafepp_daily.main(**kwargs)\n",
    "    \n",
    "    #cafepp_daily_assimilation_year_month.main(rundir)\n",
    "    \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## information common to processing all runs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('STOP!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "import math\n",
    "from array import array\n",
    "\n",
    "#remember on 1x1 degree latxlon grid.\n",
    "\n",
    "indices_nino=['nino34','nino3','nino4','nino1+2'] # 170W-120W, 150W-90W, 160E-150W, 90W-80W:270-280 (10S-0 latitude, others all 5S to 5N)\n",
    "indices_label=['Ni$\\~{n}$o3.4','Ni$\\~{n}$o3','Ni$\\~{n}$o4','Ni$\\~{n}$o1+2']\n",
    "  \n",
    "#if(cafe_grid=='gr2'):\n",
    "#elif(cafe_grid=='gn'):\n",
    "\n",
    "indices_i_gr2,indices_j_gr2=[[190,239],[210,269],[150,209],[270,280]],[[85,94],[85,94],[85,94],[80,89]] #check this, whether I need +1 also...what about fractional cells?\n",
    "indices_i_gn,indices_j_gn=[[110,159],[130,189],[80,129],[190,199]],[[122,151],[122,151],[122,151],[107,136]] #check this, whether I need +1 also...what about fractional cells?\n",
    "\n",
    "#indices_select=array('i',[0,1,2,3])\n",
    "#indices_select=[np.int(0)]\n",
    "#indices_select=range(3)\n",
    "#print(type(indices_select))\n",
    "#print('indices_select=',indices_select)\n",
    "\n",
    "#used for speeding things up, either can choose a single indice or all - don't know why can't use : in eval for e.g.\n",
    "sss='-1' #last\n",
    "sss='0' #first\n",
    "#sss='ALL'\n",
    "\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "if(sss!='ALL'):\n",
    "  indices_nino=[indices_nino[eval(sss)]]\n",
    "  indices_label=[indices_label[eval(sss)]]\n",
    "  indices_i_gr2=[indices_i_gr2[eval(sss)]]\n",
    "  indices_j_gr2=[indices_j_gr2[eval(sss)]]\n",
    "  indices_i_gn=[indices_i_gn[eval(sss)]]\n",
    "  indices_j_gn=[indices_j_gn[eval(sss)]]\n",
    "\n",
    "print('indices_nino=',indices_nino)\n",
    "\n",
    "print('indices_i_gr2=',indices_i_gr2)\n",
    "\n",
    "nindices_nino=len(indices_nino)\n",
    "\n",
    "#else:\n",
    "#  raise Exception('STOP!')\n",
    "#raise Exception('STOP!')\n",
    "#del(get_timestamp_number)\n",
    "#from decadal_diag import get_timestamp_number\n",
    "\n",
    "rad = 4.0*math.atan(1.0)/180.0\n",
    "#print('rad=',rad)\n",
    "\n",
    "#%who\n",
    "\n",
    "print('END.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to plot data, this will depend on success of previous steps producing necessary outputs with cafepp(_daily).\n",
    "\n",
    "I've also updated with an option to read in a \"raw\" monthly file and to overlay it. Note that here it includes a partial final year whereas the daily one doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "import math\n",
    "\n",
    "os.chdir(rundir)\n",
    "\n",
    "cafe_grid='gr2'\n",
    "cafe_grid='gn'\n",
    "\n",
    "files_string='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p2f1/Oday/'+dvar+'/'+cafe_grid+'/v20171025/'+dvar+'_Oday_historical_CAFE-1-0_r1i1p2f1_'+cafe_grid+'_????????-????????.nc'\n",
    "files=glob.glob(files_string)\n",
    "files=sorted(restrict_input_files(files,28,31))\n",
    "\n",
    "#print('files=',files)\n",
    "#for i,file in enumerate(files):\n",
    "#  print('i,file=',i,file)\n",
    "#raise Exception('STOP!')\n",
    "  \n",
    "ifhN=netCDF4.MFDataset(files)\n",
    "ifh0=netCDF4.Dataset(files[0])\n",
    "\n",
    "time=ifhN.variables['time']\n",
    "#lat=ifh0.variables['lat']\n",
    "#lon=ifh0.variables['lon']\n",
    "\n",
    "lat=ifh0.variables['latitude'][:,0]\n",
    "lon=ifh0.variables['longitude'][0,:]\n",
    "\n",
    "ntime=len(time)\n",
    "#print('lat=',lat)\n",
    "\n",
    "ifh0.close()\n",
    "\n",
    "#print('rad=',rad)\n",
    "clat=np.cos(lat[:]*rad)\n",
    "#print('clat=',clat)\n",
    "\n",
    "#print('lat=',lat[85:95])\n",
    "#print('lon=',lon[190:240])\n",
    "\n",
    "nino=ma.zeros((nindices_nino,ntime),dtype=float)\n",
    "\n",
    "#tos_data=(ifhN.variables['tos'])\n",
    "#tos_data=np.ma.masked_array(tos_data,np.isnan(tos_data))\n",
    "\n",
    "for k,indice in enumerate(indices_nino):\n",
    "  print('indice=',indice)\n",
    "  #if(indice=='nino1+2'):\n",
    "  imin,imax=indices_i_gn[indices_nino.index(indice)][0],indices_i_gn[indices_nino.index(indice)][1]\n",
    "  jmin,jmax=indices_j_gn[indices_nino.index(indice)][0],indices_j_gn[indices_nino.index(indice)][1]\n",
    "  nino_box=ifhN.variables[dvar][:,jmin:jmax+1,imin:imax+1]\n",
    "  nino_box=np.ma.masked_array(nino_box,np.isnan(nino_box))\n",
    "  #print('lat[jmin:jmax]=',lat[jmin:jmax+1])\n",
    "  #print('lon[imin:imax]=',lon[imin:imax+1])\n",
    "    #print(ifhN.variables['tos'][:,jmin:jmax,imin:imax])\n",
    "    #print('nino_box=',nino_box)\n",
    "    #raise Exception('STOP!')\n",
    "    #np.ma.masked_array(data,np.isnan(dat))\n",
    "  nino[k,:]=np.average(np.average(nino_box,axis=1,weights=clat[jmin:jmax+1]),axis=1)\n",
    "  #nino[k,:]=np.average(np.average(ifhN.variables['tos'][:,jmin:jmax+1,imin:imax+1],axis=1,weights=clat[jmin:jmax+1]),axis=1)\n",
    "\n",
    "#ifhN.close()\n",
    "\n",
    "'''\n",
    "print('time.units=',time.units)\n",
    "print('time.calendar=',time.calendar)\n",
    "print('time=',time)\n",
    "print('time[:]=',time[:])\n",
    "'''\n",
    "\n",
    "date_time_stamp=netCDF4.num2date(time[:],time.units,time.calendar)\n",
    "\n",
    "#print('date_time_stamp=',date_time_stamp)\n",
    "\n",
    "'''\n",
    "print('date_time_stamp=',date_time_stamp)\n",
    "num_stamp=netCDF4.date2num(date_time_stamp,time.units,time.calendar)\n",
    "print('num_stamp=',num_stamp)\n",
    "print('year_fraction=',year_fraction)\n",
    "'''\n",
    "year_fraction=fractional_year_from_num2date(date_time_stamp,time.calendar)\n",
    "\n",
    "#print('year_fraction=',year_fraction)\n",
    "#print('nino[0,:]=',nino[0,:])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('nino.shape=',nino.shape)\n",
    "print(\"indices_nino.index('nino34')=\",indices_nino.index('nino34'))\n",
    "\n",
    "fix,ax=plt.subplots()\n",
    "for k,indice in enumerate(indices_nino):\n",
    "  ax.plot(year_fraction,nino[indices_nino.index(indice),:],label=indice)\n",
    "legend=ax.legend(loc='lower right',shadow=False,fontsize='x-large')\n",
    "plt.title('Daily values')\n",
    "#plt.plot(num_stamp,nino34[:])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('$^o$C')\n",
    "plt.show()\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on code to determine how to calculate monthly averages from daily data.\n",
    "\n",
    "Thinking of 4 options, assuming that the time-series is assiminuous and increasing:\n",
    "1. exclude any partial months at beginning and end of time-series\n",
    "2. include partial months at beginning of time-series\n",
    "3. include partial months at end of time-series\n",
    "4. include partial months at beginning and end of time-series.\n",
    "\n",
    "This includes a function and a set of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN')\n",
    "\n",
    "import inspect\n",
    "__file__='jupyter_notebook' #this can be deleted when written to a python script and loaded as module.\n",
    "\n",
    "ReadPlotMonthly=True #read in the monthly cmorised file and plot it over that calculated from daily inputs to check consistency.\n",
    "#ReadPlotMonthly=False\n",
    "\n",
    "if(ReadPlotMonthly):\n",
    "  cafe_grid='gn'\n",
    "  ifil_raw='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p2f1/Omon/tos/'+cafe_grid+'/v20171025/tos_Omon_historical_CAFE-1-0_r1i1p2f1_'+cafe_grid+'_200201-201606.nc'\n",
    "  ifh_raw=netCDF4.Dataset(ifil_raw)\n",
    "  time_raw=ifh_raw.variables['time']\n",
    "  ntime_raw=len(time_raw)\n",
    "  lat_raw=ifh_raw.variables['latitude'][:,0]\n",
    "  lon_raw=ifh_raw.variables['longitude'][0,:]\n",
    "  clat_raw=np.cos(lat_raw[:]*rad)\n",
    "  \n",
    "  nino_monthly_raw=ma.zeros((nindices_nino,ntime_raw),dtype=float)\n",
    "\n",
    "  for k,indice in enumerate(indices_nino):\n",
    "    imin,imax=indices_i_gn[indices_nino.index(indice)][0],indices_i_gn[indices_nino.index(indice)][1]\n",
    "    jmin,jmax=indices_j_gn[indices_nino.index(indice)][0],indices_j_gn[indices_nino.index(indice)][1]\n",
    "    nino_monthly_box=ifh_raw.variables[dvar][:,jmin:jmax+1,imin:imax+1]\n",
    "    nino_monthly_box=np.ma.masked_array(nino_monthly_box,np.isnan(nino_monthly_box))\n",
    "    nino_monthly_raw[k,:]=np.average(np.average(nino_monthly_box,axis=1,weights=clat_raw[jmin:jmax+1]),axis=1) #need to add in area weighting strictly\n",
    "  date_time_stamp_raw=netCDF4.num2date(time_raw[:],time_raw.units,time_raw.calendar)\n",
    "  year_fraction_monthly_raw=fractional_year_from_num2date(date_time_stamp_raw,time_raw.calendar)\n",
    "  \n",
    "#  %matplotlib inline\n",
    "#  plt.title('Monthly values from monthly inputs')\n",
    "#  plt.plot(year_fraction_monthly_raw,nino34_monthly_raw[:])\n",
    "#  plt.xlabel('Year')\n",
    "#  plt.ylabel('Ni$\\~{n}$o34 ($^o$C)')\n",
    "#  plt.show()\n",
    "  \n",
    "#print('len(date_time_stamp)=',len(date_time_stamp))\n",
    "\n",
    "#num_stamp=netCDF4.date2num(date_time_stamp,time.units,time.calendar)\n",
    "\n",
    "#print('type(num_stamp)=',type(num_stamp))\n",
    "#print('num_stamp=',num_stamp)\n",
    "\n",
    "#j=netCDF4.num2date(num_stamp,time.units,time.calendar)\n",
    "\n",
    "#print('j=',j)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "  \n",
    "#try some tests:\n",
    "\n",
    "what_to_keep='all_times'\n",
    "#what_to_keep='all_but_first'\n",
    "#what_to_keep='all_but_first'\n",
    "#what_to_keep='all_but_first'\n",
    "\n",
    "if(what_to_keep=='all_times'):\n",
    "  #all times kept:\n",
    "  date_time_stamp_new=date_time_stamp\n",
    "  nino_new=nino\n",
    "  year_fraction_new=year_fraction\n",
    "  \n",
    "elif(what_to_keep=='all_but_first'):\n",
    "  #remove first day:\n",
    "  date_time_stamp_new=date_time_stamp[1::]\n",
    "  nino_new=nino[:,1::]\n",
    "  year_fraction_new=year_fraction[1::]\n",
    "  \n",
    "elif(what_to_keep=='all_but_first'):\n",
    "  #remove last day:\n",
    "  date_time_stamp_new=date_time_stamp[0:-1]\n",
    "  nino_new=nino[:,0:-1]\n",
    "  year_fraction_new=year_fraction[0:-1]\n",
    "\n",
    "elif(what_to_keep=='all_but_first'):\n",
    "  #remove first and last day:\n",
    "  date_time_stamp_new=date_time_stamp[1:-1]\n",
    "  nino_new=nino[:,1:-1]\n",
    "  year_fraction_new=year_fraction[1:-1]\n",
    "  \n",
    "else:\n",
    "  raise Exception('That what_to_keep option doesnt exist.')\n",
    "\n",
    "print('len(date_time_stamp_new)=',len(date_time_stamp_new))\n",
    "#print('date_time_stamp_new=',date_time_stamp_new)\n",
    "\n",
    "daily_month_indice_beg,daily_month_indice_end,daily_year_beg,daily_year_end,daily_month_beg,daily_month_end,daily_day_beg,daily_day_end,beg_month_partial,end_month_partial = \\\n",
    "  generate_daily_month_indices(date_time_stamp_new,time.units,time.calendar,1)\n",
    "\n",
    "#print('beg_month_partial,end_month_partial=',beg_month_partial,end_month_partial)\n",
    "#print('len(daily_month_indice_beg)=',len(daily_month_indice_beg))\n",
    "#print('daily_month_indice_beg=',daily_month_indice_beg)\n",
    "\n",
    "#print('daily_month_indice_end=',daily_month_indice_end)\n",
    "#print('daily_year_beg=',daily_year_beg)\n",
    "#print('daily_year_end=',daily_year_end)\n",
    "#print('daily_month_beg=',daily_month_beg)\n",
    "#print('daily_month_end=',daily_month_end)\n",
    "#print('daily_day_beg=',daily_day_beg)\n",
    "#print('daily_day_end=',daily_day_end)\n",
    "  \n",
    "#raise Exception('STOP!')\n",
    "\n",
    "nino_monthly=ma.zeros((nindices_nino,len(daily_month_indice_beg)),dtype=float)\n",
    "\n",
    "#print('nino_monthly.shape=',nino_monthly.shape)\n",
    "#print('nino_new.shape=',nino_new.shape)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "for k,indice in enumerate(indices_nino):\n",
    "  for month in range(0,len(daily_month_indice_beg)):\n",
    "    nino_monthly[k,month]=np.average(nino_new[k,daily_month_indice_beg[month]:daily_month_indice_end[month]+1])\n",
    "\n",
    "#print(nino_monthly[:,0])\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "year_fraction_monthly=ma.zeros(len(daily_month_indice_beg))\n",
    "for month in range(0,len(daily_month_indice_beg)):\n",
    "  year_fraction_monthly[month]=np.average(year_fraction_new[daily_month_indice_beg[month]:daily_month_indice_end[month]+1])\n",
    "\n",
    "num_stamp_new=netCDF4.date2num(date_time_stamp_new,time.units,time.calendar)\n",
    "\n",
    "num_stamp_monthly=np.zeros(len(daily_month_indice_beg))\n",
    "print('num_stamp_monthly.shape=',num_stamp_monthly.shape)\n",
    "\n",
    "for month in range(0,len(daily_month_indice_beg)):\n",
    "  num_stamp_monthly[month]=np.average(num_stamp_new[daily_month_indice_beg[month]:daily_month_indice_end[month]+1])\n",
    "\n",
    "#print('num_stamp_monthly_new=',num_stamp_monthly_new)\n",
    "\n",
    "date_time_stamp_monthly=netCDF4.num2date(num_stamp_monthly,time.units,time.calendar)\n",
    "\n",
    "#print('date_time_stamp_monthly_new',date_time_stamp_monthly_new)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "  \n",
    "EndOption=1 #use months with no days missing at begin and end months (i.e. discard partial months if they exist).\n",
    "#EndOption=2 #use months with days missing at both begin and end months (i.e. don't discard partial months if they exist @ beg/end).\n",
    "\n",
    "if(EndOption==1):\n",
    "  print('Discarding beg&/end month if they exist.')\n",
    "  if(beg_month_partial or end_month_partial):\n",
    "    if(beg_month_partial and end_month_partial):\n",
    "      print('type#1')\n",
    "      nino_monthly_new=nino_monthly[:,1:-1]\n",
    "      year_fraction_monthly_new=year_fraction_monthly[1:-1]\n",
    "      date_time_stamp_monthly_new=date_time_stamp_monthly[1:-1]\n",
    "      \n",
    "    elif(not beg_month_partial and end_month_partial):\n",
    "      print('type#2')\n",
    "      nino_monthly_new=nino_monthly[:,0:-1]\n",
    "      year_fraction_monthly_new=year_fraction_monthly[0:-1]\n",
    "      date_time_stamp_monthly_new=date_time_stamp_monthly[0:-1]\n",
    "\n",
    "    elif(beg_month_partial and not end_month_partial):\n",
    "      print('type#3')\n",
    "      nino_monthly_newnino=nino_monthly[:,1::]\n",
    "      year_fraction_monthly_new=year_fraction_monthly[1::]\n",
    "      date_time_stamp_monthly_new=date_time_stamp_monthly[1::]\n",
    "\n",
    "    else:\n",
    "      raise SystemExit('Shouldnt get here:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  else:\n",
    "    print('type#4')\n",
    "    nino_monthly_new=nino_monthly\n",
    "    year_fraction_monthly_new=year_fraction_monthly\n",
    "    date_time_stamp_monthly_new=date_time_stamp_monthly\n",
    "    \n",
    "elif(EndOption==2):\n",
    "  print('Keeping beg/end month or both.')\n",
    "  nino_monthly_new=nino_monthly\n",
    "  year_fraction_monthly_new=year_fraction_monthly\n",
    "  date_time_stamp_monthly_new=date_time_stamp_monthly\n",
    "  \n",
    "else:\n",
    "  raise SystemExit('EndOption can be only 1 or 2:'+__file__+' line number: '+str(inspect.stack()[0][2]))\n",
    "  \n",
    "#raise Exception('STOP!')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#print(nino_monthly_new)\n",
    "\n",
    "#print('year_fraction_monthly_new=',year_fraction_monthly_new)\n",
    "\n",
    "plot_index='nino34'\n",
    "#plot_index='nino1+2'\n",
    "#plot_index='nino4'\n",
    "\n",
    "fix,ax=plt.subplots()\n",
    "ax.plot(year_fraction_monthly_new,nino_monthly_new[indices_nino.index(plot_index),:],color='blue',label='mon_from_day')\n",
    "if(ReadPlotMonthly): ax.plot(year_fraction_monthly_raw,nino_monthly_raw[indices_nino.index(plot_index),:],color='red',label='mon')\n",
    "legend=ax.legend(loc='lower left',shadow=False,fontsize='large')\n",
    "plt.title('Monthly values')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(indices_label[indices_nino.index(plot_index)]($^o$C))\n",
    "plt.show()\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would like to caculate climatology/anomaly taking into account years with missing months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BEGIN.')\n",
    "\n",
    "nmy=12\n",
    "\n",
    "ybeg=date_time_stamp_monthly_new[0].year\n",
    "yend=date_time_stamp_monthly_new[-1].year\n",
    "\n",
    "#print('ybeg,yend=',ybeg,yend)\n",
    "\n",
    "#print('date_time_stamp=',date_time_stamp)\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "  \n",
    "ydiff=yend-ybeg+1\n",
    "\n",
    "MissingMonths=False\n",
    "\n",
    "first_month=date_time_stamp_monthly_new[0].month\n",
    "last_month=date_time_stamp_monthly_new[-1].month\n",
    "\n",
    "#print('first_month,last_month=',first_month,last_month)\n",
    "#print('ydiff=',ydiff)\n",
    "\n",
    "missing_months_beg,missing_months_end=0,0\n",
    "\n",
    "cyear_beg_skip,cyear_end_skip=0,1\n",
    "\n",
    "if(first_month!=1):\n",
    "  missing_months_beg=first_month-1\n",
    "  cyear_beg_skip=1\n",
    "  MissingMonths=True\n",
    "\n",
    "if(last_month!=12):\n",
    "  missing_months_end=12-last_month\n",
    "  cyear_end_skip=2\n",
    "  MissingMonths=True\n",
    "\n",
    "if(MissingMonths):\n",
    "  print('There are missing months in the set. '+str(missing_months_beg)+' at beginning and '+str(missing_months_end)+' at end.')\n",
    "  print('Currently years with missing months are not used in generating long term monthly climatology.')\n",
    "  print('And missing months will be set to missing in the final time-series.')\n",
    "  ts_beg,ts_end,ts_avg,dt_beg,dt_end,dt_avg=get_timestamp_number(ybeg,yend,1,12,time.units,time.calendar)\n",
    "  year_fraction_monthly_full=fractional_year_from_num2date(ts_avg,time.calendar)\n",
    "  \n",
    "  nino_monthly_full=ma.masked_all((nindices_nino,ydiff*nmy),dtype=float) #ensure missing months are masked out.\n",
    "  \n",
    "  print('nino_monthly_full.shape=',nino_monthly_full.shape)\n",
    "  \n",
    "  last_month_index=ydiff*nmy-(12-last_month)\n",
    "  print('first_month-1,last_month_index=',first_month-1,last_month_index)\n",
    "  nino_monthly_full[:,first_month-1:last_month_index]=nino_monthly_new\n",
    "else:\n",
    "  print('All years have 12 months of non-missing data.')\n",
    "  \n",
    "  nino_monthly_full=nino_monthly_new\n",
    "  year_fraction_monthly_full=year_fraction_monthly_new\n",
    "  \n",
    "#print(nino_monthly_full[:,0])\n",
    "\n",
    "#print('nino_monthly_full.shape=',nino_monthly_full.shape)\n",
    "#print('nino_monthly_full.shape[1]=',nino_monthly_full.shape[1])\n",
    "\n",
    "#print('cyear_beg_skip,cyear_end_skip=',cyear_beg_skip,cyear_end_skip)\n",
    "\n",
    "\n",
    "#raise Exception('STOP!')\n",
    "\n",
    "#keep all indices for monthly anomaly and 12 monthly climatology, other variables can be temporary.\n",
    "nino_monthly_anomaly=ma.zeros((nindices_nino,len(daily_month_indice_beg)),dtype=float)\n",
    "nino_climatology=ma.zeros((nindices_nino,12),dtype=float)\n",
    "\n",
    "for k,indice in enumerate(indices_nino):\n",
    "  #print('indice=',indice)\n",
    "  #print(new_monthly_array_shape(nino34_monthly_full[k,:].shape,ydiff,nmy))\n",
    "  #raise Exception('STOP!')\n",
    "  nino_monthly_reshaped=np.reshape(nino_monthly_full[k,:],new_monthly_array_shape(nino_monthly_full[k,:].shape,ydiff,nmy)) #check this works on large multi-dimensional arrays.\n",
    "  #print('nino_monthly_reshaped.shape=',nino_monthly_reshaped.shape)\n",
    "  nino_climatology[k]=np.average(nino_monthly_reshaped[cyear_beg_skip:-cyear_end_skip],axis=0) #average over full years only, this could be an option as could use for all years present.\n",
    "  nino_monthly_climatology=np.expand_dims(nino_climatology[k],0)\n",
    "  nino_monthly_climatology=np.tile(nino_monthly_climatology,(ydiff,1))\n",
    "  nino_monthly_climatology_flat=nino_monthly_climatology.flatten()\n",
    "  nino_monthly_anomaly[k,:]=nino_monthly_full[k,:]-nino_monthly_climatology_flat\n",
    "  \n",
    "%matplotlib inline\n",
    "\n",
    "zero=np.zeros(len(year_fraction_monthly_full))\n",
    "fix,ax=plt.subplots()\n",
    "for k,indice in enumerate(indices_nino):\n",
    "  ax.plot(year_fraction_monthly_full,nino_monthly_anomaly[k,:],label=indice)\n",
    "plt.plot(year_fraction_monthly_full,zero,color='black')\n",
    "\n",
    "legend=ax.legend(loc='upper center',shadow=False,fontsize='x-large')\n",
    "plt.title('Monthly anomalies')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('$^o$C')\n",
    "plt.show()\n",
    "\n",
    "#print('nino_monthly_anomaly[0]=',nino_monthly_anomaly[1])\n",
    "#print(nino_monthly_anomaly[:,0])\n",
    "\n",
    "print('END.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following monthly values will be calculated and then plotted. This approach assumes that all months have all days therefore is obsolete\n",
    "as cell above can deal with partial beg/end months of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ReadPlotMonthly=True #read in the monthly cmorised file and plot it over that calculated from daily inputs to check consistency.\n",
    "#ReadPlotMonthly=False\n",
    "\n",
    "#way to get it to reload the function without having to reset the kernel:\n",
    "#del(get_daily_indices_for_monthlyave)\n",
    "from decadal_diag import get_daily_indices_for_monthlyave\n",
    "\n",
    "if(ReadPlotMonthly):\n",
    "  ifil_raw='CMIP6/CMIP/CSIRO/CAFE-1-0/historical/r1i1p2f1/Omon/tos/gn/v20171025/tos_Omon_historical_CAFE-1-0_r1i1p2f1_gn_200201-201606.nc'\n",
    "  ifh_raw=netCDF4.Dataset(ifil_raw)\n",
    "  time_raw=ifh_raw.variables['time']\n",
    "  lat_raw=ifh_raw.variables['latitude'][:,0]\n",
    "  lon_raw=ifh_raw.variables['longitude'][0,:]\n",
    "  clat_raw=np.cos(lat_raw[:]*rad)\n",
    "  nino34_monthly_raw=np.average(np.average(ifh_raw.variables['tos'][:,122:152,110:160],axis=1,weights=clat_raw[122:152]),axis=1) #need to add in area weighting strictly\n",
    "  date_time_stamp_raw=netCDF4.num2date(time_raw[:],time_raw.units,time_raw.calendar)\n",
    "  year_fraction_monthly_raw=fractional_year_from_num2date(date_time_stamp_raw,time_raw.calendar)\n",
    "#  %matplotlib inline\n",
    "#  plt.title('Monthly values from monthly inputs')\n",
    "#  plt.plot(year_fraction_monthly_raw,nino34_monthly_raw[:])\n",
    "#  plt.xlabel('Year')\n",
    "#  plt.ylabel('Ni$\\~{n}$o34 ($^o$C)')\n",
    "#  plt.show()\n",
    "\n",
    "  #raise Exception('STOP!')\n",
    "  \n",
    "daily_indices=get_daily_indices_for_monthlyave(time,date_time_stamp,time.calendar) #a list\n",
    "\n",
    "print('daily_indices=',daily_indices)\n",
    "\n",
    "nino34_monthly=np.zeros(len(daily_indices))\n",
    "for month in range(0,len(daily_indices)):\n",
    "  nino34_monthly[month]=np.average(nino34[daily_indices[month]])\n",
    "\n",
    "year_fraction_monthly=np.zeros(len(daily_indices))\n",
    "for month in range(0,len(daily_indices)):\n",
    "  year_fraction_monthly[month]=np.average(year_fraction[daily_indices[month]])\n",
    "  \n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(year_fraction_monthly,nino34_monthly,color='blue')\n",
    "if(ReadPlotMonthly): plt.plot(year_fraction_monthly_raw,nino34_monthly_raw,color='red')\n",
    "plt.title('Monthly values')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ni$\\~{n}$o34 ($^o$C)')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the monthly values now we can calculate long term monthly climatologies and the month-to-month anomalies, and then plot the time-series. These are generally of more interest than the full monthly values.\n",
    "\n",
    "Want to generalise climatology, anomaly generation so that any data product can be processed (e.g. (time), (time, lat, lon), (time, depth, lat, lon), (time, lev, lat, lon).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ybeg=date_time_stamp[0].year\n",
    "yend=date_time_stamp[-1].year\n",
    "ydiff=yend-ybeg+1\n",
    "nmy=12\n",
    "\n",
    "nino34_monthly_reshaped=np.reshape(nino34_monthly,new_monthly_array_shape(nino34_monthly.shape,ydiff,nmy))\n",
    "climatology=np.average(nino34_monthly_reshaped,axis=0)\n",
    "nino34_monthly_climatology=np.expand_dims(climatology,0)\n",
    "nino34_monthly_climatology=np.tile(nino34_monthly_climatology,(ydiff,1))\n",
    "nino34_monthly_climatology_flat=nino34_monthly_climatology.flatten()\n",
    "nino34_monthly_anomaly=nino34_monthly-nino34_monthly_climatology_flat\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "zero=np.zeros(len(daily_indices))\n",
    "plt.plot(year_fraction_monthly,nino34_monthly_anomaly)\n",
    "plt.plot(year_fraction_monthly,zero)\n",
    "\n",
    "plt.title('Monthly anomalies')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ni$\\~{n}$o34 ($^o$C)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
